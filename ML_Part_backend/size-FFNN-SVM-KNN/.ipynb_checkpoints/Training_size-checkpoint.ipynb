{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data=np.load('data.npy')\n",
    "target=np.load('target.npy')\n",
    "\n",
    "#loading the save numpy arrays in the previous code\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,\n",
    "                                                              test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense #fully connected layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "#an empty Neural Network\n",
    "\n",
    "model.add(Dense(8,input_dim=2,activation='relu'))\n",
    "#1st Hidden Layer\n",
    "model.add(Dense(4,input_dim=8,activation='relu'))\n",
    "#2nd Hideen Layer\n",
    "model.add(Dense(2,input_dim=4,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 70\n",
      "Trainable params: 70\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "new_train_target=np_utils.to_categorical(train_target)\n",
    "print(new_train_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 104 samples, validate on 27 samples\n",
      "Epoch 1/2000\n",
      "104/104 [==============================] - 0s 1ms/step - loss: 117.4913 - accuracy: 0.4038 - val_loss: 129.7925 - val_accuracy: 0.3333\n",
      "Epoch 2/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 112.1026 - accuracy: 0.4038 - val_loss: 123.3911 - val_accuracy: 0.3333\n",
      "Epoch 3/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 106.4367 - accuracy: 0.4038 - val_loss: 117.1974 - val_accuracy: 0.3333\n",
      "Epoch 4/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 100.8690 - accuracy: 0.4038 - val_loss: 111.1620 - val_accuracy: 0.3333\n",
      "Epoch 5/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 95.6261 - accuracy: 0.4038 - val_loss: 105.2605 - val_accuracy: 0.3333\n",
      "Epoch 6/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 90.5912 - accuracy: 0.4038 - val_loss: 99.5361 - val_accuracy: 0.3333\n",
      "Epoch 7/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 85.6956 - accuracy: 0.4038 - val_loss: 94.0680 - val_accuracy: 0.3333\n",
      "Epoch 8/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 81.0611 - accuracy: 0.4038 - val_loss: 88.8514 - val_accuracy: 0.3333\n",
      "Epoch 9/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 76.6869 - accuracy: 0.4038 - val_loss: 83.7761 - val_accuracy: 0.3333\n",
      "Epoch 10/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 72.5098 - accuracy: 0.4038 - val_loss: 79.0781 - val_accuracy: 0.3333\n",
      "Epoch 11/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 68.5966 - accuracy: 0.4038 - val_loss: 74.7687 - val_accuracy: 0.3333\n",
      "Epoch 12/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 64.9099 - accuracy: 0.4038 - val_loss: 70.8529 - val_accuracy: 0.3333\n",
      "Epoch 13/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 61.5530 - accuracy: 0.4038 - val_loss: 67.2423 - val_accuracy: 0.3333\n",
      "Epoch 14/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 58.2881 - accuracy: 0.4038 - val_loss: 63.8842 - val_accuracy: 0.3333\n",
      "Epoch 15/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 55.3230 - accuracy: 0.4038 - val_loss: 60.6146 - val_accuracy: 0.3333\n",
      "Epoch 16/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 52.4844 - accuracy: 0.4038 - val_loss: 57.5257 - val_accuracy: 0.3333\n",
      "Epoch 17/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 49.6757 - accuracy: 0.4038 - val_loss: 54.6341 - val_accuracy: 0.3333\n",
      "Epoch 18/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 47.2314 - accuracy: 0.4038 - val_loss: 51.8600 - val_accuracy: 0.3333\n",
      "Epoch 19/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 44.8634 - accuracy: 0.4038 - val_loss: 49.2682 - val_accuracy: 0.3333\n",
      "Epoch 20/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 42.7095 - accuracy: 0.4038 - val_loss: 46.7749 - val_accuracy: 0.3333\n",
      "Epoch 21/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 40.4955 - accuracy: 0.4038 - val_loss: 44.2708 - val_accuracy: 0.3333\n",
      "Epoch 22/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 38.2772 - accuracy: 0.4038 - val_loss: 41.8126 - val_accuracy: 0.3333\n",
      "Epoch 23/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 36.1411 - accuracy: 0.4038 - val_loss: 39.4260 - val_accuracy: 0.3333\n",
      "Epoch 24/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 34.1551 - accuracy: 0.4038 - val_loss: 37.0913 - val_accuracy: 0.3333\n",
      "Epoch 25/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 32.0330 - accuracy: 0.4038 - val_loss: 34.7979 - val_accuracy: 0.3333\n",
      "Epoch 26/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 30.0601 - accuracy: 0.4038 - val_loss: 32.5277 - val_accuracy: 0.3333\n",
      "Epoch 27/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 28.1052 - accuracy: 0.4038 - val_loss: 30.3080 - val_accuracy: 0.3333\n",
      "Epoch 28/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 26.1383 - accuracy: 0.4038 - val_loss: 28.1552 - val_accuracy: 0.3333\n",
      "Epoch 29/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 24.2730 - accuracy: 0.4038 - val_loss: 25.9753 - val_accuracy: 0.3333\n",
      "Epoch 30/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 22.3659 - accuracy: 0.4038 - val_loss: 23.8117 - val_accuracy: 0.3333\n",
      "Epoch 31/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 20.5430 - accuracy: 0.4038 - val_loss: 22.0260 - val_accuracy: 0.3333\n",
      "Epoch 32/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 19.0814 - accuracy: 0.4038 - val_loss: 20.4037 - val_accuracy: 0.3333\n",
      "Epoch 33/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 17.6812 - accuracy: 0.4038 - val_loss: 18.7995 - val_accuracy: 0.3333\n",
      "Epoch 34/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 16.3341 - accuracy: 0.4038 - val_loss: 17.2015 - val_accuracy: 0.3333\n",
      "Epoch 35/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 12.5385 - accuracy: 0.500 - 0s 154us/step - loss: 14.8719 - accuracy: 0.4038 - val_loss: 15.6424 - val_accuracy: 0.3333\n",
      "Epoch 36/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 13.5066 - accuracy: 0.4038 - val_loss: 14.0587 - val_accuracy: 0.3333\n",
      "Epoch 37/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 12.1366 - accuracy: 0.4038 - val_loss: 12.4721 - val_accuracy: 0.3333\n",
      "Epoch 38/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 9.1166 - accuracy: 0.50 - 0s 125us/step - loss: 10.7137 - accuracy: 0.4038 - val_loss: 10.8962 - val_accuracy: 0.3333\n",
      "Epoch 39/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 9.3356 - accuracy: 0.4038 - val_loss: 9.3349 - val_accuracy: 0.3333\n",
      "Epoch 40/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 7.9982 - accuracy: 0.4038 - val_loss: 7.7823 - val_accuracy: 0.3333\n",
      "Epoch 41/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 6.6399 - accuracy: 0.4038 - val_loss: 6.2268 - val_accuracy: 0.3333\n",
      "Epoch 42/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 5.1841 - accuracy: 0.4038 - val_loss: 4.6716 - val_accuracy: 0.3333\n",
      "Epoch 43/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 3.8619 - accuracy: 0.4038 - val_loss: 3.0964 - val_accuracy: 0.3333\n",
      "Epoch 44/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 2.4636 - accuracy: 0.4038 - val_loss: 1.6469 - val_accuracy: 0.3333\n",
      "Epoch 45/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 1.2986 - accuracy: 0.4038 - val_loss: 0.7354 - val_accuracy: 0.4444\n",
      "Epoch 46/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.8411 - accuracy: 0.5385 - val_loss: 0.6607 - val_accuracy: 0.6667\n",
      "Epoch 47/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.9350 - accuracy: 0.5865 - val_loss: 0.7847 - val_accuracy: 0.6667\n",
      "Epoch 48/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 1.0791 - accuracy: 0.5865 - val_loss: 0.8296 - val_accuracy: 0.6667\n",
      "Epoch 49/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 1.1016 - accuracy: 0.5865 - val_loss: 0.7837 - val_accuracy: 0.6667\n",
      "Epoch 50/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 1.0250 - accuracy: 0.5865 - val_loss: 0.6968 - val_accuracy: 0.6667\n",
      "Epoch 51/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.9138 - accuracy: 0.5865 - val_loss: 0.6327 - val_accuracy: 0.6667\n",
      "Epoch 52/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.8304 - accuracy: 0.5865 - val_loss: 0.6278 - val_accuracy: 0.6296\n",
      "Epoch 53/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.8085 - accuracy: 0.5865 - val_loss: 0.6688 - val_accuracy: 0.6296\n",
      "Epoch 54/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.8210 - accuracy: 0.5865 - val_loss: 0.6983 - val_accuracy: 0.5556\n",
      "Epoch 55/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 135us/step - loss: 0.8325 - accuracy: 0.5865 - val_loss: 0.6868 - val_accuracy: 0.6296\n",
      "Epoch 56/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.8209 - accuracy: 0.5673 - val_loss: 0.6608 - val_accuracy: 0.6296\n",
      "Epoch 57/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.8038 - accuracy: 0.5865 - val_loss: 0.6334 - val_accuracy: 0.6296\n",
      "Epoch 58/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7956 - accuracy: 0.5865 - val_loss: 0.6181 - val_accuracy: 0.6667\n",
      "Epoch 59/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.8023 - accuracy: 0.5865 - val_loss: 0.6145 - val_accuracy: 0.6667\n",
      "Epoch 60/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.8039 - accuracy: 0.5865 - val_loss: 0.6138 - val_accuracy: 0.6667\n",
      "Epoch 61/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.8030 - accuracy: 0.5865 - val_loss: 0.6128 - val_accuracy: 0.6667\n",
      "Epoch 62/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.7969 - accuracy: 0.5865 - val_loss: 0.6125 - val_accuracy: 0.6667\n",
      "Epoch 63/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7924 - accuracy: 0.5865 - val_loss: 0.6142 - val_accuracy: 0.6667\n",
      "Epoch 64/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.7887 - accuracy: 0.5865 - val_loss: 0.6174 - val_accuracy: 0.6667\n",
      "Epoch 65/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.7874 - accuracy: 0.5865 - val_loss: 0.6209 - val_accuracy: 0.6667\n",
      "Epoch 66/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7864 - accuracy: 0.5865 - val_loss: 0.6214 - val_accuracy: 0.6667\n",
      "Epoch 67/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7855 - accuracy: 0.5865 - val_loss: 0.6195 - val_accuracy: 0.6667\n",
      "Epoch 68/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7859 - accuracy: 0.5865 - val_loss: 0.6146 - val_accuracy: 0.6667\n",
      "Epoch 69/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7829 - accuracy: 0.5865 - val_loss: 0.6161 - val_accuracy: 0.6667\n",
      "Epoch 70/2000\n",
      "104/104 [==============================] - 0s 298us/step - loss: 0.7840 - accuracy: 0.5865 - val_loss: 0.6243 - val_accuracy: 0.6667\n",
      "Epoch 71/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7844 - accuracy: 0.5865 - val_loss: 0.6299 - val_accuracy: 0.6667\n",
      "Epoch 72/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.7844 - accuracy: 0.5865 - val_loss: 0.6235 - val_accuracy: 0.6667\n",
      "Epoch 73/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 0.7798 - accuracy: 0.5865 - val_loss: 0.6144 - val_accuracy: 0.6667\n",
      "Epoch 74/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7790 - accuracy: 0.5865 - val_loss: 0.6050 - val_accuracy: 0.6667\n",
      "Epoch 75/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.59 - 0s 125us/step - loss: 0.7771 - accuracy: 0.5865 - val_loss: 0.6027 - val_accuracy: 0.6667\n",
      "Epoch 76/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7765 - accuracy: 0.5865 - val_loss: 0.6027 - val_accuracy: 0.6667\n",
      "Epoch 77/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7741 - accuracy: 0.5865 - val_loss: 0.6082 - val_accuracy: 0.6667\n",
      "Epoch 78/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7720 - accuracy: 0.5865 - val_loss: 0.6155 - val_accuracy: 0.6667\n",
      "Epoch 79/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7704 - accuracy: 0.5865 - val_loss: 0.6158 - val_accuracy: 0.6667\n",
      "Epoch 80/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7695 - accuracy: 0.5865 - val_loss: 0.6133 - val_accuracy: 0.6667\n",
      "Epoch 81/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7664 - accuracy: 0.5865 - val_loss: 0.6064 - val_accuracy: 0.6667\n",
      "Epoch 82/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.7646 - accuracy: 0.5865 - val_loss: 0.6015 - val_accuracy: 0.6667\n",
      "Epoch 83/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7650 - accuracy: 0.5865 - val_loss: 0.6011 - val_accuracy: 0.6667\n",
      "Epoch 84/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7639 - accuracy: 0.5865 - val_loss: 0.5998 - val_accuracy: 0.6667\n",
      "Epoch 85/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7630 - accuracy: 0.5865 - val_loss: 0.6019 - val_accuracy: 0.6667\n",
      "Epoch 86/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.7587 - accuracy: 0.5865 - val_loss: 0.6100 - val_accuracy: 0.6667\n",
      "Epoch 87/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7589 - accuracy: 0.5865 - val_loss: 0.6177 - val_accuracy: 0.6667\n",
      "Epoch 88/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7620 - accuracy: 0.5865 - val_loss: 0.6214 - val_accuracy: 0.6667\n",
      "Epoch 89/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7606 - accuracy: 0.5865 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
      "Epoch 90/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.7555 - accuracy: 0.5865 - val_loss: 0.6061 - val_accuracy: 0.6667\n",
      "Epoch 91/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7543 - accuracy: 0.5865 - val_loss: 0.6046 - val_accuracy: 0.6667\n",
      "Epoch 92/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.7532 - accuracy: 0.5865 - val_loss: 0.6102 - val_accuracy: 0.6667\n",
      "Epoch 93/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7522 - accuracy: 0.5865 - val_loss: 0.6122 - val_accuracy: 0.6667\n",
      "Epoch 94/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7529 - accuracy: 0.5865 - val_loss: 0.6133 - val_accuracy: 0.6667\n",
      "Epoch 95/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7501 - accuracy: 0.5865 - val_loss: 0.6070 - val_accuracy: 0.6667\n",
      "Epoch 96/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7485 - accuracy: 0.5865 - val_loss: 0.6026 - val_accuracy: 0.6667\n",
      "Epoch 97/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.7461 - accuracy: 0.5865 - val_loss: 0.6020 - val_accuracy: 0.6667\n",
      "Epoch 98/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7444 - accuracy: 0.5865 - val_loss: 0.6029 - val_accuracy: 0.6667\n",
      "Epoch 99/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7438 - accuracy: 0.5865 - val_loss: 0.6061 - val_accuracy: 0.6667\n",
      "Epoch 100/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7421 - accuracy: 0.5865 - val_loss: 0.6090 - val_accuracy: 0.6667\n",
      "Epoch 101/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7409 - accuracy: 0.5865 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
      "Epoch 102/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.6653 - accuracy: 0.53 - 0s 163us/step - loss: 0.7383 - accuracy: 0.5865 - val_loss: 0.6027 - val_accuracy: 0.6667\n",
      "Epoch 103/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7372 - accuracy: 0.5865 - val_loss: 0.5996 - val_accuracy: 0.6667\n",
      "Epoch 104/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7341 - accuracy: 0.5865 - val_loss: 0.5996 - val_accuracy: 0.6667\n",
      "Epoch 105/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7353 - accuracy: 0.5865 - val_loss: 0.5989 - val_accuracy: 0.6667\n",
      "Epoch 106/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7281 - accuracy: 0.5865 - val_loss: 0.6051 - val_accuracy: 0.6667\n",
      "Epoch 107/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7274 - accuracy: 0.5865 - val_loss: 0.6116 - val_accuracy: 0.6667\n",
      "Epoch 108/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7283 - accuracy: 0.5865 - val_loss: 0.6098 - val_accuracy: 0.6667\n",
      "Epoch 109/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7258 - accuracy: 0.5865 - val_loss: 0.6101 - val_accuracy: 0.6667\n",
      "Epoch 110/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 125us/step - loss: 0.7216 - accuracy: 0.5865 - val_loss: 0.6041 - val_accuracy: 0.6667\n",
      "Epoch 111/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7222 - accuracy: 0.5865 - val_loss: 0.5980 - val_accuracy: 0.6667\n",
      "Epoch 112/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7174 - accuracy: 0.5865 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
      "Epoch 113/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.7161 - accuracy: 0.5865 - val_loss: 0.5983 - val_accuracy: 0.6667\n",
      "Epoch 114/2000\n",
      "104/104 [==============================] - 0s 298us/step - loss: 0.7140 - accuracy: 0.5865 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
      "Epoch 115/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.7136 - accuracy: 0.5865 - val_loss: 0.5972 - val_accuracy: 0.6667\n",
      "Epoch 116/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7113 - accuracy: 0.5865 - val_loss: 0.6030 - val_accuracy: 0.6667\n",
      "Epoch 117/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.7102 - accuracy: 0.5865 - val_loss: 0.6066 - val_accuracy: 0.6667\n",
      "Epoch 118/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7105 - accuracy: 0.5865 - val_loss: 0.6127 - val_accuracy: 0.6667\n",
      "Epoch 119/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.7134 - accuracy: 0.5865 - val_loss: 0.6196 - val_accuracy: 0.6667\n",
      "Epoch 120/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.7132 - accuracy: 0.5865 - val_loss: 0.6123 - val_accuracy: 0.6667\n",
      "Epoch 121/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.7076 - accuracy: 0.5865 - val_loss: 0.6033 - val_accuracy: 0.6667\n",
      "Epoch 122/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7034 - accuracy: 0.5865 - val_loss: 0.5963 - val_accuracy: 0.6667\n",
      "Epoch 123/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.7019 - accuracy: 0.5865 - val_loss: 0.5938 - val_accuracy: 0.6667\n",
      "Epoch 124/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.7018 - accuracy: 0.5865 - val_loss: 0.5941 - val_accuracy: 0.6667\n",
      "Epoch 125/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.7000 - accuracy: 0.5865 - val_loss: 0.5967 - val_accuracy: 0.6667\n",
      "Epoch 126/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6994 - accuracy: 0.5865 - val_loss: 0.6000 - val_accuracy: 0.6667\n",
      "Epoch 127/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6965 - accuracy: 0.5865 - val_loss: 0.5985 - val_accuracy: 0.6667\n",
      "Epoch 128/2000\n",
      "104/104 [==============================] - 0s 231us/step - loss: 0.6952 - accuracy: 0.5865 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
      "Epoch 129/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6938 - accuracy: 0.5865 - val_loss: 0.5934 - val_accuracy: 0.6667\n",
      "Epoch 130/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6926 - accuracy: 0.5865 - val_loss: 0.5935 - val_accuracy: 0.6667\n",
      "Epoch 131/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6919 - accuracy: 0.5865 - val_loss: 0.5978 - val_accuracy: 0.6667\n",
      "Epoch 132/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6897 - accuracy: 0.5865 - val_loss: 0.5971 - val_accuracy: 0.6667\n",
      "Epoch 133/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6882 - accuracy: 0.5865 - val_loss: 0.5968 - val_accuracy: 0.6667\n",
      "Epoch 134/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6867 - accuracy: 0.5865 - val_loss: 0.5999 - val_accuracy: 0.6667\n",
      "Epoch 135/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6866 - accuracy: 0.5865 - val_loss: 0.6039 - val_accuracy: 0.6667\n",
      "Epoch 136/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6857 - accuracy: 0.5865 - val_loss: 0.6020 - val_accuracy: 0.6667\n",
      "Epoch 137/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6839 - accuracy: 0.5865 - val_loss: 0.5959 - val_accuracy: 0.6667\n",
      "Epoch 138/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6813 - accuracy: 0.5865 - val_loss: 0.5955 - val_accuracy: 0.6667\n",
      "Epoch 139/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6775 - accuracy: 0.5865 - val_loss: 0.5938 - val_accuracy: 0.6667\n",
      "Epoch 140/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.6753 - accuracy: 0.5865 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 141/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6749 - accuracy: 0.5865 - val_loss: 0.5894 - val_accuracy: 0.6667\n",
      "Epoch 142/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6722 - accuracy: 0.5865 - val_loss: 0.5918 - val_accuracy: 0.6667\n",
      "Epoch 143/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6703 - accuracy: 0.5865 - val_loss: 0.5958 - val_accuracy: 0.6667\n",
      "Epoch 144/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6695 - accuracy: 0.5865 - val_loss: 0.5934 - val_accuracy: 0.6667\n",
      "Epoch 145/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6689 - accuracy: 0.5865 - val_loss: 0.5926 - val_accuracy: 0.6667\n",
      "Epoch 146/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6685 - accuracy: 0.5865 - val_loss: 0.5933 - val_accuracy: 0.6667\n",
      "Epoch 147/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6672 - accuracy: 0.5865 - val_loss: 0.5920 - val_accuracy: 0.6667\n",
      "Epoch 148/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6669 - accuracy: 0.5865 - val_loss: 0.5921 - val_accuracy: 0.6667\n",
      "Epoch 149/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6651 - accuracy: 0.5865 - val_loss: 0.5886 - val_accuracy: 0.6667\n",
      "Epoch 150/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6672 - accuracy: 0.5865 - val_loss: 0.5870 - val_accuracy: 0.6667\n",
      "Epoch 151/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6668 - accuracy: 0.5865 - val_loss: 0.5881 - val_accuracy: 0.6667\n",
      "Epoch 152/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6638 - accuracy: 0.5865 - val_loss: 0.5881 - val_accuracy: 0.6667\n",
      "Epoch 153/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6640 - accuracy: 0.5865 - val_loss: 0.5890 - val_accuracy: 0.6667\n",
      "Epoch 154/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6613 - accuracy: 0.5865 - val_loss: 0.5876 - val_accuracy: 0.6667\n",
      "Epoch 155/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6611 - accuracy: 0.5865 - val_loss: 0.5871 - val_accuracy: 0.6667\n",
      "Epoch 156/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6598 - accuracy: 0.5865 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 157/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6609 - accuracy: 0.5865 - val_loss: 0.5979 - val_accuracy: 0.6667\n",
      "Epoch 158/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6615 - accuracy: 0.5865 - val_loss: 0.5905 - val_accuracy: 0.6667\n",
      "Epoch 159/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6572 - accuracy: 0.5865 - val_loss: 0.5892 - val_accuracy: 0.6667\n",
      "Epoch 160/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6579 - accuracy: 0.5865 - val_loss: 0.5879 - val_accuracy: 0.6667\n",
      "Epoch 161/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6561 - accuracy: 0.5865 - val_loss: 0.5917 - val_accuracy: 0.6667\n",
      "Epoch 162/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6568 - accuracy: 0.5865 - val_loss: 0.5999 - val_accuracy: 0.6667\n",
      "Epoch 163/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6573 - accuracy: 0.5865 - val_loss: 0.6009 - val_accuracy: 0.6667\n",
      "Epoch 164/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6582 - accuracy: 0.5865 - val_loss: 0.5999 - val_accuracy: 0.6667\n",
      "Epoch 165/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 106us/step - loss: 0.6555 - accuracy: 0.5865 - val_loss: 0.5916 - val_accuracy: 0.6667\n",
      "Epoch 166/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6585 - accuracy: 0.5865 - val_loss: 0.5829 - val_accuracy: 0.6667\n",
      "Epoch 167/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6575 - accuracy: 0.5865 - val_loss: 0.5827 - val_accuracy: 0.6667\n",
      "Epoch 168/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6561 - accuracy: 0.5865 - val_loss: 0.5828 - val_accuracy: 0.6667\n",
      "Epoch 169/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6526 - accuracy: 0.5865 - val_loss: 0.5848 - val_accuracy: 0.6667\n",
      "Epoch 170/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.6939 - accuracy: 0.59 - 0s 135us/step - loss: 0.6506 - accuracy: 0.5865 - val_loss: 0.5910 - val_accuracy: 0.6667\n",
      "Epoch 171/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.6495 - accuracy: 0.5865 - val_loss: 0.6004 - val_accuracy: 0.6667\n",
      "Epoch 172/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6550 - accuracy: 0.5865 - val_loss: 0.6030 - val_accuracy: 0.6667\n",
      "Epoch 173/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6518 - accuracy: 0.5865 - val_loss: 0.5899 - val_accuracy: 0.6667\n",
      "Epoch 174/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6466 - accuracy: 0.5865 - val_loss: 0.5833 - val_accuracy: 0.6667\n",
      "Epoch 175/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6495 - accuracy: 0.5865 - val_loss: 0.5809 - val_accuracy: 0.6667\n",
      "Epoch 176/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.6756 - accuracy: 0.59 - 0s 125us/step - loss: 0.6537 - accuracy: 0.5865 - val_loss: 0.5807 - val_accuracy: 0.6667\n",
      "Epoch 177/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6498 - accuracy: 0.5865 - val_loss: 0.5819 - val_accuracy: 0.6667\n",
      "Epoch 178/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6511 - accuracy: 0.5865 - val_loss: 0.5886 - val_accuracy: 0.6667\n",
      "Epoch 179/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6455 - accuracy: 0.5865 - val_loss: 0.5847 - val_accuracy: 0.6667\n",
      "Epoch 180/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6433 - accuracy: 0.5865 - val_loss: 0.5835 - val_accuracy: 0.6667\n",
      "Epoch 181/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6429 - accuracy: 0.5865 - val_loss: 0.5818 - val_accuracy: 0.6667\n",
      "Epoch 182/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6430 - accuracy: 0.5865 - val_loss: 0.5799 - val_accuracy: 0.6667\n",
      "Epoch 183/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6438 - accuracy: 0.5865 - val_loss: 0.5806 - val_accuracy: 0.6667\n",
      "Epoch 184/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6424 - accuracy: 0.5865 - val_loss: 0.5813 - val_accuracy: 0.6667\n",
      "Epoch 185/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6408 - accuracy: 0.5865 - val_loss: 0.5808 - val_accuracy: 0.6667\n",
      "Epoch 186/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6401 - accuracy: 0.5865 - val_loss: 0.5824 - val_accuracy: 0.6667\n",
      "Epoch 187/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6390 - accuracy: 0.5865 - val_loss: 0.5854 - val_accuracy: 0.6667\n",
      "Epoch 188/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6388 - accuracy: 0.5865 - val_loss: 0.5917 - val_accuracy: 0.6667\n",
      "Epoch 189/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6403 - accuracy: 0.5865 - val_loss: 0.5900 - val_accuracy: 0.6667\n",
      "Epoch 190/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.6389 - accuracy: 0.5865 - val_loss: 0.5869 - val_accuracy: 0.6667\n",
      "Epoch 191/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6371 - accuracy: 0.5865 - val_loss: 0.5822 - val_accuracy: 0.6667\n",
      "Epoch 192/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6354 - accuracy: 0.5865 - val_loss: 0.5778 - val_accuracy: 0.6667\n",
      "Epoch 193/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.6376 - accuracy: 0.5865 - val_loss: 0.5773 - val_accuracy: 0.6667\n",
      "Epoch 194/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6373 - accuracy: 0.5865 - val_loss: 0.5786 - val_accuracy: 0.6667\n",
      "Epoch 195/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6332 - accuracy: 0.5865 - val_loss: 0.5872 - val_accuracy: 0.6667\n",
      "Epoch 196/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.6340 - accuracy: 0.5865 - val_loss: 0.6040 - val_accuracy: 0.6667\n",
      "Epoch 197/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6443 - accuracy: 0.6346 - val_loss: 0.6071 - val_accuracy: 0.6667\n",
      "Epoch 198/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6393 - accuracy: 0.6250 - val_loss: 0.5883 - val_accuracy: 0.6667\n",
      "Epoch 199/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6329 - accuracy: 0.5865 - val_loss: 0.5772 - val_accuracy: 0.6667\n",
      "Epoch 200/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6372 - accuracy: 0.5865 - val_loss: 0.5761 - val_accuracy: 0.6667\n",
      "Epoch 201/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6388 - accuracy: 0.5865 - val_loss: 0.5827 - val_accuracy: 0.6667\n",
      "Epoch 202/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6306 - accuracy: 0.5865 - val_loss: 0.5790 - val_accuracy: 0.6667\n",
      "Epoch 203/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6295 - accuracy: 0.5865 - val_loss: 0.5777 - val_accuracy: 0.6667\n",
      "Epoch 204/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6304 - accuracy: 0.5865 - val_loss: 0.5775 - val_accuracy: 0.6667\n",
      "Epoch 205/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6288 - accuracy: 0.5865 - val_loss: 0.5846 - val_accuracy: 0.6667\n",
      "Epoch 206/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6286 - accuracy: 0.5865 - val_loss: 0.5826 - val_accuracy: 0.6667\n",
      "Epoch 207/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6291 - accuracy: 0.5865 - val_loss: 0.5788 - val_accuracy: 0.6667\n",
      "Epoch 208/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6268 - accuracy: 0.5865 - val_loss: 0.5793 - val_accuracy: 0.6667\n",
      "Epoch 209/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6259 - accuracy: 0.5865 - val_loss: 0.5780 - val_accuracy: 0.6667\n",
      "Epoch 210/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6267 - accuracy: 0.5865 - val_loss: 0.5801 - val_accuracy: 0.6667\n",
      "Epoch 211/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6250 - accuracy: 0.5865 - val_loss: 0.5781 - val_accuracy: 0.6667\n",
      "Epoch 212/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6244 - accuracy: 0.5865 - val_loss: 0.5767 - val_accuracy: 0.6667\n",
      "Epoch 213/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6240 - accuracy: 0.5865 - val_loss: 0.5758 - val_accuracy: 0.6667\n",
      "Epoch 214/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6235 - accuracy: 0.5865 - val_loss: 0.5755 - val_accuracy: 0.6667\n",
      "Epoch 215/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6231 - accuracy: 0.5865 - val_loss: 0.5752 - val_accuracy: 0.6667\n",
      "Epoch 216/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6224 - accuracy: 0.5865 - val_loss: 0.5736 - val_accuracy: 0.6667\n",
      "Epoch 217/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6235 - accuracy: 0.5865 - val_loss: 0.5716 - val_accuracy: 0.6667\n",
      "Epoch 218/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6297 - accuracy: 0.5865 - val_loss: 0.5708 - val_accuracy: 0.6667\n",
      "Epoch 219/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6264 - accuracy: 0.5865 - val_loss: 0.5753 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6208 - accuracy: 0.5865 - val_loss: 0.5779 - val_accuracy: 0.6667\n",
      "Epoch 221/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6207 - accuracy: 0.5865 - val_loss: 0.5757 - val_accuracy: 0.6667\n",
      "Epoch 222/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6200 - accuracy: 0.5865 - val_loss: 0.5765 - val_accuracy: 0.6667\n",
      "Epoch 223/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6201 - accuracy: 0.5865 - val_loss: 0.5730 - val_accuracy: 0.6667\n",
      "Epoch 224/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6189 - accuracy: 0.5865 - val_loss: 0.5746 - val_accuracy: 0.6667\n",
      "Epoch 225/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6185 - accuracy: 0.5865 - val_loss: 0.5774 - val_accuracy: 0.6667\n",
      "Epoch 226/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6172 - accuracy: 0.5865 - val_loss: 0.5830 - val_accuracy: 0.6667\n",
      "Epoch 227/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6225 - accuracy: 0.5962 - val_loss: 0.5881 - val_accuracy: 0.6667\n",
      "Epoch 228/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.6211 - accuracy: 0.5865 - val_loss: 0.5745 - val_accuracy: 0.6667\n",
      "Epoch 229/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6168 - accuracy: 0.5865 - val_loss: 0.5738 - val_accuracy: 0.6667\n",
      "Epoch 230/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6159 - accuracy: 0.5865 - val_loss: 0.5734 - val_accuracy: 0.6667\n",
      "Epoch 231/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6161 - accuracy: 0.5865 - val_loss: 0.5736 - val_accuracy: 0.6667\n",
      "Epoch 232/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6168 - accuracy: 0.5865 - val_loss: 0.5693 - val_accuracy: 0.6667\n",
      "Epoch 233/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6158 - accuracy: 0.5865 - val_loss: 0.5717 - val_accuracy: 0.6667\n",
      "Epoch 234/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6141 - accuracy: 0.5865 - val_loss: 0.5710 - val_accuracy: 0.6667\n",
      "Epoch 235/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6141 - accuracy: 0.5865 - val_loss: 0.5709 - val_accuracy: 0.6667\n",
      "Epoch 236/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6151 - accuracy: 0.5865 - val_loss: 0.5672 - val_accuracy: 0.6667\n",
      "Epoch 237/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6152 - accuracy: 0.5865 - val_loss: 0.5662 - val_accuracy: 0.6667\n",
      "Epoch 238/2000\n",
      "104/104 [==============================] - 0s 356us/step - loss: 0.6179 - accuracy: 0.5962 - val_loss: 0.5660 - val_accuracy: 0.6667\n",
      "Epoch 239/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6157 - accuracy: 0.5962 - val_loss: 0.5677 - val_accuracy: 0.6667\n",
      "Epoch 240/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.6091 - accuracy: 0.5865 - val_loss: 0.5809 - val_accuracy: 0.6667\n",
      "Epoch 241/2000\n",
      "104/104 [==============================] - 0s 375us/step - loss: 0.6160 - accuracy: 0.6442 - val_loss: 0.6042 - val_accuracy: 0.7407\n",
      "Epoch 242/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.6296 - accuracy: 0.6923 - val_loss: 0.5995 - val_accuracy: 0.7037\n",
      "Epoch 243/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6211 - accuracy: 0.6635 - val_loss: 0.5814 - val_accuracy: 0.6667\n",
      "Epoch 244/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.6139 - accuracy: 0.5865 - val_loss: 0.5725 - val_accuracy: 0.6667\n",
      "Epoch 245/2000\n",
      "104/104 [==============================] - 0s 250us/step - loss: 0.6126 - accuracy: 0.5865 - val_loss: 0.5791 - val_accuracy: 0.6667\n",
      "Epoch 246/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6110 - accuracy: 0.5865 - val_loss: 0.5742 - val_accuracy: 0.6667\n",
      "Epoch 247/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.6091 - accuracy: 0.5865 - val_loss: 0.5718 - val_accuracy: 0.6667\n",
      "Epoch 248/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6080 - accuracy: 0.5962 - val_loss: 0.5677 - val_accuracy: 0.6667\n",
      "Epoch 249/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.6064 - accuracy: 0.5962 - val_loss: 0.5638 - val_accuracy: 0.6667\n",
      "Epoch 250/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6101 - accuracy: 0.5962 - val_loss: 0.5636 - val_accuracy: 0.6667\n",
      "Epoch 251/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6103 - accuracy: 0.5962 - val_loss: 0.5658 - val_accuracy: 0.6667\n",
      "Epoch 252/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6070 - accuracy: 0.5962 - val_loss: 0.5662 - val_accuracy: 0.6667\n",
      "Epoch 253/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6063 - accuracy: 0.5962 - val_loss: 0.5701 - val_accuracy: 0.6667\n",
      "Epoch 254/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6069 - accuracy: 0.5962 - val_loss: 0.5712 - val_accuracy: 0.6667\n",
      "Epoch 255/2000\n",
      "104/104 [==============================] - 0s 260us/step - loss: 0.6057 - accuracy: 0.5962 - val_loss: 0.5668 - val_accuracy: 0.6667\n",
      "Epoch 256/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6093 - accuracy: 0.5962 - val_loss: 0.5618 - val_accuracy: 0.6667\n",
      "Epoch 257/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.6082 - accuracy: 0.5962 - val_loss: 0.5619 - val_accuracy: 0.6667\n",
      "Epoch 258/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6063 - accuracy: 0.5962 - val_loss: 0.5635 - val_accuracy: 0.6667\n",
      "Epoch 259/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6033 - accuracy: 0.5962 - val_loss: 0.5682 - val_accuracy: 0.6667\n",
      "Epoch 260/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6067 - accuracy: 0.6058 - val_loss: 0.5822 - val_accuracy: 0.7037\n",
      "Epoch 261/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6076 - accuracy: 0.6442 - val_loss: 0.5706 - val_accuracy: 0.6667\n",
      "Epoch 262/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6014 - accuracy: 0.5962 - val_loss: 0.5613 - val_accuracy: 0.6667\n",
      "Epoch 263/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6032 - accuracy: 0.5962 - val_loss: 0.5597 - val_accuracy: 0.6667\n",
      "Epoch 264/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6071 - accuracy: 0.5962 - val_loss: 0.5595 - val_accuracy: 0.6667\n",
      "Epoch 265/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.6113 - accuracy: 0.5962 - val_loss: 0.5592 - val_accuracy: 0.6667\n",
      "Epoch 266/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6066 - accuracy: 0.5962 - val_loss: 0.5601 - val_accuracy: 0.6667\n",
      "Epoch 267/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6021 - accuracy: 0.5962 - val_loss: 0.5627 - val_accuracy: 0.6667\n",
      "Epoch 268/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.6024 - accuracy: 0.5962 - val_loss: 0.5719 - val_accuracy: 0.6667\n",
      "Epoch 269/2000\n",
      "104/104 [==============================] - 0s 250us/step - loss: 0.6018 - accuracy: 0.6058 - val_loss: 0.5685 - val_accuracy: 0.6667\n",
      "Epoch 270/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 0.5992 - accuracy: 0.5962 - val_loss: 0.5620 - val_accuracy: 0.6667\n",
      "Epoch 271/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.6043 - accuracy: 0.5962 - val_loss: 0.5580 - val_accuracy: 0.6667\n",
      "Epoch 272/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.6030 - accuracy: 0.5962 - val_loss: 0.5617 - val_accuracy: 0.6667\n",
      "Epoch 273/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5989 - accuracy: 0.5962 - val_loss: 0.5628 - val_accuracy: 0.6667\n",
      "Epoch 274/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.5983 - accuracy: 0.5962 - val_loss: 0.5652 - val_accuracy: 0.6667\n",
      "Epoch 275/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 173us/step - loss: 0.5995 - accuracy: 0.5962 - val_loss: 0.5652 - val_accuracy: 0.6667\n",
      "Epoch 276/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.6003 - accuracy: 0.5962 - val_loss: 0.5582 - val_accuracy: 0.6667\n",
      "Epoch 277/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.5993 - accuracy: 0.5962 - val_loss: 0.5569 - val_accuracy: 0.6667\n",
      "Epoch 278/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5992 - accuracy: 0.5962 - val_loss: 0.5577 - val_accuracy: 0.6667\n",
      "Epoch 279/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5970 - accuracy: 0.5962 - val_loss: 0.5617 - val_accuracy: 0.6667\n",
      "Epoch 280/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5988 - accuracy: 0.6154 - val_loss: 0.5711 - val_accuracy: 0.6667\n",
      "Epoch 281/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5987 - accuracy: 0.6250 - val_loss: 0.5643 - val_accuracy: 0.6667\n",
      "Epoch 282/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5961 - accuracy: 0.5962 - val_loss: 0.5590 - val_accuracy: 0.6667\n",
      "Epoch 283/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5981 - accuracy: 0.5962 - val_loss: 0.5552 - val_accuracy: 0.6667\n",
      "Epoch 284/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5980 - accuracy: 0.5962 - val_loss: 0.5552 - val_accuracy: 0.6667\n",
      "Epoch 285/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5975 - accuracy: 0.5962 - val_loss: 0.5565 - val_accuracy: 0.6667\n",
      "Epoch 286/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5964 - accuracy: 0.5962 - val_loss: 0.5596 - val_accuracy: 0.6667\n",
      "Epoch 287/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5945 - accuracy: 0.5962 - val_loss: 0.5578 - val_accuracy: 0.6667\n",
      "Epoch 288/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.5938 - accuracy: 0.5962 - val_loss: 0.5560 - val_accuracy: 0.6667\n",
      "Epoch 289/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5941 - accuracy: 0.5962 - val_loss: 0.5558 - val_accuracy: 0.6667\n",
      "Epoch 290/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5950 - accuracy: 0.5962 - val_loss: 0.5559 - val_accuracy: 0.6667\n",
      "Epoch 291/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5937 - accuracy: 0.5962 - val_loss: 0.5555 - val_accuracy: 0.6667\n",
      "Epoch 292/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5934 - accuracy: 0.5962 - val_loss: 0.5595 - val_accuracy: 0.6667\n",
      "Epoch 293/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5960 - accuracy: 0.6058 - val_loss: 0.5645 - val_accuracy: 0.6667\n",
      "Epoch 294/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5923 - accuracy: 0.6058 - val_loss: 0.5553 - val_accuracy: 0.6667\n",
      "Epoch 295/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5907 - accuracy: 0.5962 - val_loss: 0.5519 - val_accuracy: 0.6667\n",
      "Epoch 296/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5945 - accuracy: 0.5962 - val_loss: 0.5516 - val_accuracy: 0.6667\n",
      "Epoch 297/2000\n",
      "104/104 [==============================] - 0s 116us/step - loss: 0.5949 - accuracy: 0.5962 - val_loss: 0.5521 - val_accuracy: 0.6667\n",
      "Epoch 298/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5911 - accuracy: 0.5962 - val_loss: 0.5600 - val_accuracy: 0.6667\n",
      "Epoch 299/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5898 - accuracy: 0.6442 - val_loss: 0.5717 - val_accuracy: 0.7037\n",
      "Epoch 300/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5982 - accuracy: 0.7308 - val_loss: 0.5743 - val_accuracy: 0.7037\n",
      "Epoch 301/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5975 - accuracy: 0.6827 - val_loss: 0.5578 - val_accuracy: 0.6667\n",
      "Epoch 302/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5898 - accuracy: 0.5962 - val_loss: 0.5540 - val_accuracy: 0.6667\n",
      "Epoch 303/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5895 - accuracy: 0.5962 - val_loss: 0.5508 - val_accuracy: 0.6667\n",
      "Epoch 304/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5900 - accuracy: 0.5962 - val_loss: 0.5517 - val_accuracy: 0.6667\n",
      "Epoch 305/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5881 - accuracy: 0.5962 - val_loss: 0.5570 - val_accuracy: 0.6667\n",
      "Epoch 306/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5900 - accuracy: 0.6538 - val_loss: 0.5679 - val_accuracy: 0.7037\n",
      "Epoch 307/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5954 - accuracy: 0.7019 - val_loss: 0.5687 - val_accuracy: 0.7037\n",
      "Epoch 308/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5936 - accuracy: 0.7212 - val_loss: 0.5702 - val_accuracy: 0.7037\n",
      "Epoch 309/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5910 - accuracy: 0.7115 - val_loss: 0.5577 - val_accuracy: 0.6667\n",
      "Epoch 310/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5878 - accuracy: 0.6058 - val_loss: 0.5506 - val_accuracy: 0.6667\n",
      "Epoch 311/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5867 - accuracy: 0.5962 - val_loss: 0.5542 - val_accuracy: 0.6667\n",
      "Epoch 312/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5910 - accuracy: 0.6346 - val_loss: 0.5679 - val_accuracy: 0.7037\n",
      "Epoch 313/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5902 - accuracy: 0.7115 - val_loss: 0.5574 - val_accuracy: 0.6667\n",
      "Epoch 314/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5869 - accuracy: 0.6154 - val_loss: 0.5471 - val_accuracy: 0.6667\n",
      "Epoch 315/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5921 - accuracy: 0.5962 - val_loss: 0.5474 - val_accuracy: 0.6667\n",
      "Epoch 316/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5953 - accuracy: 0.5962 - val_loss: 0.5460 - val_accuracy: 0.6667\n",
      "Epoch 317/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5890 - accuracy: 0.5962 - val_loss: 0.5512 - val_accuracy: 0.6667\n",
      "Epoch 318/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5840 - accuracy: 0.6058 - val_loss: 0.5576 - val_accuracy: 0.7037\n",
      "Epoch 319/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5863 - accuracy: 0.6923 - val_loss: 0.5613 - val_accuracy: 0.7037\n",
      "Epoch 320/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5874 - accuracy: 0.6923 - val_loss: 0.5618 - val_accuracy: 0.7037\n",
      "Epoch 321/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5884 - accuracy: 0.7115 - val_loss: 0.5653 - val_accuracy: 0.7037\n",
      "Epoch 322/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5893 - accuracy: 0.7019 - val_loss: 0.5536 - val_accuracy: 0.6667\n",
      "Epoch 323/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5822 - accuracy: 0.6250 - val_loss: 0.5470 - val_accuracy: 0.6667\n",
      "Epoch 324/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5831 - accuracy: 0.5962 - val_loss: 0.5450 - val_accuracy: 0.6667\n",
      "Epoch 325/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5836 - accuracy: 0.5962 - val_loss: 0.5449 - val_accuracy: 0.6667\n",
      "Epoch 326/2000\n",
      "104/104 [==============================] - 0s 87us/step - loss: 0.5835 - accuracy: 0.5962 - val_loss: 0.5457 - val_accuracy: 0.6667\n",
      "Epoch 327/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5825 - accuracy: 0.5962 - val_loss: 0.5479 - val_accuracy: 0.6667\n",
      "Epoch 328/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5862 - accuracy: 0.6250 - val_loss: 0.5581 - val_accuracy: 0.7037\n",
      "Epoch 329/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5826 - accuracy: 0.6827 - val_loss: 0.5485 - val_accuracy: 0.6667\n",
      "Epoch 330/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 106us/step - loss: 0.5799 - accuracy: 0.5962 - val_loss: 0.5428 - val_accuracy: 0.6667\n",
      "Epoch 331/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5839 - accuracy: 0.5962 - val_loss: 0.5422 - val_accuracy: 0.6667\n",
      "Epoch 332/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5884 - accuracy: 0.5962 - val_loss: 0.5419 - val_accuracy: 0.6667\n",
      "Epoch 333/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5888 - accuracy: 0.5962 - val_loss: 0.5418 - val_accuracy: 0.6667\n",
      "Epoch 334/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5836 - accuracy: 0.5962 - val_loss: 0.5452 - val_accuracy: 0.6667\n",
      "Epoch 335/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5771 - accuracy: 0.6538 - val_loss: 0.5667 - val_accuracy: 0.7407\n",
      "Epoch 336/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5934 - accuracy: 0.7212 - val_loss: 0.5732 - val_accuracy: 0.8148\n",
      "Epoch 337/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5896 - accuracy: 0.6923 - val_loss: 0.5447 - val_accuracy: 0.6667\n",
      "Epoch 338/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5850 - accuracy: 0.5962 - val_loss: 0.5402 - val_accuracy: 0.6667\n",
      "Epoch 339/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5783 - accuracy: 0.5962 - val_loss: 0.5465 - val_accuracy: 0.6667\n",
      "Epoch 340/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5841 - accuracy: 0.6827 - val_loss: 0.5686 - val_accuracy: 0.8148\n",
      "Epoch 341/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5876 - accuracy: 0.7404 - val_loss: 0.5638 - val_accuracy: 0.7407\n",
      "Epoch 342/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5825 - accuracy: 0.7404 - val_loss: 0.5456 - val_accuracy: 0.6667\n",
      "Epoch 343/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5807 - accuracy: 0.6058 - val_loss: 0.5388 - val_accuracy: 0.6667\n",
      "Epoch 344/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5811 - accuracy: 0.5962 - val_loss: 0.5390 - val_accuracy: 0.6667\n",
      "Epoch 345/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5762 - accuracy: 0.6058 - val_loss: 0.5486 - val_accuracy: 0.7037\n",
      "Epoch 346/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5775 - accuracy: 0.6923 - val_loss: 0.5548 - val_accuracy: 0.7037\n",
      "Epoch 347/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5784 - accuracy: 0.7212 - val_loss: 0.5507 - val_accuracy: 0.7037\n",
      "Epoch 348/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5758 - accuracy: 0.6827 - val_loss: 0.5424 - val_accuracy: 0.6667\n",
      "Epoch 349/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5768 - accuracy: 0.5962 - val_loss: 0.5382 - val_accuracy: 0.6667\n",
      "Epoch 350/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5763 - accuracy: 0.5962 - val_loss: 0.5380 - val_accuracy: 0.6667\n",
      "Epoch 351/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5757 - accuracy: 0.5962 - val_loss: 0.5399 - val_accuracy: 0.6667\n",
      "Epoch 352/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5739 - accuracy: 0.6058 - val_loss: 0.5404 - val_accuracy: 0.6667\n",
      "Epoch 353/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5745 - accuracy: 0.6635 - val_loss: 0.5439 - val_accuracy: 0.7037\n",
      "Epoch 354/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5733 - accuracy: 0.6923 - val_loss: 0.5447 - val_accuracy: 0.7037\n",
      "Epoch 355/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5760 - accuracy: 0.6731 - val_loss: 0.5414 - val_accuracy: 0.6667\n",
      "Epoch 356/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5726 - accuracy: 0.6635 - val_loss: 0.5425 - val_accuracy: 0.7037\n",
      "Epoch 357/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.5766 - accuracy: 0.65 - 0s 106us/step - loss: 0.5723 - accuracy: 0.6923 - val_loss: 0.5457 - val_accuracy: 0.7037\n",
      "Epoch 358/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5731 - accuracy: 0.6923 - val_loss: 0.5400 - val_accuracy: 0.6667\n",
      "Epoch 359/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5728 - accuracy: 0.6731 - val_loss: 0.5407 - val_accuracy: 0.6667\n",
      "Epoch 360/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5731 - accuracy: 0.6250 - val_loss: 0.5359 - val_accuracy: 0.6667\n",
      "Epoch 361/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5715 - accuracy: 0.5962 - val_loss: 0.5383 - val_accuracy: 0.6667\n",
      "Epoch 362/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5703 - accuracy: 0.6827 - val_loss: 0.5411 - val_accuracy: 0.7037\n",
      "Epoch 363/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5707 - accuracy: 0.6731 - val_loss: 0.5388 - val_accuracy: 0.6667\n",
      "Epoch 364/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5713 - accuracy: 0.6827 - val_loss: 0.5406 - val_accuracy: 0.7037\n",
      "Epoch 365/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5687 - accuracy: 0.6827 - val_loss: 0.5336 - val_accuracy: 0.6667\n",
      "Epoch 366/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5722 - accuracy: 0.5962 - val_loss: 0.5326 - val_accuracy: 0.6667\n",
      "Epoch 367/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5751 - accuracy: 0.5962 - val_loss: 0.5323 - val_accuracy: 0.6667\n",
      "Epoch 368/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5720 - accuracy: 0.5962 - val_loss: 0.5353 - val_accuracy: 0.6667\n",
      "Epoch 369/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5684 - accuracy: 0.6538 - val_loss: 0.5366 - val_accuracy: 0.6667\n",
      "Epoch 370/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.6133 - accuracy: 0.59 - 0s 106us/step - loss: 0.5690 - accuracy: 0.6731 - val_loss: 0.5356 - val_accuracy: 0.6667\n",
      "Epoch 371/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5682 - accuracy: 0.6154 - val_loss: 0.5313 - val_accuracy: 0.6667\n",
      "Epoch 372/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5727 - accuracy: 0.5962 - val_loss: 0.5321 - val_accuracy: 0.6667\n",
      "Epoch 373/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5682 - accuracy: 0.5962 - val_loss: 0.5309 - val_accuracy: 0.6667\n",
      "Epoch 374/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5702 - accuracy: 0.5962 - val_loss: 0.5307 - val_accuracy: 0.6667\n",
      "Epoch 375/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5690 - accuracy: 0.5962 - val_loss: 0.5350 - val_accuracy: 0.7037\n",
      "Epoch 376/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5662 - accuracy: 0.6923 - val_loss: 0.5430 - val_accuracy: 0.7407\n",
      "Epoch 377/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5705 - accuracy: 0.7019 - val_loss: 0.5384 - val_accuracy: 0.7037\n",
      "Epoch 378/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5652 - accuracy: 0.6923 - val_loss: 0.5322 - val_accuracy: 0.6667\n",
      "Epoch 379/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5691 - accuracy: 0.6058 - val_loss: 0.5293 - val_accuracy: 0.6667\n",
      "Epoch 380/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5757 - accuracy: 0.5962 - val_loss: 0.5289 - val_accuracy: 0.6667\n",
      "Epoch 381/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5662 - accuracy: 0.6058 - val_loss: 0.5330 - val_accuracy: 0.7037\n",
      "Epoch 382/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5672 - accuracy: 0.7019 - val_loss: 0.5502 - val_accuracy: 0.7778\n",
      "Epoch 383/2000\n",
      "104/104 [==============================] - 0s 87us/step - loss: 0.5713 - accuracy: 0.7596 - val_loss: 0.5464 - val_accuracy: 0.7407\n",
      "Epoch 384/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5652 - accuracy: 0.7212 - val_loss: 0.5304 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5716 - accuracy: 0.6154 - val_loss: 0.5276 - val_accuracy: 0.6667\n",
      "Epoch 386/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5655 - accuracy: 0.5962 - val_loss: 0.5321 - val_accuracy: 0.7037\n",
      "Epoch 387/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5656 - accuracy: 0.7404 - val_loss: 0.5586 - val_accuracy: 0.8148\n",
      "Epoch 388/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5808 - accuracy: 0.7500 - val_loss: 0.5570 - val_accuracy: 0.8148\n",
      "Epoch 389/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5684 - accuracy: 0.7404 - val_loss: 0.5296 - val_accuracy: 0.6667\n",
      "Epoch 390/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5605 - accuracy: 0.6346 - val_loss: 0.5262 - val_accuracy: 0.6667\n",
      "Epoch 391/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5692 - accuracy: 0.5962 - val_loss: 0.5261 - val_accuracy: 0.6667\n",
      "Epoch 392/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5690 - accuracy: 0.5962 - val_loss: 0.5259 - val_accuracy: 0.6667\n",
      "Epoch 393/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5629 - accuracy: 0.6250 - val_loss: 0.5289 - val_accuracy: 0.7037\n",
      "Epoch 394/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5605 - accuracy: 0.6827 - val_loss: 0.5304 - val_accuracy: 0.7037\n",
      "Epoch 395/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 0.5610 - accuracy: 0.7019 - val_loss: 0.5372 - val_accuracy: 0.7407\n",
      "Epoch 396/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5618 - accuracy: 0.7404 - val_loss: 0.5376 - val_accuracy: 0.7407\n",
      "Epoch 397/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5638 - accuracy: 0.7308 - val_loss: 0.5314 - val_accuracy: 0.7037\n",
      "Epoch 398/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5606 - accuracy: 0.7115 - val_loss: 0.5297 - val_accuracy: 0.7037\n",
      "Epoch 399/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5640 - accuracy: 0.6442 - val_loss: 0.5243 - val_accuracy: 0.6667\n",
      "Epoch 400/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5606 - accuracy: 0.6442 - val_loss: 0.5295 - val_accuracy: 0.7037\n",
      "Epoch 401/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.5586 - accuracy: 0.6923 - val_loss: 0.5275 - val_accuracy: 0.7037\n",
      "Epoch 402/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5578 - accuracy: 0.6923 - val_loss: 0.5277 - val_accuracy: 0.7037\n",
      "Epoch 403/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5582 - accuracy: 0.6923 - val_loss: 0.5312 - val_accuracy: 0.7037\n",
      "Epoch 404/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5576 - accuracy: 0.7404 - val_loss: 0.5379 - val_accuracy: 0.7407\n",
      "Epoch 405/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5603 - accuracy: 0.7500 - val_loss: 0.5306 - val_accuracy: 0.7037\n",
      "Epoch 406/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5576 - accuracy: 0.7212 - val_loss: 0.5311 - val_accuracy: 0.7407\n",
      "Epoch 407/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5574 - accuracy: 0.7308 - val_loss: 0.5307 - val_accuracy: 0.7407\n",
      "Epoch 408/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5569 - accuracy: 0.7019 - val_loss: 0.5247 - val_accuracy: 0.7037\n",
      "Epoch 409/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5570 - accuracy: 0.6827 - val_loss: 0.5233 - val_accuracy: 0.7037\n",
      "Epoch 410/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5560 - accuracy: 0.6923 - val_loss: 0.5264 - val_accuracy: 0.7037\n",
      "Epoch 411/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5547 - accuracy: 0.6923 - val_loss: 0.5231 - val_accuracy: 0.7037\n",
      "Epoch 412/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5550 - accuracy: 0.6923 - val_loss: 0.5211 - val_accuracy: 0.6667\n",
      "Epoch 413/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5560 - accuracy: 0.6635 - val_loss: 0.5199 - val_accuracy: 0.6667\n",
      "Epoch 414/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5571 - accuracy: 0.6058 - val_loss: 0.5198 - val_accuracy: 0.6667\n",
      "Epoch 415/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5632 - accuracy: 0.6154 - val_loss: 0.5198 - val_accuracy: 0.6667\n",
      "Epoch 416/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5558 - accuracy: 0.6635 - val_loss: 0.5195 - val_accuracy: 0.6667\n",
      "Epoch 417/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5552 - accuracy: 0.6538 - val_loss: 0.5194 - val_accuracy: 0.6667\n",
      "Epoch 418/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5538 - accuracy: 0.6635 - val_loss: 0.5212 - val_accuracy: 0.7037\n",
      "Epoch 419/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5529 - accuracy: 0.6923 - val_loss: 0.5221 - val_accuracy: 0.7037\n",
      "Epoch 420/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5524 - accuracy: 0.6923 - val_loss: 0.5204 - val_accuracy: 0.7037\n",
      "Epoch 421/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5529 - accuracy: 0.6827 - val_loss: 0.5179 - val_accuracy: 0.6667\n",
      "Epoch 422/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5537 - accuracy: 0.6442 - val_loss: 0.5188 - val_accuracy: 0.7037\n",
      "Epoch 423/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5518 - accuracy: 0.6923 - val_loss: 0.5218 - val_accuracy: 0.7037\n",
      "Epoch 424/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5544 - accuracy: 0.7212 - val_loss: 0.5249 - val_accuracy: 0.7407\n",
      "Epoch 425/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5521 - accuracy: 0.7212 - val_loss: 0.5183 - val_accuracy: 0.7037\n",
      "Epoch 426/2000\n",
      "104/104 [==============================] - 0s 116us/step - loss: 0.5509 - accuracy: 0.6923 - val_loss: 0.5175 - val_accuracy: 0.7037\n",
      "Epoch 427/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5525 - accuracy: 0.6731 - val_loss: 0.5163 - val_accuracy: 0.6667\n",
      "Epoch 428/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5524 - accuracy: 0.6442 - val_loss: 0.5177 - val_accuracy: 0.7037\n",
      "Epoch 429/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5493 - accuracy: 0.7019 - val_loss: 0.5285 - val_accuracy: 0.7778\n",
      "Epoch 430/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5526 - accuracy: 0.7500 - val_loss: 0.5274 - val_accuracy: 0.7407\n",
      "Epoch 431/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5567 - accuracy: 0.7692 - val_loss: 0.5292 - val_accuracy: 0.7778\n",
      "Epoch 432/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5502 - accuracy: 0.7404 - val_loss: 0.5160 - val_accuracy: 0.7037\n",
      "Epoch 433/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5560 - accuracy: 0.6442 - val_loss: 0.5144 - val_accuracy: 0.6667\n",
      "Epoch 434/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.5390 - accuracy: 0.59 - 0s 125us/step - loss: 0.5518 - accuracy: 0.6058 - val_loss: 0.5153 - val_accuracy: 0.7037\n",
      "Epoch 435/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5466 - accuracy: 0.6923 - val_loss: 0.5289 - val_accuracy: 0.8148\n",
      "Epoch 436/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5521 - accuracy: 0.7596 - val_loss: 0.5292 - val_accuracy: 0.8148\n",
      "Epoch 437/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5526 - accuracy: 0.7404 - val_loss: 0.5151 - val_accuracy: 0.7037\n",
      "Epoch 438/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5522 - accuracy: 0.6731 - val_loss: 0.5135 - val_accuracy: 0.6667\n",
      "Epoch 439/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5471 - accuracy: 0.6827 - val_loss: 0.5164 - val_accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5482 - accuracy: 0.7308 - val_loss: 0.5265 - val_accuracy: 0.7778\n",
      "Epoch 441/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5486 - accuracy: 0.7692 - val_loss: 0.5218 - val_accuracy: 0.7407\n",
      "Epoch 442/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5473 - accuracy: 0.7212 - val_loss: 0.5141 - val_accuracy: 0.7037\n",
      "Epoch 443/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5451 - accuracy: 0.6923 - val_loss: 0.5137 - val_accuracy: 0.7037\n",
      "Epoch 444/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5447 - accuracy: 0.7115 - val_loss: 0.5169 - val_accuracy: 0.7407\n",
      "Epoch 445/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5447 - accuracy: 0.7404 - val_loss: 0.5188 - val_accuracy: 0.7407\n",
      "Epoch 446/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5456 - accuracy: 0.7500 - val_loss: 0.5163 - val_accuracy: 0.7407\n",
      "Epoch 447/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5433 - accuracy: 0.7212 - val_loss: 0.5124 - val_accuracy: 0.7037\n",
      "Epoch 448/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5443 - accuracy: 0.6923 - val_loss: 0.5115 - val_accuracy: 0.7037\n",
      "Epoch 449/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5432 - accuracy: 0.7019 - val_loss: 0.5145 - val_accuracy: 0.7037\n",
      "Epoch 450/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5462 - accuracy: 0.7308 - val_loss: 0.5168 - val_accuracy: 0.7407\n",
      "Epoch 451/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5431 - accuracy: 0.7308 - val_loss: 0.5107 - val_accuracy: 0.7037\n",
      "Epoch 452/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5427 - accuracy: 0.6923 - val_loss: 0.5107 - val_accuracy: 0.7037\n",
      "Epoch 453/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5448 - accuracy: 0.6923 - val_loss: 0.5126 - val_accuracy: 0.7037\n",
      "Epoch 454/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.5461 - accuracy: 0.7596 - val_loss: 0.5282 - val_accuracy: 0.8148\n",
      "Epoch 455/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5443 - accuracy: 0.7596 - val_loss: 0.5131 - val_accuracy: 0.7407\n",
      "Epoch 456/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5464 - accuracy: 0.6923 - val_loss: 0.5081 - val_accuracy: 0.7037\n",
      "Epoch 457/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5420 - accuracy: 0.6923 - val_loss: 0.5109 - val_accuracy: 0.7037\n",
      "Epoch 458/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5401 - accuracy: 0.7212 - val_loss: 0.5162 - val_accuracy: 0.7407\n",
      "Epoch 459/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5411 - accuracy: 0.7692 - val_loss: 0.5152 - val_accuracy: 0.7407\n",
      "Epoch 460/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5401 - accuracy: 0.7404 - val_loss: 0.5090 - val_accuracy: 0.7037\n",
      "Epoch 461/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.5410 - accuracy: 0.6923 - val_loss: 0.5075 - val_accuracy: 0.7037\n",
      "Epoch 462/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5395 - accuracy: 0.6923 - val_loss: 0.5103 - val_accuracy: 0.7407\n",
      "Epoch 463/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5419 - accuracy: 0.7596 - val_loss: 0.5208 - val_accuracy: 0.8148\n",
      "Epoch 464/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5432 - accuracy: 0.7788 - val_loss: 0.5089 - val_accuracy: 0.7037\n",
      "Epoch 465/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5399 - accuracy: 0.7212 - val_loss: 0.5073 - val_accuracy: 0.7037\n",
      "Epoch 466/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5369 - accuracy: 0.6923 - val_loss: 0.5053 - val_accuracy: 0.6667\n",
      "Epoch 467/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5457 - accuracy: 0.6154 - val_loss: 0.5051 - val_accuracy: 0.6667\n",
      "Epoch 468/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5457 - accuracy: 0.6538 - val_loss: 0.5067 - val_accuracy: 0.7037\n",
      "Epoch 469/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5389 - accuracy: 0.7115 - val_loss: 0.5051 - val_accuracy: 0.7037\n",
      "Epoch 470/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5385 - accuracy: 0.7019 - val_loss: 0.5114 - val_accuracy: 0.7407\n",
      "Epoch 471/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5372 - accuracy: 0.7692 - val_loss: 0.5116 - val_accuracy: 0.7778\n",
      "Epoch 472/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5371 - accuracy: 0.7500 - val_loss: 0.5069 - val_accuracy: 0.7407\n",
      "Epoch 473/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5359 - accuracy: 0.7308 - val_loss: 0.5087 - val_accuracy: 0.7407\n",
      "Epoch 474/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5379 - accuracy: 0.7596 - val_loss: 0.5107 - val_accuracy: 0.7778\n",
      "Epoch 475/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5376 - accuracy: 0.7788 - val_loss: 0.5074 - val_accuracy: 0.7407\n",
      "Epoch 476/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5339 - accuracy: 0.7115 - val_loss: 0.5025 - val_accuracy: 0.6667\n",
      "Epoch 477/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5410 - accuracy: 0.6538 - val_loss: 0.5022 - val_accuracy: 0.6667\n",
      "Epoch 478/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5419 - accuracy: 0.6731 - val_loss: 0.5024 - val_accuracy: 0.7037\n",
      "Epoch 479/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5351 - accuracy: 0.6923 - val_loss: 0.5020 - val_accuracy: 0.7037\n",
      "Epoch 480/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5355 - accuracy: 0.6923 - val_loss: 0.5016 - val_accuracy: 0.7037\n",
      "Epoch 481/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5353 - accuracy: 0.7019 - val_loss: 0.5028 - val_accuracy: 0.7037\n",
      "Epoch 482/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5326 - accuracy: 0.7212 - val_loss: 0.5010 - val_accuracy: 0.7037\n",
      "Epoch 483/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.5368 - accuracy: 0.7019 - val_loss: 0.5004 - val_accuracy: 0.7037\n",
      "Epoch 484/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5394 - accuracy: 0.6635 - val_loss: 0.5041 - val_accuracy: 0.6667\n",
      "Epoch 485/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5512 - accuracy: 0.5962 - val_loss: 0.5017 - val_accuracy: 0.6667\n",
      "Epoch 486/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.5386 - accuracy: 0.6827 - val_loss: 0.5082 - val_accuracy: 0.7778\n",
      "Epoch 487/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5341 - accuracy: 0.7692 - val_loss: 0.5275 - val_accuracy: 0.8519\n",
      "Epoch 488/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.5536 - accuracy: 0.81 - 0s 163us/step - loss: 0.5459 - accuracy: 0.7885 - val_loss: 0.5277 - val_accuracy: 0.8519\n",
      "Epoch 489/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 0.5417 - accuracy: 0.7788 - val_loss: 0.5119 - val_accuracy: 0.8148\n",
      "Epoch 490/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.5350 - accuracy: 0.7212 - val_loss: 0.4985 - val_accuracy: 0.7037\n",
      "Epoch 491/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5406 - accuracy: 0.6346 - val_loss: 0.4999 - val_accuracy: 0.6667\n",
      "Epoch 492/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5412 - accuracy: 0.6731 - val_loss: 0.5001 - val_accuracy: 0.7407\n",
      "Epoch 493/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5292 - accuracy: 0.7404 - val_loss: 0.5031 - val_accuracy: 0.7407\n",
      "Epoch 494/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.5294 - accuracy: 0.7692 - val_loss: 0.5020 - val_accuracy: 0.7407\n",
      "Epoch 495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 125us/step - loss: 0.5317 - accuracy: 0.7500 - val_loss: 0.4982 - val_accuracy: 0.7037\n",
      "Epoch 496/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.5288 - accuracy: 0.7212 - val_loss: 0.5000 - val_accuracy: 0.7407\n",
      "Epoch 497/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5285 - accuracy: 0.7500 - val_loss: 0.5021 - val_accuracy: 0.7778\n",
      "Epoch 498/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5289 - accuracy: 0.7788 - val_loss: 0.5103 - val_accuracy: 0.8148\n",
      "Epoch 499/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5329 - accuracy: 0.7788 - val_loss: 0.5068 - val_accuracy: 0.8148\n",
      "Epoch 500/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.5300 - accuracy: 0.7692 - val_loss: 0.4969 - val_accuracy: 0.7037\n",
      "Epoch 501/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5278 - accuracy: 0.7212 - val_loss: 0.4964 - val_accuracy: 0.7037\n",
      "Epoch 502/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5301 - accuracy: 0.7500 - val_loss: 0.4993 - val_accuracy: 0.7407\n",
      "Epoch 503/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5263 - accuracy: 0.7596 - val_loss: 0.4969 - val_accuracy: 0.7407\n",
      "Epoch 504/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5271 - accuracy: 0.7404 - val_loss: 0.4950 - val_accuracy: 0.7037\n",
      "Epoch 505/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5260 - accuracy: 0.7115 - val_loss: 0.4988 - val_accuracy: 0.7407\n",
      "Epoch 506/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5298 - accuracy: 0.7596 - val_loss: 0.5118 - val_accuracy: 0.8519\n",
      "Epoch 507/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5292 - accuracy: 0.7596 - val_loss: 0.4975 - val_accuracy: 0.7407\n",
      "Epoch 508/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5246 - accuracy: 0.7404 - val_loss: 0.4934 - val_accuracy: 0.7037\n",
      "Epoch 509/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.5274 - accuracy: 0.7019 - val_loss: 0.4933 - val_accuracy: 0.7037\n",
      "Epoch 510/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.5257 - accuracy: 0.7115 - val_loss: 0.4946 - val_accuracy: 0.7407\n",
      "Epoch 511/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.5242 - accuracy: 0.7596 - val_loss: 0.4991 - val_accuracy: 0.7778\n",
      "Epoch 512/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.5246 - accuracy: 0.7596 - val_loss: 0.5067 - val_accuracy: 0.8148\n",
      "Epoch 513/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.5286 - accuracy: 0.7692 - val_loss: 0.5060 - val_accuracy: 0.8148\n",
      "Epoch 514/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.5268 - accuracy: 0.7788 - val_loss: 0.5026 - val_accuracy: 0.8148\n",
      "Epoch 515/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5255 - accuracy: 0.7788 - val_loss: 0.4980 - val_accuracy: 0.7778\n",
      "Epoch 516/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5247 - accuracy: 0.7500 - val_loss: 0.4915 - val_accuracy: 0.7037\n",
      "Epoch 517/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.5253 - accuracy: 0.7212 - val_loss: 0.4929 - val_accuracy: 0.7407\n",
      "Epoch 518/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5223 - accuracy: 0.7500 - val_loss: 0.4925 - val_accuracy: 0.7407\n",
      "Epoch 519/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5220 - accuracy: 0.7500 - val_loss: 0.4931 - val_accuracy: 0.7407\n",
      "Epoch 520/2000\n",
      "104/104 [==============================] - 0s 212us/step - loss: 0.5201 - accuracy: 0.7596 - val_loss: 0.5004 - val_accuracy: 0.8148\n",
      "Epoch 521/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5245 - accuracy: 0.7596 - val_loss: 0.5067 - val_accuracy: 0.8519\n",
      "Epoch 522/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5254 - accuracy: 0.7885 - val_loss: 0.4965 - val_accuracy: 0.8148\n",
      "Epoch 523/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.5202 - accuracy: 0.7788 - val_loss: 0.4893 - val_accuracy: 0.7037\n",
      "Epoch 524/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5226 - accuracy: 0.7115 - val_loss: 0.4889 - val_accuracy: 0.7037\n",
      "Epoch 525/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5273 - accuracy: 0.6923 - val_loss: 0.4891 - val_accuracy: 0.7037\n",
      "Epoch 526/2000\n",
      "104/104 [==============================] - 0s 317us/step - loss: 0.5242 - accuracy: 0.7404 - val_loss: 0.4944 - val_accuracy: 0.8148\n",
      "Epoch 527/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5226 - accuracy: 0.7692 - val_loss: 0.5072 - val_accuracy: 0.8519\n",
      "Epoch 528/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5267 - accuracy: 0.7885 - val_loss: 0.5058 - val_accuracy: 0.8519\n",
      "Epoch 529/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5243 - accuracy: 0.7981 - val_loss: 0.4978 - val_accuracy: 0.8148\n",
      "Epoch 530/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5190 - accuracy: 0.7596 - val_loss: 0.4875 - val_accuracy: 0.7037\n",
      "Epoch 531/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5196 - accuracy: 0.7115 - val_loss: 0.4871 - val_accuracy: 0.7037\n",
      "Epoch 532/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5212 - accuracy: 0.7019 - val_loss: 0.4872 - val_accuracy: 0.7407\n",
      "Epoch 533/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5174 - accuracy: 0.7500 - val_loss: 0.4918 - val_accuracy: 0.8148\n",
      "Epoch 534/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5176 - accuracy: 0.7885 - val_loss: 0.4942 - val_accuracy: 0.8148\n",
      "Epoch 535/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5172 - accuracy: 0.7885 - val_loss: 0.4887 - val_accuracy: 0.7778\n",
      "Epoch 536/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5191 - accuracy: 0.7404 - val_loss: 0.4856 - val_accuracy: 0.7037\n",
      "Epoch 537/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5187 - accuracy: 0.7308 - val_loss: 0.4856 - val_accuracy: 0.7407\n",
      "Epoch 538/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5175 - accuracy: 0.7212 - val_loss: 0.4850 - val_accuracy: 0.7037\n",
      "Epoch 539/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5182 - accuracy: 0.7115 - val_loss: 0.4860 - val_accuracy: 0.7407\n",
      "Epoch 540/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5155 - accuracy: 0.7692 - val_loss: 0.4942 - val_accuracy: 0.8148\n",
      "Epoch 541/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5168 - accuracy: 0.7788 - val_loss: 0.5006 - val_accuracy: 0.8519\n",
      "Epoch 542/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5279 - accuracy: 0.7885 - val_loss: 0.5082 - val_accuracy: 0.8519\n",
      "Epoch 543/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5241 - accuracy: 0.7692 - val_loss: 0.4925 - val_accuracy: 0.8148\n",
      "Epoch 544/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5142 - accuracy: 0.7885 - val_loss: 0.4848 - val_accuracy: 0.7407\n",
      "Epoch 545/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5240 - accuracy: 0.7308 - val_loss: 0.4830 - val_accuracy: 0.7037\n",
      "Epoch 546/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5152 - accuracy: 0.7404 - val_loss: 0.4906 - val_accuracy: 0.8148\n",
      "Epoch 547/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5141 - accuracy: 0.7885 - val_loss: 0.4925 - val_accuracy: 0.8148\n",
      "Epoch 548/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5150 - accuracy: 0.7885 - val_loss: 0.4884 - val_accuracy: 0.8148\n",
      "Epoch 549/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5110 - accuracy: 0.7692 - val_loss: 0.4819 - val_accuracy: 0.7037\n",
      "Epoch 550/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 163us/step - loss: 0.5155 - accuracy: 0.7212 - val_loss: 0.4816 - val_accuracy: 0.7037\n",
      "Epoch 551/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5143 - accuracy: 0.7212 - val_loss: 0.4814 - val_accuracy: 0.7407\n",
      "Epoch 552/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5116 - accuracy: 0.7404 - val_loss: 0.4846 - val_accuracy: 0.7778\n",
      "Epoch 553/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5107 - accuracy: 0.7885 - val_loss: 0.4883 - val_accuracy: 0.8148\n",
      "Epoch 554/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5120 - accuracy: 0.7788 - val_loss: 0.4854 - val_accuracy: 0.8148\n",
      "Epoch 555/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5095 - accuracy: 0.7885 - val_loss: 0.4804 - val_accuracy: 0.7407\n",
      "Epoch 556/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5117 - accuracy: 0.7404 - val_loss: 0.4801 - val_accuracy: 0.7407\n",
      "Epoch 557/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.5118 - accuracy: 0.7212 - val_loss: 0.4807 - val_accuracy: 0.7407\n",
      "Epoch 558/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5093 - accuracy: 0.7788 - val_loss: 0.4905 - val_accuracy: 0.8148\n",
      "Epoch 559/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5141 - accuracy: 0.7596 - val_loss: 0.4900 - val_accuracy: 0.8148\n",
      "Epoch 560/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.5095 - accuracy: 0.7885 - val_loss: 0.4809 - val_accuracy: 0.7778\n",
      "Epoch 561/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5086 - accuracy: 0.7596 - val_loss: 0.4792 - val_accuracy: 0.7037\n",
      "Epoch 562/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5235 - accuracy: 0.6923 - val_loss: 0.4797 - val_accuracy: 0.7037\n",
      "Epoch 563/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5104 - accuracy: 0.7212 - val_loss: 0.4851 - val_accuracy: 0.8148\n",
      "Epoch 564/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 0.5131 - accuracy: 0.7788 - val_loss: 0.4921 - val_accuracy: 0.8519\n",
      "Epoch 565/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5102 - accuracy: 0.7788 - val_loss: 0.4799 - val_accuracy: 0.7778\n",
      "Epoch 566/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5075 - accuracy: 0.7596 - val_loss: 0.4774 - val_accuracy: 0.7407\n",
      "Epoch 567/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5068 - accuracy: 0.7500 - val_loss: 0.4808 - val_accuracy: 0.8148\n",
      "Epoch 568/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5058 - accuracy: 0.7981 - val_loss: 0.4869 - val_accuracy: 0.8148\n",
      "Epoch 569/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5084 - accuracy: 0.7981 - val_loss: 0.4826 - val_accuracy: 0.8148\n",
      "Epoch 570/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5052 - accuracy: 0.7885 - val_loss: 0.4768 - val_accuracy: 0.7407\n",
      "Epoch 571/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5055 - accuracy: 0.7596 - val_loss: 0.4758 - val_accuracy: 0.7037\n",
      "Epoch 572/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5087 - accuracy: 0.7212 - val_loss: 0.4756 - val_accuracy: 0.7407\n",
      "Epoch 573/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.71 - 0s 144us/step - loss: 0.5077 - accuracy: 0.7788 - val_loss: 0.4851 - val_accuracy: 0.8148\n",
      "Epoch 574/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5134 - accuracy: 0.7692 - val_loss: 0.4947 - val_accuracy: 0.8519\n",
      "Epoch 575/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.5130 - accuracy: 0.7981 - val_loss: 0.4876 - val_accuracy: 0.8519\n",
      "Epoch 576/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5071 - accuracy: 0.7788 - val_loss: 0.4793 - val_accuracy: 0.8148\n",
      "Epoch 577/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5036 - accuracy: 0.7885 - val_loss: 0.4751 - val_accuracy: 0.7778\n",
      "Epoch 578/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5041 - accuracy: 0.7596 - val_loss: 0.4741 - val_accuracy: 0.7407\n",
      "Epoch 579/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5047 - accuracy: 0.7596 - val_loss: 0.4752 - val_accuracy: 0.7778\n",
      "Epoch 580/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.5019 - accuracy: 0.7788 - val_loss: 0.4826 - val_accuracy: 0.8148\n",
      "Epoch 581/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5060 - accuracy: 0.7981 - val_loss: 0.4823 - val_accuracy: 0.8148\n",
      "Epoch 582/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5026 - accuracy: 0.7981 - val_loss: 0.4747 - val_accuracy: 0.7778\n",
      "Epoch 583/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5026 - accuracy: 0.7788 - val_loss: 0.4724 - val_accuracy: 0.7407\n",
      "Epoch 584/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5028 - accuracy: 0.7596 - val_loss: 0.4755 - val_accuracy: 0.8148\n",
      "Epoch 585/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5017 - accuracy: 0.7692 - val_loss: 0.5005 - val_accuracy: 0.8889\n",
      "Epoch 586/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5176 - accuracy: 0.7981 - val_loss: 0.4862 - val_accuracy: 0.8519\n",
      "Epoch 587/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4977 - accuracy: 0.7981 - val_loss: 0.4712 - val_accuracy: 0.7407\n",
      "Epoch 588/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.68 - 0s 106us/step - loss: 0.5047 - accuracy: 0.7019 - val_loss: 0.4790 - val_accuracy: 0.6667\n",
      "Epoch 589/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5218 - accuracy: 0.6731 - val_loss: 0.4752 - val_accuracy: 0.7037\n",
      "Epoch 590/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5123 - accuracy: 0.6923 - val_loss: 0.4705 - val_accuracy: 0.7407\n",
      "Epoch 591/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4995 - accuracy: 0.7692 - val_loss: 0.4839 - val_accuracy: 0.8519\n",
      "Epoch 592/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5120 - accuracy: 0.7981 - val_loss: 0.4882 - val_accuracy: 0.8519\n",
      "Epoch 593/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.5036 - accuracy: 0.7885 - val_loss: 0.4696 - val_accuracy: 0.7407\n",
      "Epoch 594/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5148 - accuracy: 0.7115 - val_loss: 0.4718 - val_accuracy: 0.7037\n",
      "Epoch 595/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5064 - accuracy: 0.7404 - val_loss: 0.4721 - val_accuracy: 0.8148\n",
      "Epoch 596/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4997 - accuracy: 0.7981 - val_loss: 0.4785 - val_accuracy: 0.8519\n",
      "Epoch 597/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5047 - accuracy: 0.7692 - val_loss: 0.4822 - val_accuracy: 0.8519\n",
      "Epoch 598/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4998 - accuracy: 0.7981 - val_loss: 0.4711 - val_accuracy: 0.8148\n",
      "Epoch 599/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4973 - accuracy: 0.7692 - val_loss: 0.4687 - val_accuracy: 0.7037\n",
      "Epoch 600/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.5021 - accuracy: 0.7212 - val_loss: 0.4677 - val_accuracy: 0.7407\n",
      "Epoch 601/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4968 - accuracy: 0.7788 - val_loss: 0.4770 - val_accuracy: 0.8519\n",
      "Epoch 602/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.5033 - accuracy: 0.7885 - val_loss: 0.4799 - val_accuracy: 0.8519\n",
      "Epoch 603/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4960 - accuracy: 0.7981 - val_loss: 0.4675 - val_accuracy: 0.7778\n",
      "Epoch 604/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.4970 - accuracy: 0.7788 - val_loss: 0.4664 - val_accuracy: 0.7407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 605/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.4992 - accuracy: 0.7596 - val_loss: 0.4664 - val_accuracy: 0.7778\n",
      "Epoch 606/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4963 - accuracy: 0.7692 - val_loss: 0.4659 - val_accuracy: 0.7407\n",
      "Epoch 607/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4959 - accuracy: 0.7596 - val_loss: 0.4671 - val_accuracy: 0.8148\n",
      "Epoch 608/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.5005 - accuracy: 0.7692 - val_loss: 0.4794 - val_accuracy: 0.8519\n",
      "Epoch 609/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4968 - accuracy: 0.7981 - val_loss: 0.4666 - val_accuracy: 0.8148\n",
      "Epoch 610/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4914 - accuracy: 0.7788 - val_loss: 0.4654 - val_accuracy: 0.7407\n",
      "Epoch 611/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4986 - accuracy: 0.7212 - val_loss: 0.4656 - val_accuracy: 0.7037\n",
      "Epoch 612/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4970 - accuracy: 0.7212 - val_loss: 0.4650 - val_accuracy: 0.7778\n",
      "Epoch 613/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4961 - accuracy: 0.7885 - val_loss: 0.4728 - val_accuracy: 0.8519\n",
      "Epoch 614/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4938 - accuracy: 0.7788 - val_loss: 0.4644 - val_accuracy: 0.7778\n",
      "Epoch 615/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4915 - accuracy: 0.7788 - val_loss: 0.4655 - val_accuracy: 0.7037\n",
      "Epoch 616/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5014 - accuracy: 0.7115 - val_loss: 0.4642 - val_accuracy: 0.7037\n",
      "Epoch 617/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4968 - accuracy: 0.7308 - val_loss: 0.4636 - val_accuracy: 0.7778\n",
      "Epoch 618/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4919 - accuracy: 0.7885 - val_loss: 0.4652 - val_accuracy: 0.8148\n",
      "Epoch 619/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4943 - accuracy: 0.7981 - val_loss: 0.4643 - val_accuracy: 0.8148\n",
      "Epoch 620/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4918 - accuracy: 0.7596 - val_loss: 0.4646 - val_accuracy: 0.7037\n",
      "Epoch 621/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.5038 - accuracy: 0.7019 - val_loss: 0.4672 - val_accuracy: 0.7037\n",
      "Epoch 622/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.5003 - accuracy: 0.7115 - val_loss: 0.4623 - val_accuracy: 0.8148\n",
      "Epoch 623/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4844 - accuracy: 0.7981 - val_loss: 0.4779 - val_accuracy: 0.8519\n",
      "Epoch 624/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4979 - accuracy: 0.8077 - val_loss: 0.4903 - val_accuracy: 0.9259\n",
      "Epoch 625/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4991 - accuracy: 0.8077 - val_loss: 0.4641 - val_accuracy: 0.8148\n",
      "Epoch 626/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4867 - accuracy: 0.7981 - val_loss: 0.4613 - val_accuracy: 0.7407\n",
      "Epoch 627/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4939 - accuracy: 0.7404 - val_loss: 0.4609 - val_accuracy: 0.7407\n",
      "Epoch 628/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4936 - accuracy: 0.7596 - val_loss: 0.4600 - val_accuracy: 0.7778\n",
      "Epoch 629/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4890 - accuracy: 0.7788 - val_loss: 0.4606 - val_accuracy: 0.8148\n",
      "Epoch 630/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4902 - accuracy: 0.7981 - val_loss: 0.4602 - val_accuracy: 0.8148\n",
      "Epoch 631/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4879 - accuracy: 0.7788 - val_loss: 0.4605 - val_accuracy: 0.7407\n",
      "Epoch 632/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4939 - accuracy: 0.7212 - val_loss: 0.4591 - val_accuracy: 0.7407\n",
      "Epoch 633/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4905 - accuracy: 0.7885 - val_loss: 0.4615 - val_accuracy: 0.8148\n",
      "Epoch 634/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4867 - accuracy: 0.7981 - val_loss: 0.4605 - val_accuracy: 0.8148\n",
      "Epoch 635/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4876 - accuracy: 0.7885 - val_loss: 0.4583 - val_accuracy: 0.7778\n",
      "Epoch 636/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4866 - accuracy: 0.7788 - val_loss: 0.4590 - val_accuracy: 0.8148\n",
      "Epoch 637/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4867 - accuracy: 0.7788 - val_loss: 0.4588 - val_accuracy: 0.8148\n",
      "Epoch 638/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4865 - accuracy: 0.7885 - val_loss: 0.4661 - val_accuracy: 0.8519\n",
      "Epoch 639/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4884 - accuracy: 0.8077 - val_loss: 0.4616 - val_accuracy: 0.8148\n",
      "Epoch 640/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4847 - accuracy: 0.7885 - val_loss: 0.4571 - val_accuracy: 0.7407\n",
      "Epoch 641/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4891 - accuracy: 0.7596 - val_loss: 0.4587 - val_accuracy: 0.7037\n",
      "Epoch 642/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4959 - accuracy: 0.7212 - val_loss: 0.4575 - val_accuracy: 0.7407\n",
      "Epoch 643/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4922 - accuracy: 0.7692 - val_loss: 0.4613 - val_accuracy: 0.8148\n",
      "Epoch 644/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4844 - accuracy: 0.7981 - val_loss: 0.4597 - val_accuracy: 0.8148\n",
      "Epoch 645/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4839 - accuracy: 0.7885 - val_loss: 0.4584 - val_accuracy: 0.8148\n",
      "Epoch 646/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4837 - accuracy: 0.7981 - val_loss: 0.4594 - val_accuracy: 0.8148\n",
      "Epoch 647/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4852 - accuracy: 0.7885 - val_loss: 0.4576 - val_accuracy: 0.8148\n",
      "Epoch 648/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.4814 - accuracy: 0.8173 - val_loss: 0.4662 - val_accuracy: 0.8519\n",
      "Epoch 649/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4865 - accuracy: 0.8077 - val_loss: 0.4618 - val_accuracy: 0.8519\n",
      "Epoch 650/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.4828 - accuracy: 0.8173 - val_loss: 0.4546 - val_accuracy: 0.8148\n",
      "Epoch 651/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4826 - accuracy: 0.7788 - val_loss: 0.4578 - val_accuracy: 0.7037\n",
      "Epoch 652/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4936 - accuracy: 0.7212 - val_loss: 0.4558 - val_accuracy: 0.7407\n",
      "Epoch 653/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4894 - accuracy: 0.7308 - val_loss: 0.4534 - val_accuracy: 0.7778\n",
      "Epoch 654/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4851 - accuracy: 0.7788 - val_loss: 0.4545 - val_accuracy: 0.8148\n",
      "Epoch 655/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4803 - accuracy: 0.7981 - val_loss: 0.4545 - val_accuracy: 0.8148\n",
      "Epoch 656/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4818 - accuracy: 0.7981 - val_loss: 0.4588 - val_accuracy: 0.8519\n",
      "Epoch 657/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4849 - accuracy: 0.8173 - val_loss: 0.4612 - val_accuracy: 0.8519\n",
      "Epoch 658/2000\n",
      "104/104 [==============================] - 0s 221us/step - loss: 0.4850 - accuracy: 0.7981 - val_loss: 0.4521 - val_accuracy: 0.7778\n",
      "Epoch 659/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4847 - accuracy: 0.7692 - val_loss: 0.4538 - val_accuracy: 0.7407\n",
      "Epoch 660/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 125us/step - loss: 0.4829 - accuracy: 0.7500 - val_loss: 0.4527 - val_accuracy: 0.8148\n",
      "Epoch 661/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4772 - accuracy: 0.7981 - val_loss: 0.4653 - val_accuracy: 0.8519\n",
      "Epoch 662/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.4845 - accuracy: 0.8077 - val_loss: 0.4602 - val_accuracy: 0.8519\n",
      "Epoch 663/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.4800 - accuracy: 0.8173 - val_loss: 0.4517 - val_accuracy: 0.8148\n",
      "Epoch 664/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4822 - accuracy: 0.7885 - val_loss: 0.4513 - val_accuracy: 0.7407\n",
      "Epoch 665/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4821 - accuracy: 0.7596 - val_loss: 0.4506 - val_accuracy: 0.8148\n",
      "Epoch 666/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4847 - accuracy: 0.7981 - val_loss: 0.4576 - val_accuracy: 0.8519\n",
      "Epoch 667/2000\n",
      "104/104 [==============================] - 0s 240us/step - loss: 0.4764 - accuracy: 0.8173 - val_loss: 0.4497 - val_accuracy: 0.8148\n",
      "Epoch 668/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4818 - accuracy: 0.7885 - val_loss: 0.4496 - val_accuracy: 0.7778\n",
      "Epoch 669/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4823 - accuracy: 0.7788 - val_loss: 0.4532 - val_accuracy: 0.8148\n",
      "Epoch 670/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4764 - accuracy: 0.7981 - val_loss: 0.4503 - val_accuracy: 0.8148\n",
      "Epoch 671/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4760 - accuracy: 0.7885 - val_loss: 0.4485 - val_accuracy: 0.8148\n",
      "Epoch 672/2000\n",
      "104/104 [==============================] - 0s 356us/step - loss: 0.4768 - accuracy: 0.7885 - val_loss: 0.4481 - val_accuracy: 0.7778\n",
      "Epoch 673/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4782 - accuracy: 0.7788 - val_loss: 0.4493 - val_accuracy: 0.8148\n",
      "Epoch 674/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.4749 - accuracy: 0.7981 - val_loss: 0.4480 - val_accuracy: 0.8148\n",
      "Epoch 675/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4748 - accuracy: 0.7885 - val_loss: 0.4472 - val_accuracy: 0.7778\n",
      "Epoch 676/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4764 - accuracy: 0.7788 - val_loss: 0.4470 - val_accuracy: 0.8148\n",
      "Epoch 677/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4747 - accuracy: 0.7885 - val_loss: 0.4479 - val_accuracy: 0.8148\n",
      "Epoch 678/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4789 - accuracy: 0.7981 - val_loss: 0.4468 - val_accuracy: 0.8148\n",
      "Epoch 679/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4813 - accuracy: 0.7788 - val_loss: 0.4584 - val_accuracy: 0.8519\n",
      "Epoch 680/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4781 - accuracy: 0.8077 - val_loss: 0.4487 - val_accuracy: 0.8148\n",
      "Epoch 681/2000\n",
      "104/104 [==============================] - 0s 212us/step - loss: 0.4738 - accuracy: 0.8077 - val_loss: 0.4474 - val_accuracy: 0.8148\n",
      "Epoch 682/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4719 - accuracy: 0.7885 - val_loss: 0.4457 - val_accuracy: 0.7778\n",
      "Epoch 683/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4802 - accuracy: 0.7596 - val_loss: 0.4452 - val_accuracy: 0.7778\n",
      "Epoch 684/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4722 - accuracy: 0.7885 - val_loss: 0.4531 - val_accuracy: 0.8519\n",
      "Epoch 685/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4756 - accuracy: 0.8077 - val_loss: 0.4488 - val_accuracy: 0.8519\n",
      "Epoch 686/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4705 - accuracy: 0.7981 - val_loss: 0.4443 - val_accuracy: 0.8148\n",
      "Epoch 687/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4749 - accuracy: 0.7788 - val_loss: 0.4442 - val_accuracy: 0.7778\n",
      "Epoch 688/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4782 - accuracy: 0.7788 - val_loss: 0.4481 - val_accuracy: 0.8519\n",
      "Epoch 689/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4713 - accuracy: 0.8077 - val_loss: 0.4445 - val_accuracy: 0.8148\n",
      "Epoch 690/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4748 - accuracy: 0.7981 - val_loss: 0.4435 - val_accuracy: 0.7778\n",
      "Epoch 691/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4755 - accuracy: 0.7885 - val_loss: 0.4437 - val_accuracy: 0.8148\n",
      "Epoch 692/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4697 - accuracy: 0.8077 - val_loss: 0.4429 - val_accuracy: 0.7778\n",
      "Epoch 693/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4773 - accuracy: 0.7596 - val_loss: 0.4478 - val_accuracy: 0.7407\n",
      "Epoch 694/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4811 - accuracy: 0.7500 - val_loss: 0.4423 - val_accuracy: 0.8148\n",
      "Epoch 695/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4709 - accuracy: 0.7981 - val_loss: 0.4447 - val_accuracy: 0.8148\n",
      "Epoch 696/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4739 - accuracy: 0.7981 - val_loss: 0.4549 - val_accuracy: 0.8519\n",
      "Epoch 697/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4729 - accuracy: 0.8077 - val_loss: 0.4426 - val_accuracy: 0.8148\n",
      "Epoch 698/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.4405 - accuracy: 0.90 - 0s 135us/step - loss: 0.4715 - accuracy: 0.8077 - val_loss: 0.4412 - val_accuracy: 0.8148\n",
      "Epoch 699/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4694 - accuracy: 0.7981 - val_loss: 0.4557 - val_accuracy: 0.8519\n",
      "Epoch 700/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4780 - accuracy: 0.8077 - val_loss: 0.4581 - val_accuracy: 0.8889\n",
      "Epoch 701/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4710 - accuracy: 0.8077 - val_loss: 0.4404 - val_accuracy: 0.8148\n",
      "Epoch 702/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4690 - accuracy: 0.7981 - val_loss: 0.4418 - val_accuracy: 0.7778\n",
      "Epoch 703/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4739 - accuracy: 0.7788 - val_loss: 0.4407 - val_accuracy: 0.7778\n",
      "Epoch 704/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4729 - accuracy: 0.7788 - val_loss: 0.4400 - val_accuracy: 0.7778\n",
      "Epoch 705/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4697 - accuracy: 0.7885 - val_loss: 0.4395 - val_accuracy: 0.8148\n",
      "Epoch 706/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4667 - accuracy: 0.7981 - val_loss: 0.4394 - val_accuracy: 0.8148\n",
      "Epoch 707/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4685 - accuracy: 0.7885 - val_loss: 0.4389 - val_accuracy: 0.8148\n",
      "Epoch 708/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4668 - accuracy: 0.7885 - val_loss: 0.4392 - val_accuracy: 0.8148\n",
      "Epoch 709/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4646 - accuracy: 0.7885 - val_loss: 0.4437 - val_accuracy: 0.8519\n",
      "Epoch 710/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4658 - accuracy: 0.8173 - val_loss: 0.4475 - val_accuracy: 0.8519\n",
      "Epoch 711/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4680 - accuracy: 0.8173 - val_loss: 0.4424 - val_accuracy: 0.8519\n",
      "Epoch 712/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4639 - accuracy: 0.8077 - val_loss: 0.4377 - val_accuracy: 0.8148\n",
      "Epoch 713/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4667 - accuracy: 0.7981 - val_loss: 0.4403 - val_accuracy: 0.7778\n",
      "Epoch 714/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4729 - accuracy: 0.7692 - val_loss: 0.4398 - val_accuracy: 0.7778\n",
      "Epoch 715/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 135us/step - loss: 0.4695 - accuracy: 0.7885 - val_loss: 0.4383 - val_accuracy: 0.8148\n",
      "Epoch 716/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4629 - accuracy: 0.7981 - val_loss: 0.4470 - val_accuracy: 0.8519\n",
      "Epoch 717/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4701 - accuracy: 0.7981 - val_loss: 0.4491 - val_accuracy: 0.8519\n",
      "Epoch 718/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4664 - accuracy: 0.8077 - val_loss: 0.4373 - val_accuracy: 0.8148\n",
      "Epoch 719/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4645 - accuracy: 0.8077 - val_loss: 0.4384 - val_accuracy: 0.7778\n",
      "Epoch 720/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4701 - accuracy: 0.7788 - val_loss: 0.4369 - val_accuracy: 0.7778\n",
      "Epoch 721/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4649 - accuracy: 0.7788 - val_loss: 0.4361 - val_accuracy: 0.8148\n",
      "Epoch 722/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4626 - accuracy: 0.8077 - val_loss: 0.4552 - val_accuracy: 0.9259\n",
      "Epoch 723/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.4717 - accuracy: 0.8173 - val_loss: 0.4424 - val_accuracy: 0.8519\n",
      "Epoch 724/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4626 - accuracy: 0.8269 - val_loss: 0.4360 - val_accuracy: 0.8148\n",
      "Epoch 725/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.4605 - accuracy: 0.7981 - val_loss: 0.4343 - val_accuracy: 0.8148\n",
      "Epoch 726/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4611 - accuracy: 0.8077 - val_loss: 0.4345 - val_accuracy: 0.8148\n",
      "Epoch 727/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4859 - accuracy: 0.7500 - val_loss: 0.4390 - val_accuracy: 0.7407\n",
      "Epoch 728/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4609 - accuracy: 0.7788 - val_loss: 0.4407 - val_accuracy: 0.8519\n",
      "Epoch 729/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4692 - accuracy: 0.8173 - val_loss: 0.4639 - val_accuracy: 0.9259\n",
      "Epoch 730/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4771 - accuracy: 0.8269 - val_loss: 0.4421 - val_accuracy: 0.8519\n",
      "Epoch 731/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.4654 - accuracy: 0.7981 - val_loss: 0.4366 - val_accuracy: 0.7778\n",
      "Epoch 732/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4699 - accuracy: 0.7788 - val_loss: 0.4352 - val_accuracy: 0.7778\n",
      "Epoch 733/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.4641 - accuracy: 0.7788 - val_loss: 0.4322 - val_accuracy: 0.8148\n",
      "Epoch 734/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4578 - accuracy: 0.8365 - val_loss: 0.4400 - val_accuracy: 0.8519\n",
      "Epoch 735/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4662 - accuracy: 0.7981 - val_loss: 0.4424 - val_accuracy: 0.8519\n",
      "Epoch 736/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4554 - accuracy: 0.8077 - val_loss: 0.4330 - val_accuracy: 0.7778\n",
      "Epoch 737/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4784 - accuracy: 0.7308 - val_loss: 0.4408 - val_accuracy: 0.7407\n",
      "Epoch 738/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4692 - accuracy: 0.7596 - val_loss: 0.4343 - val_accuracy: 0.8519\n",
      "Epoch 739/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4583 - accuracy: 0.7885 - val_loss: 0.4508 - val_accuracy: 0.9259\n",
      "Epoch 740/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4675 - accuracy: 0.8173 - val_loss: 0.4377 - val_accuracy: 0.8519\n",
      "Epoch 741/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4572 - accuracy: 0.8173 - val_loss: 0.4302 - val_accuracy: 0.8148\n",
      "Epoch 742/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4577 - accuracy: 0.7981 - val_loss: 0.4302 - val_accuracy: 0.8148\n",
      "Epoch 743/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4584 - accuracy: 0.7981 - val_loss: 0.4297 - val_accuracy: 0.8148\n",
      "Epoch 744/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4598 - accuracy: 0.8077 - val_loss: 0.4387 - val_accuracy: 0.8519\n",
      "Epoch 745/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4594 - accuracy: 0.8077 - val_loss: 0.4355 - val_accuracy: 0.8519\n",
      "Epoch 746/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4577 - accuracy: 0.8173 - val_loss: 0.4317 - val_accuracy: 0.8519\n",
      "Epoch 747/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4557 - accuracy: 0.8173 - val_loss: 0.4340 - val_accuracy: 0.8519\n",
      "Epoch 748/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4574 - accuracy: 0.8077 - val_loss: 0.4335 - val_accuracy: 0.8519\n",
      "Epoch 749/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4556 - accuracy: 0.8173 - val_loss: 0.4295 - val_accuracy: 0.8519\n",
      "Epoch 750/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4554 - accuracy: 0.8173 - val_loss: 0.4279 - val_accuracy: 0.8148\n",
      "Epoch 751/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4552 - accuracy: 0.8173 - val_loss: 0.4280 - val_accuracy: 0.8148\n",
      "Epoch 752/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4543 - accuracy: 0.7981 - val_loss: 0.4275 - val_accuracy: 0.8148\n",
      "Epoch 753/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4554 - accuracy: 0.7981 - val_loss: 0.4270 - val_accuracy: 0.8148\n",
      "Epoch 754/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4675 - accuracy: 0.7788 - val_loss: 0.4306 - val_accuracy: 0.7778\n",
      "Epoch 755/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4590 - accuracy: 0.7885 - val_loss: 0.4305 - val_accuracy: 0.8519\n",
      "Epoch 756/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4539 - accuracy: 0.8077 - val_loss: 0.4344 - val_accuracy: 0.8519\n",
      "Epoch 757/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4560 - accuracy: 0.8173 - val_loss: 0.4274 - val_accuracy: 0.8519\n",
      "Epoch 758/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4629 - accuracy: 0.8173 - val_loss: 0.4270 - val_accuracy: 0.8148\n",
      "Epoch 759/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4522 - accuracy: 0.7885 - val_loss: 0.4297 - val_accuracy: 0.8519\n",
      "Epoch 760/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.4567 - accuracy: 0.8173 - val_loss: 0.4418 - val_accuracy: 0.9259\n",
      "Epoch 761/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.4582 - accuracy: 0.8269 - val_loss: 0.4252 - val_accuracy: 0.8148\n",
      "Epoch 762/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4512 - accuracy: 0.7885 - val_loss: 0.4254 - val_accuracy: 0.8148\n",
      "Epoch 763/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4517 - accuracy: 0.8077 - val_loss: 0.4256 - val_accuracy: 0.8519\n",
      "Epoch 764/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4525 - accuracy: 0.8365 - val_loss: 0.4321 - val_accuracy: 0.8519\n",
      "Epoch 765/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4493 - accuracy: 0.8173 - val_loss: 0.4240 - val_accuracy: 0.8148\n",
      "Epoch 766/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4574 - accuracy: 0.7981 - val_loss: 0.4270 - val_accuracy: 0.7778\n",
      "Epoch 767/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4532 - accuracy: 0.7981 - val_loss: 0.4257 - val_accuracy: 0.8519\n",
      "Epoch 768/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4494 - accuracy: 0.8269 - val_loss: 0.4314 - val_accuracy: 0.8519\n",
      "Epoch 769/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4535 - accuracy: 0.8077 - val_loss: 0.4236 - val_accuracy: 0.8148\n",
      "Epoch 770/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 173us/step - loss: 0.4530 - accuracy: 0.7885 - val_loss: 0.4233 - val_accuracy: 0.8148\n",
      "Epoch 771/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4515 - accuracy: 0.8077 - val_loss: 0.4292 - val_accuracy: 0.8519\n",
      "Epoch 772/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4565 - accuracy: 0.7981 - val_loss: 0.4283 - val_accuracy: 0.8519\n",
      "Epoch 773/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4454 - accuracy: 0.7981 - val_loss: 0.4272 - val_accuracy: 0.7778\n",
      "Epoch 774/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4880 - accuracy: 0.7308 - val_loss: 0.4459 - val_accuracy: 0.7037\n",
      "Epoch 775/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4750 - accuracy: 0.7308 - val_loss: 0.4220 - val_accuracy: 0.8148\n",
      "Epoch 776/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4548 - accuracy: 0.8173 - val_loss: 0.4290 - val_accuracy: 0.8519\n",
      "Epoch 777/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4466 - accuracy: 0.8077 - val_loss: 0.4210 - val_accuracy: 0.8148\n",
      "Epoch 778/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4538 - accuracy: 0.7596 - val_loss: 0.4325 - val_accuracy: 0.7407\n",
      "Epoch 779/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4604 - accuracy: 0.7596 - val_loss: 0.4205 - val_accuracy: 0.8148\n",
      "Epoch 780/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4393 - accuracy: 0.8462 - val_loss: 0.4368 - val_accuracy: 0.9259\n",
      "Epoch 781/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4650 - accuracy: 0.8365 - val_loss: 0.4472 - val_accuracy: 0.9259\n",
      "Epoch 782/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4521 - accuracy: 0.8365 - val_loss: 0.4197 - val_accuracy: 0.8148\n",
      "Epoch 783/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4541 - accuracy: 0.7788 - val_loss: 0.4393 - val_accuracy: 0.7037\n",
      "Epoch 784/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4764 - accuracy: 0.7115 - val_loss: 0.4290 - val_accuracy: 0.7407\n",
      "Epoch 785/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4550 - accuracy: 0.7981 - val_loss: 0.4206 - val_accuracy: 0.8519\n",
      "Epoch 786/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4471 - accuracy: 0.8077 - val_loss: 0.4343 - val_accuracy: 0.9259\n",
      "Epoch 787/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4512 - accuracy: 0.8173 - val_loss: 0.4197 - val_accuracy: 0.8519\n",
      "Epoch 788/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4466 - accuracy: 0.8365 - val_loss: 0.4196 - val_accuracy: 0.8148\n",
      "Epoch 789/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4486 - accuracy: 0.7981 - val_loss: 0.4186 - val_accuracy: 0.8148\n",
      "Epoch 790/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4459 - accuracy: 0.8173 - val_loss: 0.4198 - val_accuracy: 0.8519\n",
      "Epoch 791/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4435 - accuracy: 0.8173 - val_loss: 0.4196 - val_accuracy: 0.8519\n",
      "Epoch 792/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4448 - accuracy: 0.8173 - val_loss: 0.4203 - val_accuracy: 0.8519\n",
      "Epoch 793/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4490 - accuracy: 0.8173 - val_loss: 0.4376 - val_accuracy: 0.9259\n",
      "Epoch 794/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4603 - accuracy: 0.8173 - val_loss: 0.4303 - val_accuracy: 0.9259\n",
      "Epoch 795/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4545 - accuracy: 0.8077 - val_loss: 0.4170 - val_accuracy: 0.8148\n",
      "Epoch 796/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4433 - accuracy: 0.7981 - val_loss: 0.4171 - val_accuracy: 0.8519\n",
      "Epoch 797/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4415 - accuracy: 0.8462 - val_loss: 0.4168 - val_accuracy: 0.8519\n",
      "Epoch 798/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4424 - accuracy: 0.8269 - val_loss: 0.4167 - val_accuracy: 0.8519\n",
      "Epoch 799/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4402 - accuracy: 0.8269 - val_loss: 0.4243 - val_accuracy: 0.8519\n",
      "Epoch 800/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.4484 - accuracy: 0.8173 - val_loss: 0.4224 - val_accuracy: 0.8519\n",
      "Epoch 801/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4423 - accuracy: 0.8269 - val_loss: 0.4152 - val_accuracy: 0.8148\n",
      "Epoch 802/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4454 - accuracy: 0.7885 - val_loss: 0.4223 - val_accuracy: 0.7778\n",
      "Epoch 803/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4514 - accuracy: 0.7788 - val_loss: 0.4152 - val_accuracy: 0.8148\n",
      "Epoch 804/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4451 - accuracy: 0.8173 - val_loss: 0.4265 - val_accuracy: 0.9259\n",
      "Epoch 805/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4462 - accuracy: 0.8077 - val_loss: 0.4210 - val_accuracy: 0.8519\n",
      "Epoch 806/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4429 - accuracy: 0.8077 - val_loss: 0.4161 - val_accuracy: 0.8519\n",
      "Epoch 807/2000\n",
      "104/104 [==============================] - 0s 221us/step - loss: 0.4393 - accuracy: 0.8269 - val_loss: 0.4144 - val_accuracy: 0.8519\n",
      "Epoch 808/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4388 - accuracy: 0.8365 - val_loss: 0.4140 - val_accuracy: 0.8519\n",
      "Epoch 809/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4388 - accuracy: 0.8269 - val_loss: 0.4134 - val_accuracy: 0.8519\n",
      "Epoch 810/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4385 - accuracy: 0.8269 - val_loss: 0.4130 - val_accuracy: 0.8148\n",
      "Epoch 811/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4408 - accuracy: 0.7981 - val_loss: 0.4131 - val_accuracy: 0.8148\n",
      "Epoch 812/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.4392 - accuracy: 0.8173 - val_loss: 0.4126 - val_accuracy: 0.8519\n",
      "Epoch 813/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4454 - accuracy: 0.8077 - val_loss: 0.4143 - val_accuracy: 0.8519\n",
      "Epoch 814/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4353 - accuracy: 0.8365 - val_loss: 0.4130 - val_accuracy: 0.8148\n",
      "Epoch 815/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4418 - accuracy: 0.8077 - val_loss: 0.4131 - val_accuracy: 0.8148\n",
      "Epoch 816/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4408 - accuracy: 0.7981 - val_loss: 0.4118 - val_accuracy: 0.8148\n",
      "Epoch 817/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4401 - accuracy: 0.8269 - val_loss: 0.4124 - val_accuracy: 0.8519\n",
      "Epoch 818/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4367 - accuracy: 0.8269 - val_loss: 0.4116 - val_accuracy: 0.8519\n",
      "Epoch 819/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4372 - accuracy: 0.8173 - val_loss: 0.4107 - val_accuracy: 0.8148\n",
      "Epoch 820/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4363 - accuracy: 0.8077 - val_loss: 0.4125 - val_accuracy: 0.8519\n",
      "Epoch 821/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.4366 - accuracy: 0.7981 - val_loss: 0.4217 - val_accuracy: 0.9259\n",
      "Epoch 822/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4486 - accuracy: 0.8269 - val_loss: 0.4233 - val_accuracy: 0.9259\n",
      "Epoch 823/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4399 - accuracy: 0.8269 - val_loss: 0.4122 - val_accuracy: 0.8148\n",
      "Epoch 824/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4461 - accuracy: 0.7885 - val_loss: 0.4139 - val_accuracy: 0.8148\n",
      "Epoch 825/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 135us/step - loss: 0.4366 - accuracy: 0.8173 - val_loss: 0.4157 - val_accuracy: 0.8519\n",
      "Epoch 826/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4436 - accuracy: 0.8173 - val_loss: 0.4253 - val_accuracy: 0.9259\n",
      "Epoch 827/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.4424 - accuracy: 0.8365 - val_loss: 0.4112 - val_accuracy: 0.8519\n",
      "Epoch 828/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4289 - accuracy: 0.8269 - val_loss: 0.4136 - val_accuracy: 0.8148\n",
      "Epoch 829/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4430 - accuracy: 0.7788 - val_loss: 0.4125 - val_accuracy: 0.8148\n",
      "Epoch 830/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4385 - accuracy: 0.7981 - val_loss: 0.4084 - val_accuracy: 0.8519\n",
      "Epoch 831/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4329 - accuracy: 0.8269 - val_loss: 0.4164 - val_accuracy: 0.8889\n",
      "Epoch 832/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4386 - accuracy: 0.8077 - val_loss: 0.4078 - val_accuracy: 0.8519\n",
      "Epoch 833/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4323 - accuracy: 0.8269 - val_loss: 0.4084 - val_accuracy: 0.8148\n",
      "Epoch 834/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4357 - accuracy: 0.8173 - val_loss: 0.4091 - val_accuracy: 0.8148\n",
      "Epoch 835/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4347 - accuracy: 0.8173 - val_loss: 0.4075 - val_accuracy: 0.8519\n",
      "Epoch 836/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.4429 - accuracy: 0.8077 - val_loss: 0.4199 - val_accuracy: 0.9259\n",
      "Epoch 837/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4346 - accuracy: 0.8269 - val_loss: 0.4066 - val_accuracy: 0.8148\n",
      "Epoch 838/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4380 - accuracy: 0.7981 - val_loss: 0.4252 - val_accuracy: 0.7407\n",
      "Epoch 839/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4570 - accuracy: 0.7500 - val_loss: 0.4100 - val_accuracy: 0.8148\n",
      "Epoch 840/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4399 - accuracy: 0.7788 - val_loss: 0.4196 - val_accuracy: 0.9259\n",
      "Epoch 841/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4402 - accuracy: 0.8365 - val_loss: 0.4119 - val_accuracy: 0.8519\n",
      "Epoch 842/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4296 - accuracy: 0.8173 - val_loss: 0.4090 - val_accuracy: 0.8148\n",
      "Epoch 843/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4389 - accuracy: 0.7981 - val_loss: 0.4098 - val_accuracy: 0.8148\n",
      "Epoch 844/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4332 - accuracy: 0.8173 - val_loss: 0.4066 - val_accuracy: 0.8519\n",
      "Epoch 845/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4337 - accuracy: 0.8269 - val_loss: 0.4233 - val_accuracy: 0.9259\n",
      "Epoch 846/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4383 - accuracy: 0.8077 - val_loss: 0.4056 - val_accuracy: 0.8519\n",
      "Epoch 847/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4342 - accuracy: 0.7981 - val_loss: 0.4134 - val_accuracy: 0.7778\n",
      "Epoch 848/2000\n",
      "104/104 [==============================] - 0s 221us/step - loss: 0.4426 - accuracy: 0.7788 - val_loss: 0.4055 - val_accuracy: 0.8148\n",
      "Epoch 849/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4311 - accuracy: 0.8558 - val_loss: 0.4124 - val_accuracy: 0.8889\n",
      "Epoch 850/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4351 - accuracy: 0.8269 - val_loss: 0.4120 - val_accuracy: 0.8889\n",
      "Epoch 851/2000\n",
      "104/104 [==============================] - 0s 279us/step - loss: 0.4312 - accuracy: 0.8173 - val_loss: 0.4038 - val_accuracy: 0.8519\n",
      "Epoch 852/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4318 - accuracy: 0.8365 - val_loss: 0.4036 - val_accuracy: 0.8148\n",
      "Epoch 853/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.4310 - accuracy: 0.7981 - val_loss: 0.4082 - val_accuracy: 0.8519\n",
      "Epoch 854/2000\n",
      "104/104 [==============================] - 0s 221us/step - loss: 0.4304 - accuracy: 0.8077 - val_loss: 0.4047 - val_accuracy: 0.8519\n",
      "Epoch 855/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4279 - accuracy: 0.8269 - val_loss: 0.4032 - val_accuracy: 0.8519\n",
      "Epoch 856/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4290 - accuracy: 0.8269 - val_loss: 0.4023 - val_accuracy: 0.8148\n",
      "Epoch 857/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4271 - accuracy: 0.8462 - val_loss: 0.4044 - val_accuracy: 0.8519\n",
      "Epoch 858/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4284 - accuracy: 0.8077 - val_loss: 0.4134 - val_accuracy: 0.9259\n",
      "Epoch 859/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4334 - accuracy: 0.8173 - val_loss: 0.4046 - val_accuracy: 0.8519\n",
      "Epoch 860/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4264 - accuracy: 0.8365 - val_loss: 0.4015 - val_accuracy: 0.8148\n",
      "Epoch 861/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4287 - accuracy: 0.8077 - val_loss: 0.4012 - val_accuracy: 0.8148\n",
      "Epoch 862/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4250 - accuracy: 0.8269 - val_loss: 0.4045 - val_accuracy: 0.8519\n",
      "Epoch 863/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4300 - accuracy: 0.8077 - val_loss: 0.4055 - val_accuracy: 0.8519\n",
      "Epoch 864/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4286 - accuracy: 0.8077 - val_loss: 0.4007 - val_accuracy: 0.8519\n",
      "Epoch 865/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4254 - accuracy: 0.8462 - val_loss: 0.4002 - val_accuracy: 0.8519\n",
      "Epoch 866/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4280 - accuracy: 0.8269 - val_loss: 0.4000 - val_accuracy: 0.8519\n",
      "Epoch 867/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4251 - accuracy: 0.8269 - val_loss: 0.4016 - val_accuracy: 0.8519\n",
      "Epoch 868/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4259 - accuracy: 0.8269 - val_loss: 0.4002 - val_accuracy: 0.8519\n",
      "Epoch 869/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4242 - accuracy: 0.8269 - val_loss: 0.3995 - val_accuracy: 0.8519\n",
      "Epoch 870/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4243 - accuracy: 0.8173 - val_loss: 0.3995 - val_accuracy: 0.8148\n",
      "Epoch 871/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4322 - accuracy: 0.7885 - val_loss: 0.4072 - val_accuracy: 0.8148\n",
      "Epoch 872/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4323 - accuracy: 0.8077 - val_loss: 0.3987 - val_accuracy: 0.8148\n",
      "Epoch 873/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4212 - accuracy: 0.8365 - val_loss: 0.4068 - val_accuracy: 0.9259\n",
      "Epoch 874/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4298 - accuracy: 0.8173 - val_loss: 0.4055 - val_accuracy: 0.8889\n",
      "Epoch 875/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4248 - accuracy: 0.8077 - val_loss: 0.3980 - val_accuracy: 0.8519\n",
      "Epoch 876/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4299 - accuracy: 0.8462 - val_loss: 0.4065 - val_accuracy: 0.8148\n",
      "Epoch 877/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.4277 - accuracy: 0.8173 - val_loss: 0.3988 - val_accuracy: 0.8519\n",
      "Epoch 878/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4387 - accuracy: 0.8077 - val_loss: 0.4234 - val_accuracy: 0.9259\n",
      "Epoch 879/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4313 - accuracy: 0.8269 - val_loss: 0.3973 - val_accuracy: 0.8148\n",
      "Epoch 880/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 96us/step - loss: 0.4348 - accuracy: 0.7885 - val_loss: 0.4054 - val_accuracy: 0.8148\n",
      "Epoch 881/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4293 - accuracy: 0.8077 - val_loss: 0.3967 - val_accuracy: 0.8519\n",
      "Epoch 882/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4224 - accuracy: 0.8558 - val_loss: 0.3980 - val_accuracy: 0.8519\n",
      "Epoch 883/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4221 - accuracy: 0.8462 - val_loss: 0.3977 - val_accuracy: 0.8148\n",
      "Epoch 884/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4285 - accuracy: 0.7885 - val_loss: 0.4016 - val_accuracy: 0.8148\n",
      "Epoch 885/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4275 - accuracy: 0.8077 - val_loss: 0.3959 - val_accuracy: 0.8519\n",
      "Epoch 886/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4224 - accuracy: 0.8269 - val_loss: 0.3982 - val_accuracy: 0.8519\n",
      "Epoch 887/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4244 - accuracy: 0.8077 - val_loss: 0.3985 - val_accuracy: 0.8519\n",
      "Epoch 888/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4339 - accuracy: 0.7981 - val_loss: 0.3969 - val_accuracy: 0.8148\n",
      "Epoch 889/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.4312 - accuracy: 0.8365 - val_loss: 0.3973 - val_accuracy: 0.8519\n",
      "Epoch 890/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4207 - accuracy: 0.8462 - val_loss: 0.3958 - val_accuracy: 0.8148\n",
      "Epoch 891/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4222 - accuracy: 0.8173 - val_loss: 0.3947 - val_accuracy: 0.8148\n",
      "Epoch 892/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4213 - accuracy: 0.8173 - val_loss: 0.3957 - val_accuracy: 0.8148\n",
      "Epoch 893/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4220 - accuracy: 0.8173 - val_loss: 0.3952 - val_accuracy: 0.8148\n",
      "Epoch 894/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4237 - accuracy: 0.7981 - val_loss: 0.3939 - val_accuracy: 0.8519\n",
      "Epoch 895/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4193 - accuracy: 0.8365 - val_loss: 0.4006 - val_accuracy: 0.9259\n",
      "Epoch 896/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4213 - accuracy: 0.8173 - val_loss: 0.3940 - val_accuracy: 0.8519\n",
      "Epoch 897/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4210 - accuracy: 0.8269 - val_loss: 0.3964 - val_accuracy: 0.8148\n",
      "Epoch 898/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4216 - accuracy: 0.8173 - val_loss: 0.3930 - val_accuracy: 0.8519\n",
      "Epoch 899/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4182 - accuracy: 0.8365 - val_loss: 0.3965 - val_accuracy: 0.8519\n",
      "Epoch 900/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4187 - accuracy: 0.8077 - val_loss: 0.3930 - val_accuracy: 0.8519\n",
      "Epoch 901/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4181 - accuracy: 0.8173 - val_loss: 0.3935 - val_accuracy: 0.8519\n",
      "Epoch 902/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4191 - accuracy: 0.8269 - val_loss: 0.3970 - val_accuracy: 0.8889\n",
      "Epoch 903/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4176 - accuracy: 0.8365 - val_loss: 0.3926 - val_accuracy: 0.8148\n",
      "Epoch 904/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4195 - accuracy: 0.8173 - val_loss: 0.3933 - val_accuracy: 0.8148\n",
      "Epoch 905/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4174 - accuracy: 0.8269 - val_loss: 0.3921 - val_accuracy: 0.8519\n",
      "Epoch 906/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4198 - accuracy: 0.8077 - val_loss: 0.3937 - val_accuracy: 0.8519\n",
      "Epoch 907/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4152 - accuracy: 0.8077 - val_loss: 0.3927 - val_accuracy: 0.8148\n",
      "Epoch 908/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4188 - accuracy: 0.7981 - val_loss: 0.3911 - val_accuracy: 0.8519\n",
      "Epoch 909/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4147 - accuracy: 0.8558 - val_loss: 0.3926 - val_accuracy: 0.8519\n",
      "Epoch 910/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4178 - accuracy: 0.8077 - val_loss: 0.3913 - val_accuracy: 0.8519\n",
      "Epoch 911/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4189 - accuracy: 0.8173 - val_loss: 0.3931 - val_accuracy: 0.8148\n",
      "Epoch 912/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4236 - accuracy: 0.8173 - val_loss: 0.3900 - val_accuracy: 0.8519\n",
      "Epoch 913/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4170 - accuracy: 0.8269 - val_loss: 0.3899 - val_accuracy: 0.8519\n",
      "Epoch 914/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4139 - accuracy: 0.8462 - val_loss: 0.3912 - val_accuracy: 0.8148\n",
      "Epoch 915/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.4191 - accuracy: 0.8269 - val_loss: 0.3971 - val_accuracy: 0.8148\n",
      "Epoch 916/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4254 - accuracy: 0.7981 - val_loss: 0.3901 - val_accuracy: 0.8148\n",
      "Epoch 917/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4159 - accuracy: 0.8077 - val_loss: 0.3913 - val_accuracy: 0.8519\n",
      "Epoch 918/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4150 - accuracy: 0.8077 - val_loss: 0.3920 - val_accuracy: 0.8519\n",
      "Epoch 919/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4152 - accuracy: 0.8077 - val_loss: 0.3939 - val_accuracy: 0.8889\n",
      "Epoch 920/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.4165 - accuracy: 0.8173 - val_loss: 0.3907 - val_accuracy: 0.8519\n",
      "Epoch 921/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4149 - accuracy: 0.8173 - val_loss: 0.3882 - val_accuracy: 0.8519\n",
      "Epoch 922/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4162 - accuracy: 0.8173 - val_loss: 0.3892 - val_accuracy: 0.8519\n",
      "Epoch 923/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4136 - accuracy: 0.8077 - val_loss: 0.3879 - val_accuracy: 0.8519\n",
      "Epoch 924/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4182 - accuracy: 0.8269 - val_loss: 0.3891 - val_accuracy: 0.8148\n",
      "Epoch 925/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4134 - accuracy: 0.8077 - val_loss: 0.3924 - val_accuracy: 0.8889\n",
      "Epoch 926/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4178 - accuracy: 0.8269 - val_loss: 0.3969 - val_accuracy: 0.9259\n",
      "Epoch 927/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4140 - accuracy: 0.8173 - val_loss: 0.3870 - val_accuracy: 0.8519\n",
      "Epoch 928/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4224 - accuracy: 0.8173 - val_loss: 0.4044 - val_accuracy: 0.7778\n",
      "Epoch 929/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4308 - accuracy: 0.7885 - val_loss: 0.3887 - val_accuracy: 0.8148\n",
      "Epoch 930/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4122 - accuracy: 0.8365 - val_loss: 0.3945 - val_accuracy: 0.9259\n",
      "Epoch 931/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.4183 - accuracy: 0.84 - 0s 202us/step - loss: 0.4268 - accuracy: 0.8269 - val_loss: 0.4085 - val_accuracy: 0.9259\n",
      "Epoch 932/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4296 - accuracy: 0.8077 - val_loss: 0.3863 - val_accuracy: 0.8519\n",
      "Epoch 933/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4147 - accuracy: 0.8462 - val_loss: 0.3862 - val_accuracy: 0.8519\n",
      "Epoch 934/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4109 - accuracy: 0.8558 - val_loss: 0.3863 - val_accuracy: 0.8519\n",
      "Epoch 935/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 154us/step - loss: 0.4162 - accuracy: 0.8173 - val_loss: 0.3953 - val_accuracy: 0.9259\n",
      "Epoch 936/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4187 - accuracy: 0.8269 - val_loss: 0.3898 - val_accuracy: 0.8889\n",
      "Epoch 937/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.4125 - accuracy: 0.8173 - val_loss: 0.3864 - val_accuracy: 0.8519\n",
      "Epoch 938/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4104 - accuracy: 0.8077 - val_loss: 0.3853 - val_accuracy: 0.8519\n",
      "Epoch 939/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4116 - accuracy: 0.8077 - val_loss: 0.3855 - val_accuracy: 0.8519\n",
      "Epoch 940/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4105 - accuracy: 0.8269 - val_loss: 0.3847 - val_accuracy: 0.8519\n",
      "Epoch 941/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4111 - accuracy: 0.8173 - val_loss: 0.3843 - val_accuracy: 0.8519\n",
      "Epoch 942/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4099 - accuracy: 0.8269 - val_loss: 0.3843 - val_accuracy: 0.8519\n",
      "Epoch 943/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.4105 - accuracy: 0.8173 - val_loss: 0.3885 - val_accuracy: 0.9259\n",
      "Epoch 944/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4098 - accuracy: 0.8077 - val_loss: 0.3835 - val_accuracy: 0.8519\n",
      "Epoch 945/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4140 - accuracy: 0.8558 - val_loss: 0.3839 - val_accuracy: 0.8519\n",
      "Epoch 946/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4099 - accuracy: 0.8365 - val_loss: 0.3831 - val_accuracy: 0.8519\n",
      "Epoch 947/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4097 - accuracy: 0.8365 - val_loss: 0.3829 - val_accuracy: 0.8519\n",
      "Epoch 948/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4129 - accuracy: 0.8365 - val_loss: 0.3855 - val_accuracy: 0.8519\n",
      "Epoch 949/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4074 - accuracy: 0.8269 - val_loss: 0.3842 - val_accuracy: 0.8148\n",
      "Epoch 950/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4148 - accuracy: 0.8077 - val_loss: 0.3856 - val_accuracy: 0.8148\n",
      "Epoch 951/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4076 - accuracy: 0.8077 - val_loss: 0.3869 - val_accuracy: 0.9259\n",
      "Epoch 952/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4105 - accuracy: 0.8365 - val_loss: 0.3971 - val_accuracy: 0.9630\n",
      "Epoch 953/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.4156 - accuracy: 0.8173 - val_loss: 0.3817 - val_accuracy: 0.8519\n",
      "Epoch 954/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.4113 - accuracy: 0.8269 - val_loss: 0.3904 - val_accuracy: 0.8148\n",
      "Epoch 955/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4144 - accuracy: 0.8077 - val_loss: 0.3812 - val_accuracy: 0.8519\n",
      "Epoch 956/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4046 - accuracy: 0.8269 - val_loss: 0.3880 - val_accuracy: 0.9259\n",
      "Epoch 957/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4113 - accuracy: 0.8173 - val_loss: 0.3826 - val_accuracy: 0.8519\n",
      "Epoch 958/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4079 - accuracy: 0.8269 - val_loss: 0.3806 - val_accuracy: 0.8519\n",
      "Epoch 959/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4063 - accuracy: 0.8365 - val_loss: 0.3804 - val_accuracy: 0.8519\n",
      "Epoch 960/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4087 - accuracy: 0.8173 - val_loss: 0.3813 - val_accuracy: 0.8519\n",
      "Epoch 961/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.4063 - accuracy: 0.8462 - val_loss: 0.3806 - val_accuracy: 0.8519\n",
      "Epoch 962/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4074 - accuracy: 0.8365 - val_loss: 0.3798 - val_accuracy: 0.8519\n",
      "Epoch 963/2000\n",
      "104/104 [==============================] - 0s 118us/step - loss: 0.4057 - accuracy: 0.8365 - val_loss: 0.3805 - val_accuracy: 0.8519\n",
      "Epoch 964/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4055 - accuracy: 0.8462 - val_loss: 0.3795 - val_accuracy: 0.8519\n",
      "Epoch 965/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4040 - accuracy: 0.8269 - val_loss: 0.3832 - val_accuracy: 0.9259\n",
      "Epoch 966/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4055 - accuracy: 0.8269 - val_loss: 0.3791 - val_accuracy: 0.8519\n",
      "Epoch 967/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4101 - accuracy: 0.8365 - val_loss: 0.3800 - val_accuracy: 0.8519\n",
      "Epoch 968/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4101 - accuracy: 0.8462 - val_loss: 0.3844 - val_accuracy: 0.9259\n",
      "Epoch 969/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4073 - accuracy: 0.8173 - val_loss: 0.3796 - val_accuracy: 0.8519\n",
      "Epoch 970/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4037 - accuracy: 0.8173 - val_loss: 0.3785 - val_accuracy: 0.8519\n",
      "Epoch 971/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4082 - accuracy: 0.8269 - val_loss: 0.3780 - val_accuracy: 0.8519\n",
      "Epoch 972/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4069 - accuracy: 0.8269 - val_loss: 0.3812 - val_accuracy: 0.8889\n",
      "Epoch 973/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4032 - accuracy: 0.8173 - val_loss: 0.3794 - val_accuracy: 0.8148\n",
      "Epoch 974/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4056 - accuracy: 0.8173 - val_loss: 0.3780 - val_accuracy: 0.8519\n",
      "Epoch 975/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4055 - accuracy: 0.8365 - val_loss: 0.3794 - val_accuracy: 0.8889\n",
      "Epoch 976/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4045 - accuracy: 0.8077 - val_loss: 0.3779 - val_accuracy: 0.8519\n",
      "Epoch 977/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4021 - accuracy: 0.8077 - val_loss: 0.3775 - val_accuracy: 0.8519\n",
      "Epoch 978/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4027 - accuracy: 0.8077 - val_loss: 0.3766 - val_accuracy: 0.8519\n",
      "Epoch 979/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4027 - accuracy: 0.8365 - val_loss: 0.3764 - val_accuracy: 0.8519\n",
      "Epoch 980/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4011 - accuracy: 0.8173 - val_loss: 0.3786 - val_accuracy: 0.8889\n",
      "Epoch 981/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4027 - accuracy: 0.8077 - val_loss: 0.3764 - val_accuracy: 0.8519\n",
      "Epoch 982/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4005 - accuracy: 0.8269 - val_loss: 0.3788 - val_accuracy: 0.8148\n",
      "Epoch 983/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4053 - accuracy: 0.8077 - val_loss: 0.3769 - val_accuracy: 0.8519\n",
      "Epoch 984/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4010 - accuracy: 0.8365 - val_loss: 0.3777 - val_accuracy: 0.8889\n",
      "Epoch 985/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4068 - accuracy: 0.8269 - val_loss: 0.3805 - val_accuracy: 0.9259\n",
      "Epoch 986/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3995 - accuracy: 0.8269 - val_loss: 0.3781 - val_accuracy: 0.8148\n",
      "Epoch 987/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4073 - accuracy: 0.8173 - val_loss: 0.3789 - val_accuracy: 0.8148\n",
      "Epoch 988/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4049 - accuracy: 0.8269 - val_loss: 0.3785 - val_accuracy: 0.9259\n",
      "Epoch 989/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4026 - accuracy: 0.8077 - val_loss: 0.3745 - val_accuracy: 0.8519\n",
      "Epoch 990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 144us/step - loss: 0.4009 - accuracy: 0.8558 - val_loss: 0.3752 - val_accuracy: 0.8519\n",
      "Epoch 991/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3994 - accuracy: 0.8365 - val_loss: 0.3754 - val_accuracy: 0.8519\n",
      "Epoch 992/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4000 - accuracy: 0.8173 - val_loss: 0.3773 - val_accuracy: 0.9259\n",
      "Epoch 993/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4017 - accuracy: 0.8173 - val_loss: 0.3737 - val_accuracy: 0.8519\n",
      "Epoch 994/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3993 - accuracy: 0.8269 - val_loss: 0.3734 - val_accuracy: 0.8519\n",
      "Epoch 995/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3985 - accuracy: 0.8365 - val_loss: 0.3747 - val_accuracy: 0.8519\n",
      "Epoch 996/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3996 - accuracy: 0.8077 - val_loss: 0.3743 - val_accuracy: 0.8519\n",
      "Epoch 997/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3995 - accuracy: 0.8173 - val_loss: 0.3741 - val_accuracy: 0.8519\n",
      "Epoch 998/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3983 - accuracy: 0.8173 - val_loss: 0.3734 - val_accuracy: 0.8519\n",
      "Epoch 999/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3990 - accuracy: 0.8462 - val_loss: 0.3736 - val_accuracy: 0.8519\n",
      "Epoch 1000/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3994 - accuracy: 0.8558 - val_loss: 0.3724 - val_accuracy: 0.8519\n",
      "Epoch 1001/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3983 - accuracy: 0.8462 - val_loss: 0.3730 - val_accuracy: 0.8519\n",
      "Epoch 1002/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4008 - accuracy: 0.8269 - val_loss: 0.3739 - val_accuracy: 0.8889\n",
      "Epoch 1003/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3932 - accuracy: 0.8365 - val_loss: 0.3774 - val_accuracy: 0.8148\n",
      "Epoch 1004/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4040 - accuracy: 0.8269 - val_loss: 0.3846 - val_accuracy: 0.8148\n",
      "Epoch 1005/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4066 - accuracy: 0.8173 - val_loss: 0.3716 - val_accuracy: 0.8519\n",
      "Epoch 1006/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3990 - accuracy: 0.8365 - val_loss: 0.3862 - val_accuracy: 0.9630\n",
      "Epoch 1007/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4260 - accuracy: 0.7981 - val_loss: 0.3860 - val_accuracy: 0.9630\n",
      "Epoch 1008/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3949 - accuracy: 0.8365 - val_loss: 0.3856 - val_accuracy: 0.8148\n",
      "Epoch 1009/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4202 - accuracy: 0.7788 - val_loss: 0.3872 - val_accuracy: 0.8148\n",
      "Epoch 1010/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4023 - accuracy: 0.8365 - val_loss: 0.3721 - val_accuracy: 0.8889\n",
      "Epoch 1011/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3975 - accuracy: 0.8269 - val_loss: 0.3826 - val_accuracy: 0.9630\n",
      "Epoch 1012/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.4066 - accuracy: 0.8173 - val_loss: 0.3736 - val_accuracy: 0.9259\n",
      "Epoch 1013/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4011 - accuracy: 0.8173 - val_loss: 0.3750 - val_accuracy: 0.8148\n",
      "Epoch 1014/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4006 - accuracy: 0.8173 - val_loss: 0.3705 - val_accuracy: 0.8519\n",
      "Epoch 1015/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3952 - accuracy: 0.8269 - val_loss: 0.3713 - val_accuracy: 0.8889\n",
      "Epoch 1016/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4005 - accuracy: 0.8269 - val_loss: 0.3707 - val_accuracy: 0.8889\n",
      "Epoch 1017/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3996 - accuracy: 0.8173 - val_loss: 0.3711 - val_accuracy: 0.8519\n",
      "Epoch 1018/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3985 - accuracy: 0.8269 - val_loss: 0.3727 - val_accuracy: 0.9259\n",
      "Epoch 1019/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4019 - accuracy: 0.8269 - val_loss: 0.3744 - val_accuracy: 0.9259\n",
      "Epoch 1020/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3977 - accuracy: 0.8173 - val_loss: 0.3687 - val_accuracy: 0.8519\n",
      "Epoch 1021/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3918 - accuracy: 0.8365 - val_loss: 0.3726 - val_accuracy: 0.8148\n",
      "Epoch 1022/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4003 - accuracy: 0.8173 - val_loss: 0.3688 - val_accuracy: 0.8519\n",
      "Epoch 1023/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3948 - accuracy: 0.8365 - val_loss: 0.3751 - val_accuracy: 0.9259\n",
      "Epoch 1024/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3986 - accuracy: 0.8269 - val_loss: 0.3689 - val_accuracy: 0.8889\n",
      "Epoch 1025/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3961 - accuracy: 0.8173 - val_loss: 0.3683 - val_accuracy: 0.8519\n",
      "Epoch 1026/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3947 - accuracy: 0.8269 - val_loss: 0.3677 - val_accuracy: 0.8519\n",
      "Epoch 1027/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3927 - accuracy: 0.8173 - val_loss: 0.3673 - val_accuracy: 0.8519\n",
      "Epoch 1028/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3926 - accuracy: 0.8077 - val_loss: 0.3674 - val_accuracy: 0.8519\n",
      "Epoch 1029/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3916 - accuracy: 0.8077 - val_loss: 0.3669 - val_accuracy: 0.8519\n",
      "Epoch 1030/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3918 - accuracy: 0.8365 - val_loss: 0.3686 - val_accuracy: 0.8519\n",
      "Epoch 1031/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.4021 - accuracy: 0.8077 - val_loss: 0.3768 - val_accuracy: 0.8148\n",
      "Epoch 1032/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4071 - accuracy: 0.8173 - val_loss: 0.3746 - val_accuracy: 0.8148\n",
      "Epoch 1033/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3995 - accuracy: 0.8077 - val_loss: 0.3675 - val_accuracy: 0.8889\n",
      "Epoch 1034/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3965 - accuracy: 0.8365 - val_loss: 0.3694 - val_accuracy: 0.9259\n",
      "Epoch 1035/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3902 - accuracy: 0.8173 - val_loss: 0.3671 - val_accuracy: 0.8519\n",
      "Epoch 1036/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3958 - accuracy: 0.8462 - val_loss: 0.3711 - val_accuracy: 0.8148\n",
      "Epoch 1037/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 0.3953 - accuracy: 0.8269 - val_loss: 0.3657 - val_accuracy: 0.8519\n",
      "Epoch 1038/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3925 - accuracy: 0.8173 - val_loss: 0.3675 - val_accuracy: 0.9259\n",
      "Epoch 1039/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3919 - accuracy: 0.8269 - val_loss: 0.3651 - val_accuracy: 0.8519\n",
      "Epoch 1040/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3989 - accuracy: 0.8077 - val_loss: 0.3821 - val_accuracy: 0.8148\n",
      "Epoch 1041/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.4037 - accuracy: 0.8077 - val_loss: 0.3652 - val_accuracy: 0.8519\n",
      "Epoch 1042/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3945 - accuracy: 0.8077 - val_loss: 0.3738 - val_accuracy: 0.9630\n",
      "Epoch 1043/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3989 - accuracy: 0.8269 - val_loss: 0.3648 - val_accuracy: 0.8519\n",
      "Epoch 1044/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.4074 - accuracy: 0.7981 - val_loss: 0.3737 - val_accuracy: 0.8148\n",
      "Epoch 1045/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 135us/step - loss: 0.3976 - accuracy: 0.8462 - val_loss: 0.3640 - val_accuracy: 0.8519\n",
      "Epoch 1046/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3888 - accuracy: 0.8365 - val_loss: 0.3659 - val_accuracy: 0.9259\n",
      "Epoch 1047/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3958 - accuracy: 0.8077 - val_loss: 0.3753 - val_accuracy: 0.9630\n",
      "Epoch 1048/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3978 - accuracy: 0.8077 - val_loss: 0.3645 - val_accuracy: 0.8519\n",
      "Epoch 1049/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3909 - accuracy: 0.8365 - val_loss: 0.3632 - val_accuracy: 0.8519\n",
      "Epoch 1050/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3906 - accuracy: 0.8173 - val_loss: 0.3631 - val_accuracy: 0.8519\n",
      "Epoch 1051/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3913 - accuracy: 0.8365 - val_loss: 0.3709 - val_accuracy: 0.8148\n",
      "Epoch 1052/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3966 - accuracy: 0.8269 - val_loss: 0.3659 - val_accuracy: 0.8519\n",
      "Epoch 1053/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3908 - accuracy: 0.8269 - val_loss: 0.3651 - val_accuracy: 0.9259\n",
      "Epoch 1054/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3915 - accuracy: 0.8269 - val_loss: 0.3627 - val_accuracy: 0.8519\n",
      "Epoch 1055/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3918 - accuracy: 0.8462 - val_loss: 0.3727 - val_accuracy: 0.8148\n",
      "Epoch 1056/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3949 - accuracy: 0.8269 - val_loss: 0.3623 - val_accuracy: 0.8519\n",
      "Epoch 1057/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3964 - accuracy: 0.8173 - val_loss: 0.3677 - val_accuracy: 0.9259\n",
      "Epoch 1058/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4018 - accuracy: 0.8077 - val_loss: 0.3619 - val_accuracy: 0.8519\n",
      "Epoch 1059/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3882 - accuracy: 0.8173 - val_loss: 0.3627 - val_accuracy: 0.8889\n",
      "Epoch 1060/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3903 - accuracy: 0.8269 - val_loss: 0.3613 - val_accuracy: 0.8519\n",
      "Epoch 1061/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3918 - accuracy: 0.8173 - val_loss: 0.3685 - val_accuracy: 0.8148\n",
      "Epoch 1062/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.3933 - accuracy: 0.8365 - val_loss: 0.3619 - val_accuracy: 0.8519\n",
      "Epoch 1063/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3905 - accuracy: 0.8077 - val_loss: 0.3640 - val_accuracy: 0.9259\n",
      "Epoch 1064/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3930 - accuracy: 0.8269 - val_loss: 0.3653 - val_accuracy: 0.9259\n",
      "Epoch 1065/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3932 - accuracy: 0.8077 - val_loss: 0.3605 - val_accuracy: 0.8519\n",
      "Epoch 1066/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3862 - accuracy: 0.8173 - val_loss: 0.3609 - val_accuracy: 0.8519\n",
      "Epoch 1067/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.3870 - accuracy: 0.8558 - val_loss: 0.3660 - val_accuracy: 0.8148\n",
      "Epoch 1068/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3877 - accuracy: 0.8462 - val_loss: 0.3601 - val_accuracy: 0.8519\n",
      "Epoch 1069/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3928 - accuracy: 0.8269 - val_loss: 0.3725 - val_accuracy: 0.9630\n",
      "Epoch 1070/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3963 - accuracy: 0.8269 - val_loss: 0.3597 - val_accuracy: 0.8519\n",
      "Epoch 1071/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3851 - accuracy: 0.8365 - val_loss: 0.3595 - val_accuracy: 0.8519\n",
      "Epoch 1072/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3890 - accuracy: 0.8173 - val_loss: 0.3592 - val_accuracy: 0.8519\n",
      "Epoch 1073/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3868 - accuracy: 0.8558 - val_loss: 0.3655 - val_accuracy: 0.8148\n",
      "Epoch 1074/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3910 - accuracy: 0.8269 - val_loss: 0.3641 - val_accuracy: 0.8148\n",
      "Epoch 1075/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3901 - accuracy: 0.8462 - val_loss: 0.3602 - val_accuracy: 0.8519\n",
      "Epoch 1076/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.3854 - accuracy: 0.8173 - val_loss: 0.3620 - val_accuracy: 0.9259\n",
      "Epoch 1077/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3918 - accuracy: 0.8269 - val_loss: 0.3591 - val_accuracy: 0.8889\n",
      "Epoch 1078/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3841 - accuracy: 0.8365 - val_loss: 0.3734 - val_accuracy: 0.8148\n",
      "Epoch 1079/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.4043 - accuracy: 0.8173 - val_loss: 0.3726 - val_accuracy: 0.8148\n",
      "Epoch 1080/2000\n",
      "104/104 [==============================] - 0s 481us/step - loss: 0.3966 - accuracy: 0.8269 - val_loss: 0.3595 - val_accuracy: 0.8519\n",
      "Epoch 1081/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3849 - accuracy: 0.8462 - val_loss: 0.3592 - val_accuracy: 0.9259\n",
      "Epoch 1082/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3854 - accuracy: 0.8269 - val_loss: 0.3612 - val_accuracy: 0.9259\n",
      "Epoch 1083/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3868 - accuracy: 0.8462 - val_loss: 0.3595 - val_accuracy: 0.9259\n",
      "Epoch 1084/2000\n",
      "104/104 [==============================] - 0s 298us/step - loss: 0.3850 - accuracy: 0.8173 - val_loss: 0.3572 - val_accuracy: 0.8519\n",
      "Epoch 1085/2000\n",
      "104/104 [==============================] - 0s 250us/step - loss: 0.3831 - accuracy: 0.8269 - val_loss: 0.3571 - val_accuracy: 0.8519\n",
      "Epoch 1086/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3830 - accuracy: 0.8077 - val_loss: 0.3585 - val_accuracy: 0.9259\n",
      "Epoch 1087/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3847 - accuracy: 0.8365 - val_loss: 0.3594 - val_accuracy: 0.9259\n",
      "Epoch 1088/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3902 - accuracy: 0.8173 - val_loss: 0.3566 - val_accuracy: 0.8519\n",
      "Epoch 1089/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3831 - accuracy: 0.8269 - val_loss: 0.3590 - val_accuracy: 0.9259\n",
      "Epoch 1090/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3833 - accuracy: 0.8269 - val_loss: 0.3564 - val_accuracy: 0.8519\n",
      "Epoch 1091/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3842 - accuracy: 0.8365 - val_loss: 0.3608 - val_accuracy: 0.8148\n",
      "Epoch 1092/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3857 - accuracy: 0.8558 - val_loss: 0.3560 - val_accuracy: 0.8519\n",
      "Epoch 1093/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3826 - accuracy: 0.8173 - val_loss: 0.3558 - val_accuracy: 0.8519\n",
      "Epoch 1094/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3814 - accuracy: 0.8269 - val_loss: 0.3570 - val_accuracy: 0.8519\n",
      "Epoch 1095/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3834 - accuracy: 0.8558 - val_loss: 0.3575 - val_accuracy: 0.8519\n",
      "Epoch 1096/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3825 - accuracy: 0.8365 - val_loss: 0.3555 - val_accuracy: 0.8519\n",
      "Epoch 1097/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3808 - accuracy: 0.8365 - val_loss: 0.3550 - val_accuracy: 0.8519\n",
      "Epoch 1098/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3824 - accuracy: 0.8173 - val_loss: 0.3561 - val_accuracy: 0.9259\n",
      "Epoch 1099/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3815 - accuracy: 0.8269 - val_loss: 0.3548 - val_accuracy: 0.8519\n",
      "Epoch 1100/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 144us/step - loss: 0.3803 - accuracy: 0.8173 - val_loss: 0.3557 - val_accuracy: 0.8519\n",
      "Epoch 1101/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3819 - accuracy: 0.8365 - val_loss: 0.3544 - val_accuracy: 0.8519\n",
      "Epoch 1102/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3804 - accuracy: 0.8269 - val_loss: 0.3551 - val_accuracy: 0.8519\n",
      "Epoch 1103/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3860 - accuracy: 0.8462 - val_loss: 0.3594 - val_accuracy: 0.8148\n",
      "Epoch 1104/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3821 - accuracy: 0.8462 - val_loss: 0.3538 - val_accuracy: 0.8519\n",
      "Epoch 1105/2000\n",
      "104/104 [==============================] - 0s 87us/step - loss: 0.3807 - accuracy: 0.8365 - val_loss: 0.3538 - val_accuracy: 0.8889\n",
      "Epoch 1106/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3836 - accuracy: 0.8365 - val_loss: 0.3576 - val_accuracy: 0.8519\n",
      "Epoch 1107/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3823 - accuracy: 0.8462 - val_loss: 0.3533 - val_accuracy: 0.8519\n",
      "Epoch 1108/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3787 - accuracy: 0.8269 - val_loss: 0.3573 - val_accuracy: 0.9259\n",
      "Epoch 1109/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3913 - accuracy: 0.8173 - val_loss: 0.3570 - val_accuracy: 0.9259\n",
      "Epoch 1110/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3849 - accuracy: 0.8462 - val_loss: 0.3613 - val_accuracy: 0.8148\n",
      "Epoch 1111/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3866 - accuracy: 0.8269 - val_loss: 0.3571 - val_accuracy: 0.8519\n",
      "Epoch 1112/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3821 - accuracy: 0.8269 - val_loss: 0.3525 - val_accuracy: 0.8519\n",
      "Epoch 1113/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3785 - accuracy: 0.8269 - val_loss: 0.3528 - val_accuracy: 0.8519\n",
      "Epoch 1114/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3738 - accuracy: 0.84 - 0s 144us/step - loss: 0.3781 - accuracy: 0.8365 - val_loss: 0.3525 - val_accuracy: 0.8519\n",
      "Epoch 1115/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3777 - accuracy: 0.8365 - val_loss: 0.3523 - val_accuracy: 0.8889\n",
      "Epoch 1116/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3834 - accuracy: 0.8365 - val_loss: 0.3568 - val_accuracy: 0.9259\n",
      "Epoch 1117/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3794 - accuracy: 0.8365 - val_loss: 0.3524 - val_accuracy: 0.8519\n",
      "Epoch 1118/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3767 - accuracy: 0.8558 - val_loss: 0.3623 - val_accuracy: 0.8148\n",
      "Epoch 1119/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3852 - accuracy: 0.8365 - val_loss: 0.3520 - val_accuracy: 0.8519\n",
      "Epoch 1120/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3720 - accuracy: 0.8173 - val_loss: 0.3646 - val_accuracy: 0.9630\n",
      "Epoch 1121/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3945 - accuracy: 0.8173 - val_loss: 0.3603 - val_accuracy: 0.9630\n",
      "Epoch 1122/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3828 - accuracy: 0.8365 - val_loss: 0.3509 - val_accuracy: 0.8519\n",
      "Epoch 1123/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3848 - accuracy: 0.8365 - val_loss: 0.3551 - val_accuracy: 0.8519\n",
      "Epoch 1124/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3866 - accuracy: 0.8269 - val_loss: 0.3537 - val_accuracy: 0.9259\n",
      "Epoch 1125/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3813 - accuracy: 0.8269 - val_loss: 0.3508 - val_accuracy: 0.8519\n",
      "Epoch 1126/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3760 - accuracy: 0.8462 - val_loss: 0.3534 - val_accuracy: 0.8519\n",
      "Epoch 1127/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3830 - accuracy: 0.8462 - val_loss: 0.3527 - val_accuracy: 0.8519\n",
      "Epoch 1128/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3732 - accuracy: 0.8365 - val_loss: 0.3540 - val_accuracy: 0.9259\n",
      "Epoch 1129/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3804 - accuracy: 0.8462 - val_loss: 0.3518 - val_accuracy: 0.9259\n",
      "Epoch 1130/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3786 - accuracy: 0.8269 - val_loss: 0.3497 - val_accuracy: 0.8519\n",
      "Epoch 1131/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3788 - accuracy: 0.8365 - val_loss: 0.3555 - val_accuracy: 0.8148\n",
      "Epoch 1132/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3799 - accuracy: 0.8558 - val_loss: 0.3497 - val_accuracy: 0.8519\n",
      "Epoch 1133/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3748 - accuracy: 0.8077 - val_loss: 0.3492 - val_accuracy: 0.8889\n",
      "Epoch 1134/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3772 - accuracy: 0.8173 - val_loss: 0.3501 - val_accuracy: 0.8519\n",
      "Epoch 1135/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3813 - accuracy: 0.8462 - val_loss: 0.3517 - val_accuracy: 0.8519\n",
      "Epoch 1136/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.4164 - accuracy: 0.84 - 0s 106us/step - loss: 0.3800 - accuracy: 0.8269 - val_loss: 0.3486 - val_accuracy: 0.8519\n",
      "Epoch 1137/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3738 - accuracy: 0.8077 - val_loss: 0.3494 - val_accuracy: 0.8519\n",
      "Epoch 1138/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3768 - accuracy: 0.8462 - val_loss: 0.3498 - val_accuracy: 0.8519\n",
      "Epoch 1139/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3736 - accuracy: 0.8365 - val_loss: 0.3491 - val_accuracy: 0.9259\n",
      "Epoch 1140/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3755 - accuracy: 0.8269 - val_loss: 0.3498 - val_accuracy: 0.9259\n",
      "Epoch 1141/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3749 - accuracy: 0.8269 - val_loss: 0.3479 - val_accuracy: 0.8519\n",
      "Epoch 1142/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3774 - accuracy: 0.8462 - val_loss: 0.3506 - val_accuracy: 0.8519\n",
      "Epoch 1143/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3744 - accuracy: 0.8365 - val_loss: 0.3475 - val_accuracy: 0.8889\n",
      "Epoch 1144/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3799 - accuracy: 0.8269 - val_loss: 0.3497 - val_accuracy: 0.9259\n",
      "Epoch 1145/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3780 - accuracy: 0.8269 - val_loss: 0.3492 - val_accuracy: 0.8519\n",
      "Epoch 1146/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3742 - accuracy: 0.8365 - val_loss: 0.3470 - val_accuracy: 0.8519\n",
      "Epoch 1147/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3727 - accuracy: 0.8269 - val_loss: 0.3469 - val_accuracy: 0.8519\n",
      "Epoch 1148/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3735 - accuracy: 0.8365 - val_loss: 0.3471 - val_accuracy: 0.8519\n",
      "Epoch 1149/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3727 - accuracy: 0.8365 - val_loss: 0.3465 - val_accuracy: 0.8889\n",
      "Epoch 1150/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3844 - accuracy: 0.8077 - val_loss: 0.3473 - val_accuracy: 0.9259\n",
      "Epoch 1151/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3743 - accuracy: 0.8462 - val_loss: 0.3626 - val_accuracy: 0.8148\n",
      "Epoch 1152/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3850 - accuracy: 0.8365 - val_loss: 0.3463 - val_accuracy: 0.8519\n",
      "Epoch 1153/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3746 - accuracy: 0.8365 - val_loss: 0.3505 - val_accuracy: 0.9259\n",
      "Epoch 1154/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 183us/step - loss: 0.3780 - accuracy: 0.8365 - val_loss: 0.3459 - val_accuracy: 0.8519\n",
      "Epoch 1155/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3696 - accuracy: 0.8462 - val_loss: 0.3748 - val_accuracy: 0.8148\n",
      "Epoch 1156/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.4114 - accuracy: 0.7788 - val_loss: 0.3677 - val_accuracy: 0.8148\n",
      "Epoch 1157/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3912 - accuracy: 0.8173 - val_loss: 0.3470 - val_accuracy: 0.9259\n",
      "Epoch 1158/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3738 - accuracy: 0.8462 - val_loss: 0.3460 - val_accuracy: 0.9259\n",
      "Epoch 1159/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3727 - accuracy: 0.8077 - val_loss: 0.3475 - val_accuracy: 0.8519\n",
      "Epoch 1160/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 0.3774 - accuracy: 0.8558 - val_loss: 0.3548 - val_accuracy: 0.8148\n",
      "Epoch 1161/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3787 - accuracy: 0.8365 - val_loss: 0.3479 - val_accuracy: 0.8519\n",
      "Epoch 1162/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3711 - accuracy: 0.8462 - val_loss: 0.3448 - val_accuracy: 0.9259\n",
      "Epoch 1163/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3866 - accuracy: 0.8269 - val_loss: 0.3609 - val_accuracy: 0.9630\n",
      "Epoch 1164/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3835 - accuracy: 0.8173 - val_loss: 0.3441 - val_accuracy: 0.8889\n",
      "Epoch 1165/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3728 - accuracy: 0.8462 - val_loss: 0.3807 - val_accuracy: 0.8148\n",
      "Epoch 1166/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.4072 - accuracy: 0.7885 - val_loss: 0.3700 - val_accuracy: 0.8148\n",
      "Epoch 1167/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3836 - accuracy: 0.8077 - val_loss: 0.3436 - val_accuracy: 0.8519\n",
      "Epoch 1168/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3753 - accuracy: 0.8173 - val_loss: 0.3474 - val_accuracy: 0.9259\n",
      "Epoch 1169/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3712 - accuracy: 0.8269 - val_loss: 0.3457 - val_accuracy: 0.8519\n",
      "Epoch 1170/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3713 - accuracy: 0.8462 - val_loss: 0.3433 - val_accuracy: 0.8519\n",
      "Epoch 1171/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3704 - accuracy: 0.8269 - val_loss: 0.3455 - val_accuracy: 0.9259\n",
      "Epoch 1172/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3739 - accuracy: 0.8269 - val_loss: 0.3439 - val_accuracy: 0.8519\n",
      "Epoch 1173/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3696 - accuracy: 0.8654 - val_loss: 0.3506 - val_accuracy: 0.8148\n",
      "Epoch 1174/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3788 - accuracy: 0.8558 - val_loss: 0.3441 - val_accuracy: 0.8519\n",
      "Epoch 1175/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3699 - accuracy: 0.8462 - val_loss: 0.3432 - val_accuracy: 0.8519\n",
      "Epoch 1176/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3700 - accuracy: 0.8269 - val_loss: 0.3423 - val_accuracy: 0.8519\n",
      "Epoch 1177/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3690 - accuracy: 0.8269 - val_loss: 0.3428 - val_accuracy: 0.8519\n",
      "Epoch 1178/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.87 - 0s 106us/step - loss: 0.3687 - accuracy: 0.8365 - val_loss: 0.3428 - val_accuracy: 0.9259\n",
      "Epoch 1179/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3713 - accuracy: 0.8173 - val_loss: 0.3558 - val_accuracy: 0.9630\n",
      "Epoch 1180/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3818 - accuracy: 0.8173 - val_loss: 0.3443 - val_accuracy: 0.9259\n",
      "Epoch 1181/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3706 - accuracy: 0.8269 - val_loss: 0.3420 - val_accuracy: 0.8519\n",
      "Epoch 1182/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3676 - accuracy: 0.8269 - val_loss: 0.3417 - val_accuracy: 0.9259\n",
      "Epoch 1183/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3702 - accuracy: 0.8269 - val_loss: 0.3459 - val_accuracy: 0.9630\n",
      "Epoch 1184/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.84 - 0s 144us/step - loss: 0.3735 - accuracy: 0.8365 - val_loss: 0.3447 - val_accuracy: 0.9259\n",
      "Epoch 1185/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3717 - accuracy: 0.8462 - val_loss: 0.3415 - val_accuracy: 0.9259\n",
      "Epoch 1186/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3672 - accuracy: 0.8269 - val_loss: 0.3413 - val_accuracy: 0.8519\n",
      "Epoch 1187/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3667 - accuracy: 0.8365 - val_loss: 0.3456 - val_accuracy: 0.8519\n",
      "Epoch 1188/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3797 - accuracy: 0.8462 - val_loss: 0.3472 - val_accuracy: 0.8519\n",
      "Epoch 1189/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3699 - accuracy: 0.8462 - val_loss: 0.3433 - val_accuracy: 0.9259\n",
      "Epoch 1190/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3713 - accuracy: 0.8462 - val_loss: 0.3427 - val_accuracy: 0.9259\n",
      "Epoch 1191/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3687 - accuracy: 0.8365 - val_loss: 0.3401 - val_accuracy: 0.8519\n",
      "Epoch 1192/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3688 - accuracy: 0.8365 - val_loss: 0.3401 - val_accuracy: 0.8519\n",
      "Epoch 1193/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3716 - accuracy: 0.8269 - val_loss: 0.3489 - val_accuracy: 0.9630\n",
      "Epoch 1194/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3738 - accuracy: 0.8269 - val_loss: 0.3396 - val_accuracy: 0.8889\n",
      "Epoch 1195/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3691 - accuracy: 0.8365 - val_loss: 0.3437 - val_accuracy: 0.8519\n",
      "Epoch 1196/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3690 - accuracy: 0.8462 - val_loss: 0.3393 - val_accuracy: 0.8889\n",
      "Epoch 1197/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3656 - accuracy: 0.8173 - val_loss: 0.3393 - val_accuracy: 0.9259\n",
      "Epoch 1198/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3707 - accuracy: 0.8365 - val_loss: 0.3397 - val_accuracy: 0.9259\n",
      "Epoch 1199/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3680 - accuracy: 0.8077 - val_loss: 0.3388 - val_accuracy: 0.8889\n",
      "Epoch 1200/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3681 - accuracy: 0.8269 - val_loss: 0.3386 - val_accuracy: 0.8889\n",
      "Epoch 1201/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3757 - accuracy: 0.8365 - val_loss: 0.3412 - val_accuracy: 0.8519\n",
      "Epoch 1202/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3764 - accuracy: 0.8269 - val_loss: 0.3398 - val_accuracy: 0.9259\n",
      "Epoch 1203/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3682 - accuracy: 0.8654 - val_loss: 0.3412 - val_accuracy: 0.8519\n",
      "Epoch 1204/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3684 - accuracy: 0.8269 - val_loss: 0.3382 - val_accuracy: 0.8519\n",
      "Epoch 1205/2000\n",
      "104/104 [==============================] - 0s 164us/step - loss: 0.3669 - accuracy: 0.8462 - val_loss: 0.3462 - val_accuracy: 0.8519\n",
      "Epoch 1206/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3721 - accuracy: 0.8558 - val_loss: 0.3525 - val_accuracy: 0.8148\n",
      "Epoch 1207/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3750 - accuracy: 0.8462 - val_loss: 0.3376 - val_accuracy: 0.8889\n",
      "Epoch 1208/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 96us/step - loss: 0.3629 - accuracy: 0.8173 - val_loss: 0.3403 - val_accuracy: 0.9259\n",
      "Epoch 1209/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3689 - accuracy: 0.8365 - val_loss: 0.3391 - val_accuracy: 0.9259\n",
      "Epoch 1210/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3662 - accuracy: 0.8462 - val_loss: 0.3372 - val_accuracy: 0.9259\n",
      "Epoch 1211/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3649 - accuracy: 0.8173 - val_loss: 0.3371 - val_accuracy: 0.8889\n",
      "Epoch 1212/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3633 - accuracy: 0.8269 - val_loss: 0.3385 - val_accuracy: 0.8519\n",
      "Epoch 1213/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3640 - accuracy: 0.8462 - val_loss: 0.3369 - val_accuracy: 0.8519\n",
      "Epoch 1214/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3675 - accuracy: 0.8365 - val_loss: 0.3377 - val_accuracy: 0.9259\n",
      "Epoch 1215/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3628 - accuracy: 0.8269 - val_loss: 0.3382 - val_accuracy: 0.8519\n",
      "Epoch 1216/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3701 - accuracy: 0.8462 - val_loss: 0.3478 - val_accuracy: 0.8148\n",
      "Epoch 1217/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3699 - accuracy: 0.8462 - val_loss: 0.3371 - val_accuracy: 0.8519\n",
      "Epoch 1218/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3609 - accuracy: 0.8173 - val_loss: 0.3392 - val_accuracy: 0.9259\n",
      "Epoch 1219/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3659 - accuracy: 0.8365 - val_loss: 0.3359 - val_accuracy: 0.8889\n",
      "Epoch 1220/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3735 - accuracy: 0.8173 - val_loss: 0.3436 - val_accuracy: 0.8519\n",
      "Epoch 1221/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3623 - accuracy: 0.8654 - val_loss: 0.3364 - val_accuracy: 0.9259\n",
      "Epoch 1222/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3729 - accuracy: 0.8269 - val_loss: 0.3491 - val_accuracy: 0.9630\n",
      "Epoch 1223/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3735 - accuracy: 0.8365 - val_loss: 0.3353 - val_accuracy: 0.9259\n",
      "Epoch 1224/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3619 - accuracy: 0.8365 - val_loss: 0.3484 - val_accuracy: 0.8148\n",
      "Epoch 1225/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3746 - accuracy: 0.8365 - val_loss: 0.3428 - val_accuracy: 0.8519\n",
      "Epoch 1226/2000\n",
      "104/104 [==============================] - 0s 308us/step - loss: 0.3648 - accuracy: 0.8462 - val_loss: 0.3361 - val_accuracy: 0.9259\n",
      "Epoch 1227/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3719 - accuracy: 0.8365 - val_loss: 0.3440 - val_accuracy: 0.9630\n",
      "Epoch 1228/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3720 - accuracy: 0.8365 - val_loss: 0.3356 - val_accuracy: 0.9259\n",
      "Epoch 1229/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3597 - accuracy: 0.8173 - val_loss: 0.3380 - val_accuracy: 0.8519\n",
      "Epoch 1230/2000\n",
      "104/104 [==============================] - 0s 250us/step - loss: 0.3665 - accuracy: 0.8654 - val_loss: 0.3418 - val_accuracy: 0.8519\n",
      "Epoch 1231/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3635 - accuracy: 0.8558 - val_loss: 0.3341 - val_accuracy: 0.9259\n",
      "Epoch 1232/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3705 - accuracy: 0.8173 - val_loss: 0.3425 - val_accuracy: 0.9630\n",
      "Epoch 1233/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3663 - accuracy: 0.8365 - val_loss: 0.3342 - val_accuracy: 0.8519\n",
      "Epoch 1234/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3624 - accuracy: 0.8462 - val_loss: 0.3364 - val_accuracy: 0.8519\n",
      "Epoch 1235/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3636 - accuracy: 0.8558 - val_loss: 0.3360 - val_accuracy: 0.8519\n",
      "Epoch 1236/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3618 - accuracy: 0.8365 - val_loss: 0.3334 - val_accuracy: 0.9259\n",
      "Epoch 1237/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3602 - accuracy: 0.8269 - val_loss: 0.3350 - val_accuracy: 0.9259\n",
      "Epoch 1238/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3633 - accuracy: 0.8365 - val_loss: 0.3364 - val_accuracy: 0.9259\n",
      "Epoch 1239/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3608 - accuracy: 0.8462 - val_loss: 0.3370 - val_accuracy: 0.8519\n",
      "Epoch 1240/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3788 - accuracy: 0.8269 - val_loss: 0.3620 - val_accuracy: 0.8148\n",
      "Epoch 1241/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3771 - accuracy: 0.8269 - val_loss: 0.3328 - val_accuracy: 0.8889\n",
      "Epoch 1242/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3581 - accuracy: 0.8462 - val_loss: 0.3393 - val_accuracy: 0.9630\n",
      "Epoch 1243/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3683 - accuracy: 0.8365 - val_loss: 0.3330 - val_accuracy: 0.9259\n",
      "Epoch 1244/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3581 - accuracy: 0.8462 - val_loss: 0.3389 - val_accuracy: 0.8519\n",
      "Epoch 1245/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3734 - accuracy: 0.8462 - val_loss: 0.3424 - val_accuracy: 0.8148\n",
      "Epoch 1246/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3619 - accuracy: 0.8558 - val_loss: 0.3340 - val_accuracy: 0.9259\n",
      "Epoch 1247/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3623 - accuracy: 0.8462 - val_loss: 0.3512 - val_accuracy: 0.9630\n",
      "Epoch 1248/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3919 - accuracy: 0.8173 - val_loss: 0.3408 - val_accuracy: 0.9630\n",
      "Epoch 1249/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3660 - accuracy: 0.8462 - val_loss: 0.3534 - val_accuracy: 0.8148\n",
      "Epoch 1250/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3781 - accuracy: 0.8269 - val_loss: 0.3405 - val_accuracy: 0.8519\n",
      "Epoch 1251/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3639 - accuracy: 0.8365 - val_loss: 0.3356 - val_accuracy: 0.9630\n",
      "Epoch 1252/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3668 - accuracy: 0.8365 - val_loss: 0.3359 - val_accuracy: 0.9630\n",
      "Epoch 1253/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3603 - accuracy: 0.8462 - val_loss: 0.3329 - val_accuracy: 0.8519\n",
      "Epoch 1254/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3726 - accuracy: 0.8365 - val_loss: 0.3624 - val_accuracy: 0.8148\n",
      "Epoch 1255/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3808 - accuracy: 0.8365 - val_loss: 0.3322 - val_accuracy: 0.8519\n",
      "Epoch 1256/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3561 - accuracy: 0.8365 - val_loss: 0.3323 - val_accuracy: 0.9259\n",
      "Epoch 1257/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3621 - accuracy: 0.8365 - val_loss: 0.3358 - val_accuracy: 0.9630\n",
      "Epoch 1258/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3630 - accuracy: 0.8365 - val_loss: 0.3303 - val_accuracy: 0.9259\n",
      "Epoch 1259/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3631 - accuracy: 0.8365 - val_loss: 0.3388 - val_accuracy: 0.8519\n",
      "Epoch 1260/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3617 - accuracy: 0.8654 - val_loss: 0.3301 - val_accuracy: 0.8889\n",
      "Epoch 1261/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3639 - accuracy: 0.8269 - val_loss: 0.3398 - val_accuracy: 0.9630\n",
      "Epoch 1262/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3648 - accuracy: 0.8365 - val_loss: 0.3298 - val_accuracy: 0.9259\n",
      "Epoch 1263/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 115us/step - loss: 0.3595 - accuracy: 0.8365 - val_loss: 0.3369 - val_accuracy: 0.8519\n",
      "Epoch 1264/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3608 - accuracy: 0.8558 - val_loss: 0.3305 - val_accuracy: 0.8519\n",
      "Epoch 1265/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3594 - accuracy: 0.8077 - val_loss: 0.3297 - val_accuracy: 0.9259\n",
      "Epoch 1266/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3589 - accuracy: 0.8462 - val_loss: 0.3293 - val_accuracy: 0.9259\n",
      "Epoch 1267/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3579 - accuracy: 0.8269 - val_loss: 0.3371 - val_accuracy: 0.8519\n",
      "Epoch 1268/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3651 - accuracy: 0.8654 - val_loss: 0.3382 - val_accuracy: 0.8519\n",
      "Epoch 1269/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.84 - 0s 115us/step - loss: 0.3649 - accuracy: 0.8558 - val_loss: 0.3325 - val_accuracy: 0.8519\n",
      "Epoch 1270/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3593 - accuracy: 0.8462 - val_loss: 0.3371 - val_accuracy: 0.8519\n",
      "Epoch 1271/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3599 - accuracy: 0.8750 - val_loss: 0.3291 - val_accuracy: 0.8889\n",
      "Epoch 1272/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3599 - accuracy: 0.8173 - val_loss: 0.3285 - val_accuracy: 0.9259\n",
      "Epoch 1273/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3592 - accuracy: 0.8365 - val_loss: 0.3300 - val_accuracy: 0.8519\n",
      "Epoch 1274/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3561 - accuracy: 0.8365 - val_loss: 0.3282 - val_accuracy: 0.9259\n",
      "Epoch 1275/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3555 - accuracy: 0.8269 - val_loss: 0.3285 - val_accuracy: 0.8889\n",
      "Epoch 1276/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3555 - accuracy: 0.8269 - val_loss: 0.3285 - val_accuracy: 0.8889\n",
      "Epoch 1277/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3573 - accuracy: 0.8269 - val_loss: 0.3285 - val_accuracy: 0.8519\n",
      "Epoch 1278/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3551 - accuracy: 0.8365 - val_loss: 0.3323 - val_accuracy: 0.8519\n",
      "Epoch 1279/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3577 - accuracy: 0.8462 - val_loss: 0.3284 - val_accuracy: 0.8519\n",
      "Epoch 1280/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3555 - accuracy: 0.8269 - val_loss: 0.3283 - val_accuracy: 0.8519\n",
      "Epoch 1281/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3547 - accuracy: 0.8365 - val_loss: 0.3298 - val_accuracy: 0.8519\n",
      "Epoch 1282/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3556 - accuracy: 0.8462 - val_loss: 0.3281 - val_accuracy: 0.8519\n",
      "Epoch 1283/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3544 - accuracy: 0.8269 - val_loss: 0.3270 - val_accuracy: 0.9259\n",
      "Epoch 1284/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3542 - accuracy: 0.8269 - val_loss: 0.3285 - val_accuracy: 0.8519\n",
      "Epoch 1285/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3561 - accuracy: 0.8558 - val_loss: 0.3309 - val_accuracy: 0.8519\n",
      "Epoch 1286/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3569 - accuracy: 0.8365 - val_loss: 0.3266 - val_accuracy: 0.9259\n",
      "Epoch 1287/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3560 - accuracy: 0.8269 - val_loss: 0.3268 - val_accuracy: 0.8889\n",
      "Epoch 1288/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3549 - accuracy: 0.8269 - val_loss: 0.3263 - val_accuracy: 0.9259\n",
      "Epoch 1289/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3553 - accuracy: 0.8365 - val_loss: 0.3299 - val_accuracy: 0.9630\n",
      "Epoch 1290/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3589 - accuracy: 0.8462 - val_loss: 0.3261 - val_accuracy: 0.9259\n",
      "Epoch 1291/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3536 - accuracy: 0.8462 - val_loss: 0.3300 - val_accuracy: 0.8519\n",
      "Epoch 1292/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3560 - accuracy: 0.8269 - val_loss: 0.3258 - val_accuracy: 0.9259\n",
      "Epoch 1293/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3543 - accuracy: 0.8365 - val_loss: 0.3263 - val_accuracy: 0.9259\n",
      "Epoch 1294/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3554 - accuracy: 0.8462 - val_loss: 0.3265 - val_accuracy: 0.9259\n",
      "Epoch 1295/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3581 - accuracy: 0.8462 - val_loss: 0.3254 - val_accuracy: 0.9259\n",
      "Epoch 1296/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3605 - accuracy: 0.8462 - val_loss: 0.3425 - val_accuracy: 0.8148\n",
      "Epoch 1297/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3672 - accuracy: 0.8558 - val_loss: 0.3318 - val_accuracy: 0.8519\n",
      "Epoch 1298/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3562 - accuracy: 0.8558 - val_loss: 0.3250 - val_accuracy: 0.9259\n",
      "Epoch 1299/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3544 - accuracy: 0.8558 - val_loss: 0.3257 - val_accuracy: 0.9259\n",
      "Epoch 1300/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3531 - accuracy: 0.8365 - val_loss: 0.3253 - val_accuracy: 0.8889\n",
      "Epoch 1301/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3528 - accuracy: 0.8365 - val_loss: 0.3334 - val_accuracy: 0.8519\n",
      "Epoch 1302/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3585 - accuracy: 0.8558 - val_loss: 0.3308 - val_accuracy: 0.8519\n",
      "Epoch 1303/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3561 - accuracy: 0.8558 - val_loss: 0.3271 - val_accuracy: 0.8519\n",
      "Epoch 1304/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3563 - accuracy: 0.8558 - val_loss: 0.3245 - val_accuracy: 0.8889\n",
      "Epoch 1305/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3504 - accuracy: 0.8365 - val_loss: 0.3281 - val_accuracy: 0.9630\n",
      "Epoch 1306/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3592 - accuracy: 0.8462 - val_loss: 0.3272 - val_accuracy: 0.9630\n",
      "Epoch 1307/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3587 - accuracy: 0.8365 - val_loss: 0.3281 - val_accuracy: 0.9630\n",
      "Epoch 1308/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3587 - accuracy: 0.8365 - val_loss: 0.3250 - val_accuracy: 0.9259\n",
      "Epoch 1309/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3538 - accuracy: 0.8462 - val_loss: 0.3234 - val_accuracy: 0.9259\n",
      "Epoch 1310/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3500 - accuracy: 0.8462 - val_loss: 0.3278 - val_accuracy: 0.8519\n",
      "Epoch 1311/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3551 - accuracy: 0.8558 - val_loss: 0.3245 - val_accuracy: 0.8519\n",
      "Epoch 1312/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3559 - accuracy: 0.8462 - val_loss: 0.3328 - val_accuracy: 0.9630\n",
      "Epoch 1313/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3615 - accuracy: 0.8269 - val_loss: 0.3229 - val_accuracy: 0.9259\n",
      "Epoch 1314/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3520 - accuracy: 0.8269 - val_loss: 0.3345 - val_accuracy: 0.8519\n",
      "Epoch 1315/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.3556 - accuracy: 0.8558 - val_loss: 0.3230 - val_accuracy: 0.9259\n",
      "Epoch 1316/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3496 - accuracy: 0.8365 - val_loss: 0.3250 - val_accuracy: 0.9630\n",
      "Epoch 1317/2000\n",
      "104/104 [==============================] - 0s 231us/step - loss: 0.3540 - accuracy: 0.8462 - val_loss: 0.3224 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1318/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3564 - accuracy: 0.8365 - val_loss: 0.3292 - val_accuracy: 0.8519\n",
      "Epoch 1319/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3547 - accuracy: 0.8365 - val_loss: 0.3245 - val_accuracy: 0.8519\n",
      "Epoch 1320/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3528 - accuracy: 0.8462 - val_loss: 0.3263 - val_accuracy: 0.8519\n",
      "Epoch 1321/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3532 - accuracy: 0.8462 - val_loss: 0.3219 - val_accuracy: 0.9259\n",
      "Epoch 1322/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3497 - accuracy: 0.8269 - val_loss: 0.3226 - val_accuracy: 0.8889\n",
      "Epoch 1323/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3506 - accuracy: 0.8462 - val_loss: 0.3278 - val_accuracy: 0.8519\n",
      "Epoch 1324/2000\n",
      "104/104 [==============================] - 0s 134us/step - loss: 0.3550 - accuracy: 0.8558 - val_loss: 0.3232 - val_accuracy: 0.8519\n",
      "Epoch 1325/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3558 - accuracy: 0.8365 - val_loss: 0.3263 - val_accuracy: 0.9630\n",
      "Epoch 1326/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3549 - accuracy: 0.8269 - val_loss: 0.3222 - val_accuracy: 0.8889\n",
      "Epoch 1327/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3498 - accuracy: 0.8462 - val_loss: 0.3252 - val_accuracy: 0.8519\n",
      "Epoch 1328/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3510 - accuracy: 0.8462 - val_loss: 0.3222 - val_accuracy: 0.8889\n",
      "Epoch 1329/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3496 - accuracy: 0.8269 - val_loss: 0.3223 - val_accuracy: 0.8519\n",
      "Epoch 1330/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3508 - accuracy: 0.8462 - val_loss: 0.3228 - val_accuracy: 0.8519\n",
      "Epoch 1331/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3487 - accuracy: 0.8365 - val_loss: 0.3212 - val_accuracy: 0.9259\n",
      "Epoch 1332/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3504 - accuracy: 0.8462 - val_loss: 0.3210 - val_accuracy: 0.8889\n",
      "Epoch 1333/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3485 - accuracy: 0.8269 - val_loss: 0.3203 - val_accuracy: 0.9259\n",
      "Epoch 1334/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3515 - accuracy: 0.8365 - val_loss: 0.3274 - val_accuracy: 0.9630\n",
      "Epoch 1335/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3768 - accuracy: 0.8269 - val_loss: 0.3325 - val_accuracy: 0.9630\n",
      "Epoch 1336/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3511 - accuracy: 0.8269 - val_loss: 0.3346 - val_accuracy: 0.8148\n",
      "Epoch 1337/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3669 - accuracy: 0.8365 - val_loss: 0.3421 - val_accuracy: 0.8148\n",
      "Epoch 1338/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3569 - accuracy: 0.8750 - val_loss: 0.3197 - val_accuracy: 0.9259\n",
      "Epoch 1339/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3642 - accuracy: 0.8269 - val_loss: 0.3379 - val_accuracy: 0.9630\n",
      "Epoch 1340/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3662 - accuracy: 0.8269 - val_loss: 0.3197 - val_accuracy: 0.9259\n",
      "Epoch 1341/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3490 - accuracy: 0.8269 - val_loss: 0.3242 - val_accuracy: 0.8519\n",
      "Epoch 1342/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3492 - accuracy: 0.8462 - val_loss: 0.3203 - val_accuracy: 0.8889\n",
      "Epoch 1343/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3519 - accuracy: 0.8269 - val_loss: 0.3198 - val_accuracy: 0.9259\n",
      "Epoch 1344/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3481 - accuracy: 0.8462 - val_loss: 0.3212 - val_accuracy: 0.8519\n",
      "Epoch 1345/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3470 - accuracy: 0.8462 - val_loss: 0.3284 - val_accuracy: 0.8519\n",
      "Epoch 1346/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3536 - accuracy: 0.8654 - val_loss: 0.3249 - val_accuracy: 0.8519\n",
      "Epoch 1347/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3520 - accuracy: 0.8558 - val_loss: 0.3244 - val_accuracy: 0.8519\n",
      "Epoch 1348/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3486 - accuracy: 0.8365 - val_loss: 0.3191 - val_accuracy: 0.9259\n",
      "Epoch 1349/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3468 - accuracy: 0.8269 - val_loss: 0.3183 - val_accuracy: 0.9259\n",
      "Epoch 1350/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3470 - accuracy: 0.8462 - val_loss: 0.3193 - val_accuracy: 0.9259\n",
      "Epoch 1351/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3469 - accuracy: 0.8365 - val_loss: 0.3198 - val_accuracy: 0.8519\n",
      "Epoch 1352/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3523 - accuracy: 0.8462 - val_loss: 0.3237 - val_accuracy: 0.8519\n",
      "Epoch 1353/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3525 - accuracy: 0.8269 - val_loss: 0.3178 - val_accuracy: 0.9259\n",
      "Epoch 1354/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3473 - accuracy: 0.8365 - val_loss: 0.3178 - val_accuracy: 0.9259\n",
      "Epoch 1355/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3482 - accuracy: 0.8462 - val_loss: 0.3177 - val_accuracy: 0.9259\n",
      "Epoch 1356/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3519 - accuracy: 0.8269 - val_loss: 0.3213 - val_accuracy: 0.8519\n",
      "Epoch 1357/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3470 - accuracy: 0.8365 - val_loss: 0.3174 - val_accuracy: 0.9259\n",
      "Epoch 1358/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3457 - accuracy: 0.8173 - val_loss: 0.3177 - val_accuracy: 0.9259\n",
      "Epoch 1359/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3455 - accuracy: 0.8269 - val_loss: 0.3232 - val_accuracy: 0.8519\n",
      "Epoch 1360/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3494 - accuracy: 0.8558 - val_loss: 0.3202 - val_accuracy: 0.8519\n",
      "Epoch 1361/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3478 - accuracy: 0.8365 - val_loss: 0.3203 - val_accuracy: 0.8519\n",
      "Epoch 1362/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3463 - accuracy: 0.8462 - val_loss: 0.3219 - val_accuracy: 0.8519\n",
      "Epoch 1363/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3469 - accuracy: 0.8462 - val_loss: 0.3176 - val_accuracy: 0.8889\n",
      "Epoch 1364/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3440 - accuracy: 0.8269 - val_loss: 0.3174 - val_accuracy: 0.9259\n",
      "Epoch 1365/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3530 - accuracy: 0.8462 - val_loss: 0.3294 - val_accuracy: 0.9630\n",
      "Epoch 1366/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3637 - accuracy: 0.8269 - val_loss: 0.3185 - val_accuracy: 0.9630\n",
      "Epoch 1367/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3499 - accuracy: 0.8462 - val_loss: 0.3163 - val_accuracy: 0.9259\n",
      "Epoch 1368/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3439 - accuracy: 0.8365 - val_loss: 0.3176 - val_accuracy: 0.8889\n",
      "Epoch 1369/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3473 - accuracy: 0.8365 - val_loss: 0.3200 - val_accuracy: 0.8519\n",
      "Epoch 1370/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3439 - accuracy: 0.8269 - val_loss: 0.3160 - val_accuracy: 0.9259\n",
      "Epoch 1371/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3476 - accuracy: 0.8462 - val_loss: 0.3197 - val_accuracy: 0.9630\n",
      "Epoch 1372/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3593 - accuracy: 0.8269 - val_loss: 0.3199 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1373/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3453 - accuracy: 0.8269 - val_loss: 0.3315 - val_accuracy: 0.8148\n",
      "Epoch 1374/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3615 - accuracy: 0.8558 - val_loss: 0.3283 - val_accuracy: 0.8519\n",
      "Epoch 1375/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3477 - accuracy: 0.8558 - val_loss: 0.3205 - val_accuracy: 0.9630\n",
      "Epoch 1376/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3576 - accuracy: 0.8173 - val_loss: 0.3267 - val_accuracy: 0.9630\n",
      "Epoch 1377/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3725 - accuracy: 0.8365 - val_loss: 0.3190 - val_accuracy: 0.9630\n",
      "Epoch 1378/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3493 - accuracy: 0.8365 - val_loss: 0.3397 - val_accuracy: 0.8148\n",
      "Epoch 1379/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3624 - accuracy: 0.8462 - val_loss: 0.3191 - val_accuracy: 0.8519\n",
      "Epoch 1380/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3630 - accuracy: 0.8269 - val_loss: 0.3334 - val_accuracy: 0.9630\n",
      "Epoch 1381/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.90 - 0s 154us/step - loss: 0.3572 - accuracy: 0.8558 - val_loss: 0.3166 - val_accuracy: 0.8519\n",
      "Epoch 1382/2000\n",
      "104/104 [==============================] - 0s 250us/step - loss: 0.3550 - accuracy: 0.8654 - val_loss: 0.3270 - val_accuracy: 0.8519\n",
      "Epoch 1383/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3425 - accuracy: 0.8654 - val_loss: 0.3162 - val_accuracy: 0.9630\n",
      "Epoch 1384/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3637 - accuracy: 0.8173 - val_loss: 0.3205 - val_accuracy: 0.9630\n",
      "Epoch 1385/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3556 - accuracy: 0.8558 - val_loss: 0.3413 - val_accuracy: 0.8148\n",
      "Epoch 1386/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3740 - accuracy: 0.8173 - val_loss: 0.3426 - val_accuracy: 0.8148\n",
      "Epoch 1387/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3560 - accuracy: 0.8365 - val_loss: 0.3151 - val_accuracy: 0.9630\n",
      "Epoch 1388/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3632 - accuracy: 0.8269 - val_loss: 0.3231 - val_accuracy: 0.9630\n",
      "Epoch 1389/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3533 - accuracy: 0.8173 - val_loss: 0.3172 - val_accuracy: 0.8519\n",
      "Epoch 1390/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3450 - accuracy: 0.8462 - val_loss: 0.3268 - val_accuracy: 0.8519\n",
      "Epoch 1391/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.3581 - accuracy: 0.8365 - val_loss: 0.3264 - val_accuracy: 0.8519\n",
      "Epoch 1392/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3457 - accuracy: 0.8558 - val_loss: 0.3130 - val_accuracy: 0.9259\n",
      "Epoch 1393/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.3419 - accuracy: 0.8462 - val_loss: 0.3179 - val_accuracy: 0.9630\n",
      "Epoch 1394/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3479 - accuracy: 0.8365 - val_loss: 0.3127 - val_accuracy: 0.9259\n",
      "Epoch 1395/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3373 - accuracy: 0.8558 - val_loss: 0.3220 - val_accuracy: 0.8519\n",
      "Epoch 1396/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3575 - accuracy: 0.8558 - val_loss: 0.3309 - val_accuracy: 0.8148\n",
      "Epoch 1397/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3432 - accuracy: 0.8750 - val_loss: 0.3127 - val_accuracy: 0.9259\n",
      "Epoch 1398/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3542 - accuracy: 0.8365 - val_loss: 0.3289 - val_accuracy: 0.9630\n",
      "Epoch 1399/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3534 - accuracy: 0.8173 - val_loss: 0.3124 - val_accuracy: 0.9259\n",
      "Epoch 1400/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3456 - accuracy: 0.8365 - val_loss: 0.3204 - val_accuracy: 0.8519\n",
      "Epoch 1401/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3444 - accuracy: 0.8365 - val_loss: 0.3118 - val_accuracy: 0.9259\n",
      "Epoch 1402/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3434 - accuracy: 0.8462 - val_loss: 0.3130 - val_accuracy: 0.9630\n",
      "Epoch 1403/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3480 - accuracy: 0.8269 - val_loss: 0.3116 - val_accuracy: 0.9259\n",
      "Epoch 1404/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3398 - accuracy: 0.8558 - val_loss: 0.3127 - val_accuracy: 0.9630\n",
      "Epoch 1405/2000\n",
      "104/104 [==============================] - 0s 116us/step - loss: 0.3435 - accuracy: 0.8462 - val_loss: 0.3116 - val_accuracy: 0.9259\n",
      "Epoch 1406/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3381 - accuracy: 0.8365 - val_loss: 0.3185 - val_accuracy: 0.8519\n",
      "Epoch 1407/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3504 - accuracy: 0.8846 - val_loss: 0.3271 - val_accuracy: 0.8519\n",
      "Epoch 1408/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3433 - accuracy: 0.8558 - val_loss: 0.3119 - val_accuracy: 0.9630\n",
      "Epoch 1409/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3502 - accuracy: 0.8365 - val_loss: 0.3216 - val_accuracy: 0.9630\n",
      "Epoch 1410/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3478 - accuracy: 0.8365 - val_loss: 0.3137 - val_accuracy: 0.8519\n",
      "Epoch 1411/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3517 - accuracy: 0.8558 - val_loss: 0.3435 - val_accuracy: 0.8148\n",
      "Epoch 1412/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3618 - accuracy: 0.8365 - val_loss: 0.3151 - val_accuracy: 0.8519\n",
      "Epoch 1413/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3471 - accuracy: 0.8462 - val_loss: 0.3361 - val_accuracy: 0.8889\n",
      "Epoch 1414/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3671 - accuracy: 0.8365 - val_loss: 0.3129 - val_accuracy: 0.9630\n",
      "Epoch 1415/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3456 - accuracy: 0.8365 - val_loss: 0.3241 - val_accuracy: 0.8519\n",
      "Epoch 1416/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3490 - accuracy: 0.8558 - val_loss: 0.3214 - val_accuracy: 0.8519\n",
      "Epoch 1417/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3435 - accuracy: 0.8750 - val_loss: 0.3110 - val_accuracy: 0.9259\n",
      "Epoch 1418/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3398 - accuracy: 0.8365 - val_loss: 0.3098 - val_accuracy: 0.9259\n",
      "Epoch 1419/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3369 - accuracy: 0.8462 - val_loss: 0.3189 - val_accuracy: 0.8519\n",
      "Epoch 1420/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3516 - accuracy: 0.8558 - val_loss: 0.3305 - val_accuracy: 0.8148\n",
      "Epoch 1421/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3493 - accuracy: 0.8558 - val_loss: 0.3095 - val_accuracy: 0.9259\n",
      "Epoch 1422/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3426 - accuracy: 0.8462 - val_loss: 0.3114 - val_accuracy: 0.9630\n",
      "Epoch 1423/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3408 - accuracy: 0.8462 - val_loss: 0.3113 - val_accuracy: 0.8889\n",
      "Epoch 1424/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3400 - accuracy: 0.8365 - val_loss: 0.3095 - val_accuracy: 0.9259\n",
      "Epoch 1425/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3356 - accuracy: 0.8365 - val_loss: 0.3208 - val_accuracy: 0.9630\n",
      "Epoch 1426/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3622 - accuracy: 0.8365 - val_loss: 0.3155 - val_accuracy: 0.9630\n",
      "Epoch 1427/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3445 - accuracy: 0.8365 - val_loss: 0.3171 - val_accuracy: 0.8519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1428/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3441 - accuracy: 0.8750 - val_loss: 0.3135 - val_accuracy: 0.8519\n",
      "Epoch 1429/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3431 - accuracy: 0.8365 - val_loss: 0.3106 - val_accuracy: 0.9630\n",
      "Epoch 1430/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3475 - accuracy: 0.8365 - val_loss: 0.3111 - val_accuracy: 0.8889\n",
      "Epoch 1431/2000\n",
      "104/104 [==============================] - 0s 142us/step - loss: 0.3381 - accuracy: 0.8365 - val_loss: 0.3087 - val_accuracy: 0.9259\n",
      "Epoch 1432/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3397 - accuracy: 0.8365 - val_loss: 0.3082 - val_accuracy: 0.9259\n",
      "Epoch 1433/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.3381 - accuracy: 0.8365 - val_loss: 0.3087 - val_accuracy: 0.9259\n",
      "Epoch 1434/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3374 - accuracy: 0.8365 - val_loss: 0.3080 - val_accuracy: 0.9259\n",
      "Epoch 1435/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3402 - accuracy: 0.8365 - val_loss: 0.3097 - val_accuracy: 0.9630\n",
      "Epoch 1436/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3410 - accuracy: 0.8462 - val_loss: 0.3077 - val_accuracy: 0.9259\n",
      "Epoch 1437/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3369 - accuracy: 0.8462 - val_loss: 0.3091 - val_accuracy: 0.9259\n",
      "Epoch 1438/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3421 - accuracy: 0.8558 - val_loss: 0.3132 - val_accuracy: 0.8519\n",
      "Epoch 1439/2000\n",
      "104/104 [==============================] - 0s 221us/step - loss: 0.3399 - accuracy: 0.8462 - val_loss: 0.3077 - val_accuracy: 0.9259\n",
      "Epoch 1440/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3377 - accuracy: 0.8365 - val_loss: 0.3073 - val_accuracy: 0.9259\n",
      "Epoch 1441/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3428 - accuracy: 0.8462 - val_loss: 0.3108 - val_accuracy: 0.9630\n",
      "Epoch 1442/2000\n",
      "104/104 [==============================] - 0s 240us/step - loss: 0.3419 - accuracy: 0.8462 - val_loss: 0.3071 - val_accuracy: 0.9259\n",
      "Epoch 1443/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3360 - accuracy: 0.8365 - val_loss: 0.3135 - val_accuracy: 0.8519\n",
      "Epoch 1444/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3404 - accuracy: 0.8462 - val_loss: 0.3145 - val_accuracy: 0.8519\n",
      "Epoch 1445/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.3434 - accuracy: 0.8365 - val_loss: 0.3075 - val_accuracy: 0.9259\n",
      "Epoch 1446/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3362 - accuracy: 0.8365 - val_loss: 0.3067 - val_accuracy: 0.9259\n",
      "Epoch 1447/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3293 - accuracy: 0.90 - 0s 144us/step - loss: 0.3353 - accuracy: 0.8558 - val_loss: 0.3071 - val_accuracy: 0.9630\n",
      "Epoch 1448/2000\n",
      "104/104 [==============================] - 0s 240us/step - loss: 0.3397 - accuracy: 0.8462 - val_loss: 0.3068 - val_accuracy: 0.9259\n",
      "Epoch 1449/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3371 - accuracy: 0.8269 - val_loss: 0.3165 - val_accuracy: 0.8519\n",
      "Epoch 1450/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3392 - accuracy: 0.8654 - val_loss: 0.3073 - val_accuracy: 0.9259\n",
      "Epoch 1451/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3403 - accuracy: 0.8269 - val_loss: 0.3094 - val_accuracy: 0.9630\n",
      "Epoch 1452/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3432 - accuracy: 0.8365 - val_loss: 0.3059 - val_accuracy: 0.9259\n",
      "Epoch 1453/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3342 - accuracy: 0.8462 - val_loss: 0.3146 - val_accuracy: 0.8519\n",
      "Epoch 1454/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3418 - accuracy: 0.8558 - val_loss: 0.3136 - val_accuracy: 0.8519\n",
      "Epoch 1455/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3373 - accuracy: 0.8558 - val_loss: 0.3065 - val_accuracy: 0.9259\n",
      "Epoch 1456/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3364 - accuracy: 0.8365 - val_loss: 0.3061 - val_accuracy: 0.9630\n",
      "Epoch 1457/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3448 - accuracy: 0.8365 - val_loss: 0.3079 - val_accuracy: 0.9630\n",
      "Epoch 1458/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3356 - accuracy: 0.8462 - val_loss: 0.3086 - val_accuracy: 0.8889\n",
      "Epoch 1459/2000\n",
      "104/104 [==============================] - 0s 231us/step - loss: 0.3396 - accuracy: 0.8750 - val_loss: 0.3328 - val_accuracy: 0.8148\n",
      "Epoch 1460/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3529 - accuracy: 0.8654 - val_loss: 0.3087 - val_accuracy: 0.8889\n",
      "Epoch 1461/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3343 - accuracy: 0.8462 - val_loss: 0.3049 - val_accuracy: 0.9259\n",
      "Epoch 1462/2000\n",
      "104/104 [==============================] - 0s 126us/step - loss: 0.3355 - accuracy: 0.8462 - val_loss: 0.3100 - val_accuracy: 0.9630\n",
      "Epoch 1463/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3405 - accuracy: 0.8365 - val_loss: 0.3048 - val_accuracy: 0.9259\n",
      "Epoch 1464/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3405 - accuracy: 0.8365 - val_loss: 0.3159 - val_accuracy: 0.8519\n",
      "Epoch 1465/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3362 - accuracy: 0.8558 - val_loss: 0.3048 - val_accuracy: 0.9630\n",
      "Epoch 1466/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3354 - accuracy: 0.8365 - val_loss: 0.3156 - val_accuracy: 0.9630\n",
      "Epoch 1467/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3476 - accuracy: 0.8269 - val_loss: 0.3043 - val_accuracy: 0.9259\n",
      "Epoch 1468/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3326 - accuracy: 0.8558 - val_loss: 0.3073 - val_accuracy: 0.8889\n",
      "Epoch 1469/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3383 - accuracy: 0.8462 - val_loss: 0.3106 - val_accuracy: 0.8519\n",
      "Epoch 1470/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3379 - accuracy: 0.8462 - val_loss: 0.3041 - val_accuracy: 0.9259\n",
      "Epoch 1471/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2826 - accuracy: 0.93 - 0s 144us/step - loss: 0.3335 - accuracy: 0.8462 - val_loss: 0.3055 - val_accuracy: 0.9259\n",
      "Epoch 1472/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3361 - accuracy: 0.8462 - val_loss: 0.3071 - val_accuracy: 0.8889\n",
      "Epoch 1473/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3381 - accuracy: 0.8558 - val_loss: 0.3048 - val_accuracy: 0.9630\n",
      "Epoch 1474/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3375 - accuracy: 0.8462 - val_loss: 0.3044 - val_accuracy: 0.9630\n",
      "Epoch 1475/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3345 - accuracy: 0.8558 - val_loss: 0.3046 - val_accuracy: 0.9259\n",
      "Epoch 1476/2000\n",
      "104/104 [==============================] - 0s 279us/step - loss: 0.3328 - accuracy: 0.8365 - val_loss: 0.3054 - val_accuracy: 0.9259\n",
      "Epoch 1477/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3331 - accuracy: 0.8365 - val_loss: 0.3048 - val_accuracy: 0.9259\n",
      "Epoch 1478/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3357 - accuracy: 0.8365 - val_loss: 0.3041 - val_accuracy: 0.9259\n",
      "Epoch 1479/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3362 - accuracy: 0.8462 - val_loss: 0.3073 - val_accuracy: 0.8519\n",
      "Epoch 1480/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3333 - accuracy: 0.8462 - val_loss: 0.3037 - val_accuracy: 0.9259\n",
      "Epoch 1481/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3319 - accuracy: 0.8365 - val_loss: 0.3030 - val_accuracy: 0.9630\n",
      "Epoch 1482/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 135us/step - loss: 0.3371 - accuracy: 0.8462 - val_loss: 0.3063 - val_accuracy: 0.9630\n",
      "Epoch 1483/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3356 - accuracy: 0.8462 - val_loss: 0.3035 - val_accuracy: 0.9259\n",
      "Epoch 1484/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3341 - accuracy: 0.8365 - val_loss: 0.3027 - val_accuracy: 0.9259\n",
      "Epoch 1485/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3351 - accuracy: 0.8462 - val_loss: 0.3024 - val_accuracy: 0.9259\n",
      "Epoch 1486/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3337 - accuracy: 0.8365 - val_loss: 0.3051 - val_accuracy: 0.9259\n",
      "Epoch 1487/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3319 - accuracy: 0.8462 - val_loss: 0.3027 - val_accuracy: 0.9259\n",
      "Epoch 1488/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3315 - accuracy: 0.8462 - val_loss: 0.3020 - val_accuracy: 0.9259\n",
      "Epoch 1489/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3313 - accuracy: 0.8462 - val_loss: 0.3042 - val_accuracy: 0.9630\n",
      "Epoch 1490/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3370 - accuracy: 0.8462 - val_loss: 0.3024 - val_accuracy: 0.9630\n",
      "Epoch 1491/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.3312 - accuracy: 0.8462 - val_loss: 0.3057 - val_accuracy: 0.8889\n",
      "Epoch 1492/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.3386 - accuracy: 0.8654 - val_loss: 0.3084 - val_accuracy: 0.8519\n",
      "Epoch 1493/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3322 - accuracy: 0.8558 - val_loss: 0.3026 - val_accuracy: 0.9630\n",
      "Epoch 1494/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3350 - accuracy: 0.8462 - val_loss: 0.3026 - val_accuracy: 0.9630\n",
      "Epoch 1495/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3321 - accuracy: 0.8462 - val_loss: 0.3037 - val_accuracy: 0.9259\n",
      "Epoch 1496/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.3355 - accuracy: 0.8462 - val_loss: 0.3134 - val_accuracy: 0.8519\n",
      "Epoch 1497/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3343 - accuracy: 0.8654 - val_loss: 0.3009 - val_accuracy: 0.9259\n",
      "Epoch 1498/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3393 - accuracy: 0.8462 - val_loss: 0.3046 - val_accuracy: 0.9630\n",
      "Epoch 1499/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3376 - accuracy: 0.8462 - val_loss: 0.3009 - val_accuracy: 0.9630\n",
      "Epoch 1500/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3326 - accuracy: 0.8462 - val_loss: 0.3008 - val_accuracy: 0.9630\n",
      "Epoch 1501/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3334 - accuracy: 0.8462 - val_loss: 0.3010 - val_accuracy: 0.9630\n",
      "Epoch 1502/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.3423 - accuracy: 0.8462 - val_loss: 0.3005 - val_accuracy: 0.9630\n",
      "Epoch 1503/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3362 - accuracy: 0.8365 - val_loss: 0.3116 - val_accuracy: 0.8519\n",
      "Epoch 1504/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3367 - accuracy: 0.8654 - val_loss: 0.3023 - val_accuracy: 0.9259\n",
      "Epoch 1505/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3312 - accuracy: 0.8558 - val_loss: 0.3024 - val_accuracy: 0.9630\n",
      "Epoch 1506/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3367 - accuracy: 0.8462 - val_loss: 0.3003 - val_accuracy: 0.9630\n",
      "Epoch 1507/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3333 - accuracy: 0.8462 - val_loss: 0.2998 - val_accuracy: 0.9259\n",
      "Epoch 1508/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3375 - accuracy: 0.8462 - val_loss: 0.3161 - val_accuracy: 0.8519\n",
      "Epoch 1509/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3401 - accuracy: 0.8654 - val_loss: 0.3064 - val_accuracy: 0.8519\n",
      "Epoch 1510/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3301 - accuracy: 0.8462 - val_loss: 0.2996 - val_accuracy: 0.9259\n",
      "Epoch 1511/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3284 - accuracy: 0.8462 - val_loss: 0.3067 - val_accuracy: 0.9630\n",
      "Epoch 1512/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3504 - accuracy: 0.8365 - val_loss: 0.3054 - val_accuracy: 0.9630\n",
      "Epoch 1513/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3334 - accuracy: 0.8558 - val_loss: 0.3056 - val_accuracy: 0.8519\n",
      "Epoch 1514/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3338 - accuracy: 0.8750 - val_loss: 0.3160 - val_accuracy: 0.8519\n",
      "Epoch 1515/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3377 - accuracy: 0.8654 - val_loss: 0.3031 - val_accuracy: 0.8889\n",
      "Epoch 1516/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3353 - accuracy: 0.8462 - val_loss: 0.2999 - val_accuracy: 0.9630\n",
      "Epoch 1517/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3288 - accuracy: 0.8462 - val_loss: 0.3021 - val_accuracy: 0.9259\n",
      "Epoch 1518/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3272 - accuracy: 0.8654 - val_loss: 0.3175 - val_accuracy: 0.8519\n",
      "Epoch 1519/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3411 - accuracy: 0.8750 - val_loss: 0.3155 - val_accuracy: 0.8519\n",
      "Epoch 1520/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3336 - accuracy: 0.8750 - val_loss: 0.2988 - val_accuracy: 0.9259\n",
      "Epoch 1521/2000\n",
      "104/104 [==============================] - 0s 116us/step - loss: 0.3321 - accuracy: 0.8462 - val_loss: 0.3056 - val_accuracy: 0.9630\n",
      "Epoch 1522/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3396 - accuracy: 0.8365 - val_loss: 0.2988 - val_accuracy: 0.9259\n",
      "Epoch 1523/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3290 - accuracy: 0.8558 - val_loss: 0.3088 - val_accuracy: 0.8519\n",
      "Epoch 1524/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3340 - accuracy: 0.8750 - val_loss: 0.3006 - val_accuracy: 0.9259\n",
      "Epoch 1525/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3405 - accuracy: 0.8173 - val_loss: 0.3015 - val_accuracy: 0.9630\n",
      "Epoch 1526/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3304 - accuracy: 0.8365 - val_loss: 0.3022 - val_accuracy: 0.8889\n",
      "Epoch 1527/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3303 - accuracy: 0.8462 - val_loss: 0.3021 - val_accuracy: 0.8889\n",
      "Epoch 1528/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3288 - accuracy: 0.8558 - val_loss: 0.2984 - val_accuracy: 0.9259\n",
      "Epoch 1529/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3286 - accuracy: 0.8558 - val_loss: 0.2984 - val_accuracy: 0.9259\n",
      "Epoch 1530/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3303 - accuracy: 0.8462 - val_loss: 0.2997 - val_accuracy: 0.9259\n",
      "Epoch 1531/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3269 - accuracy: 0.8462 - val_loss: 0.2974 - val_accuracy: 0.9259\n",
      "Epoch 1532/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3274 - accuracy: 0.8558 - val_loss: 0.2977 - val_accuracy: 0.9630\n",
      "Epoch 1533/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3319 - accuracy: 0.8462 - val_loss: 0.2975 - val_accuracy: 0.9630\n",
      "Epoch 1534/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3233 - accuracy: 0.8558 - val_loss: 0.3089 - val_accuracy: 0.8519\n",
      "Epoch 1535/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3399 - accuracy: 0.8750 - val_loss: 0.3255 - val_accuracy: 0.8148\n",
      "Epoch 1536/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3430 - accuracy: 0.8750 - val_loss: 0.3004 - val_accuracy: 0.9259\n",
      "Epoch 1537/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 135us/step - loss: 0.3349 - accuracy: 0.8269 - val_loss: 0.3108 - val_accuracy: 0.9630\n",
      "Epoch 1538/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3414 - accuracy: 0.8462 - val_loss: 0.2965 - val_accuracy: 0.9259\n",
      "Epoch 1539/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3396 - accuracy: 0.8654 - val_loss: 0.3107 - val_accuracy: 0.8519\n",
      "Epoch 1540/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3315 - accuracy: 0.8462 - val_loss: 0.2967 - val_accuracy: 0.9630\n",
      "Epoch 1541/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3294 - accuracy: 0.8462 - val_loss: 0.2978 - val_accuracy: 0.9630\n",
      "Epoch 1542/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3296 - accuracy: 0.8462 - val_loss: 0.2963 - val_accuracy: 0.9259\n",
      "Epoch 1543/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3338 - accuracy: 0.8462 - val_loss: 0.3000 - val_accuracy: 0.9259\n",
      "Epoch 1544/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3247 - accuracy: 0.8654 - val_loss: 0.2965 - val_accuracy: 0.9630\n",
      "Epoch 1545/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3313 - accuracy: 0.8462 - val_loss: 0.2958 - val_accuracy: 0.9630\n",
      "Epoch 1546/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3231 - accuracy: 0.8654 - val_loss: 0.3100 - val_accuracy: 0.8519\n",
      "Epoch 1547/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3400 - accuracy: 0.8750 - val_loss: 0.3161 - val_accuracy: 0.8519\n",
      "Epoch 1548/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3326 - accuracy: 0.8654 - val_loss: 0.2954 - val_accuracy: 0.9630\n",
      "Epoch 1549/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3289 - accuracy: 0.8462 - val_loss: 0.2987 - val_accuracy: 0.9630\n",
      "Epoch 1550/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3347 - accuracy: 0.8365 - val_loss: 0.2954 - val_accuracy: 0.9259\n",
      "Epoch 1551/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3369 - accuracy: 0.8654 - val_loss: 0.3233 - val_accuracy: 0.8148\n",
      "Epoch 1552/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3466 - accuracy: 0.8462 - val_loss: 0.3060 - val_accuracy: 0.8519\n",
      "Epoch 1553/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3233 - accuracy: 0.8558 - val_loss: 0.2957 - val_accuracy: 0.9630\n",
      "Epoch 1554/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3359 - accuracy: 0.8365 - val_loss: 0.3097 - val_accuracy: 0.9630\n",
      "Epoch 1555/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3426 - accuracy: 0.8365 - val_loss: 0.2948 - val_accuracy: 0.9630\n",
      "Epoch 1556/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3209 - accuracy: 0.8558 - val_loss: 0.3105 - val_accuracy: 0.8519\n",
      "Epoch 1557/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3380 - accuracy: 0.8846 - val_loss: 0.3087 - val_accuracy: 0.8519\n",
      "Epoch 1558/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3239 - accuracy: 0.8654 - val_loss: 0.2957 - val_accuracy: 0.9630\n",
      "Epoch 1559/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3309 - accuracy: 0.8365 - val_loss: 0.3025 - val_accuracy: 0.9630\n",
      "Epoch 1560/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3363 - accuracy: 0.8365 - val_loss: 0.2948 - val_accuracy: 0.9630\n",
      "Epoch 1561/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3254 - accuracy: 0.8462 - val_loss: 0.2960 - val_accuracy: 0.9259\n",
      "Epoch 1562/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3271 - accuracy: 0.8462 - val_loss: 0.2951 - val_accuracy: 0.9259\n",
      "Epoch 1563/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3258 - accuracy: 0.8365 - val_loss: 0.2974 - val_accuracy: 0.9630\n",
      "Epoch 1564/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3299 - accuracy: 0.8462 - val_loss: 0.2937 - val_accuracy: 0.9259\n",
      "Epoch 1565/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3236 - accuracy: 0.8558 - val_loss: 0.2984 - val_accuracy: 0.9259\n",
      "Epoch 1566/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3418 - accuracy: 0.8558 - val_loss: 0.3126 - val_accuracy: 0.8519\n",
      "Epoch 1567/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3310 - accuracy: 0.8462 - val_loss: 0.2944 - val_accuracy: 0.9630\n",
      "Epoch 1568/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3341 - accuracy: 0.8558 - val_loss: 0.3004 - val_accuracy: 0.9630\n",
      "Epoch 1569/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3325 - accuracy: 0.8558 - val_loss: 0.2938 - val_accuracy: 0.9259\n",
      "Epoch 1570/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3244 - accuracy: 0.8462 - val_loss: 0.3077 - val_accuracy: 0.8519\n",
      "Epoch 1571/2000\n",
      "104/104 [==============================] - 0s 192us/step - loss: 0.3316 - accuracy: 0.8462 - val_loss: 0.2979 - val_accuracy: 0.9259\n",
      "Epoch 1572/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.90 - 0s 173us/step - loss: 0.3258 - accuracy: 0.8558 - val_loss: 0.2986 - val_accuracy: 0.8889\n",
      "Epoch 1573/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3274 - accuracy: 0.8365 - val_loss: 0.2938 - val_accuracy: 0.9259\n",
      "Epoch 1574/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.3232 - accuracy: 0.8558 - val_loss: 0.2933 - val_accuracy: 0.9259\n",
      "Epoch 1575/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3223 - accuracy: 0.8558 - val_loss: 0.2952 - val_accuracy: 0.9259\n",
      "Epoch 1576/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3277 - accuracy: 0.8462 - val_loss: 0.2925 - val_accuracy: 0.9259\n",
      "Epoch 1577/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3417 - accuracy: 0.8365 - val_loss: 0.3195 - val_accuracy: 0.8889\n",
      "Epoch 1578/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3472 - accuracy: 0.8462 - val_loss: 0.2928 - val_accuracy: 0.9259\n",
      "Epoch 1579/2000\n",
      "104/104 [==============================] - 0s 202us/step - loss: 0.3316 - accuracy: 0.8654 - val_loss: 0.3279 - val_accuracy: 0.8148\n",
      "Epoch 1580/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3459 - accuracy: 0.8654 - val_loss: 0.3049 - val_accuracy: 0.8519\n",
      "Epoch 1581/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3278 - accuracy: 0.8942 - val_loss: 0.2920 - val_accuracy: 0.9630\n",
      "Epoch 1582/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3219 - accuracy: 0.8558 - val_loss: 0.2946 - val_accuracy: 0.9259\n",
      "Epoch 1583/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3265 - accuracy: 0.8558 - val_loss: 0.3038 - val_accuracy: 0.8519\n",
      "Epoch 1584/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3288 - accuracy: 0.8365 - val_loss: 0.2925 - val_accuracy: 0.9259\n",
      "Epoch 1585/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3266 - accuracy: 0.8558 - val_loss: 0.2924 - val_accuracy: 0.9630\n",
      "Epoch 1586/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3259 - accuracy: 0.8462 - val_loss: 0.2923 - val_accuracy: 0.9630\n",
      "Epoch 1587/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3252 - accuracy: 0.8462 - val_loss: 0.2914 - val_accuracy: 0.9259\n",
      "Epoch 1588/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3211 - accuracy: 0.8654 - val_loss: 0.2987 - val_accuracy: 0.8519\n",
      "Epoch 1589/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3265 - accuracy: 0.8365 - val_loss: 0.2945 - val_accuracy: 0.9259\n",
      "Epoch 1590/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3240 - accuracy: 0.8462 - val_loss: 0.2954 - val_accuracy: 0.9259\n",
      "Epoch 1591/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3224 - accuracy: 0.8558 - val_loss: 0.2934 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1592/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3221 - accuracy: 0.8558 - val_loss: 0.2909 - val_accuracy: 0.9259\n",
      "Epoch 1593/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3243 - accuracy: 0.8654 - val_loss: 0.2912 - val_accuracy: 0.9259\n",
      "Epoch 1594/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3275 - accuracy: 0.8462 - val_loss: 0.2912 - val_accuracy: 0.9630\n",
      "Epoch 1595/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3273 - accuracy: 0.8462 - val_loss: 0.2965 - val_accuracy: 0.8889\n",
      "Epoch 1596/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3619 - accuracy: 0.84 - 0s 125us/step - loss: 0.3241 - accuracy: 0.8462 - val_loss: 0.2905 - val_accuracy: 0.9630\n",
      "Epoch 1597/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3225 - accuracy: 0.8558 - val_loss: 0.2904 - val_accuracy: 0.9630\n",
      "Epoch 1598/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3228 - accuracy: 0.8365 - val_loss: 0.2931 - val_accuracy: 0.9259\n",
      "Epoch 1599/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3210 - accuracy: 0.8558 - val_loss: 0.2910 - val_accuracy: 0.9259\n",
      "Epoch 1600/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3204 - accuracy: 0.8558 - val_loss: 0.2914 - val_accuracy: 0.9259\n",
      "Epoch 1601/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3214 - accuracy: 0.8558 - val_loss: 0.2910 - val_accuracy: 0.9259\n",
      "Epoch 1602/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3203 - accuracy: 0.8558 - val_loss: 0.2899 - val_accuracy: 0.9630\n",
      "Epoch 1603/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3216 - accuracy: 0.8558 - val_loss: 0.2900 - val_accuracy: 0.9630\n",
      "Epoch 1604/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3222 - accuracy: 0.8462 - val_loss: 0.2901 - val_accuracy: 0.9259\n",
      "Epoch 1605/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3188 - accuracy: 0.8462 - val_loss: 0.3002 - val_accuracy: 0.8519\n",
      "Epoch 1606/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3343 - accuracy: 0.8750 - val_loss: 0.3168 - val_accuracy: 0.8148\n",
      "Epoch 1607/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3336 - accuracy: 0.8558 - val_loss: 0.2913 - val_accuracy: 0.9259\n",
      "Epoch 1608/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3204 - accuracy: 0.8558 - val_loss: 0.2995 - val_accuracy: 0.9630\n",
      "Epoch 1609/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3361 - accuracy: 0.8462 - val_loss: 0.2897 - val_accuracy: 0.9630\n",
      "Epoch 1610/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3176 - accuracy: 0.8558 - val_loss: 0.3065 - val_accuracy: 0.8519\n",
      "Epoch 1611/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3373 - accuracy: 0.8654 - val_loss: 0.3174 - val_accuracy: 0.8148\n",
      "Epoch 1612/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3399 - accuracy: 0.8654 - val_loss: 0.2889 - val_accuracy: 0.9630\n",
      "Epoch 1613/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3229 - accuracy: 0.8462 - val_loss: 0.2894 - val_accuracy: 0.9630\n",
      "Epoch 1614/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3206 - accuracy: 0.8558 - val_loss: 0.2909 - val_accuracy: 0.9259\n",
      "Epoch 1615/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3207 - accuracy: 0.8462 - val_loss: 0.2958 - val_accuracy: 0.8889\n",
      "Epoch 1616/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3226 - accuracy: 0.8462 - val_loss: 0.2888 - val_accuracy: 0.9259\n",
      "Epoch 1617/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3196 - accuracy: 0.8462 - val_loss: 0.2980 - val_accuracy: 0.9630\n",
      "Epoch 1618/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3368 - accuracy: 0.8365 - val_loss: 0.2888 - val_accuracy: 0.9630\n",
      "Epoch 1619/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3167 - accuracy: 0.8558 - val_loss: 0.3004 - val_accuracy: 0.8519\n",
      "Epoch 1620/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3239 - accuracy: 0.8654 - val_loss: 0.2907 - val_accuracy: 0.9259\n",
      "Epoch 1621/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3173 - accuracy: 0.8558 - val_loss: 0.2937 - val_accuracy: 0.9630\n",
      "Epoch 1622/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3318 - accuracy: 0.8558 - val_loss: 0.2930 - val_accuracy: 0.9630\n",
      "Epoch 1623/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3290 - accuracy: 0.8558 - val_loss: 0.2886 - val_accuracy: 0.9259\n",
      "Epoch 1624/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3178 - accuracy: 0.8654 - val_loss: 0.2951 - val_accuracy: 0.8889\n",
      "Epoch 1625/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3296 - accuracy: 0.8558 - val_loss: 0.3020 - val_accuracy: 0.8519\n",
      "Epoch 1626/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3205 - accuracy: 0.8558 - val_loss: 0.2878 - val_accuracy: 0.9630\n",
      "Epoch 1627/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3195 - accuracy: 0.8462 - val_loss: 0.2912 - val_accuracy: 0.9630\n",
      "Epoch 1628/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3296 - accuracy: 0.8365 - val_loss: 0.2876 - val_accuracy: 0.9630\n",
      "Epoch 1629/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3340 - accuracy: 0.8269 - val_loss: 0.3010 - val_accuracy: 0.8519\n",
      "Epoch 1630/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3218 - accuracy: 0.8462 - val_loss: 0.2872 - val_accuracy: 0.9630\n",
      "Epoch 1631/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3208 - accuracy: 0.8462 - val_loss: 0.2871 - val_accuracy: 0.9630\n",
      "Epoch 1632/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3234 - accuracy: 0.8462 - val_loss: 0.2902 - val_accuracy: 0.9259\n",
      "Epoch 1633/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3227 - accuracy: 0.8462 - val_loss: 0.2868 - val_accuracy: 0.9630\n",
      "Epoch 1634/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3218 - accuracy: 0.8462 - val_loss: 0.2952 - val_accuracy: 0.8889\n",
      "Epoch 1635/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3222 - accuracy: 0.8462 - val_loss: 0.2946 - val_accuracy: 0.8889\n",
      "Epoch 1636/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3222 - accuracy: 0.8462 - val_loss: 0.2882 - val_accuracy: 0.9259\n",
      "Epoch 1637/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3180 - accuracy: 0.8654 - val_loss: 0.2884 - val_accuracy: 0.9259\n",
      "Epoch 1638/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3199 - accuracy: 0.8462 - val_loss: 0.2869 - val_accuracy: 0.9630\n",
      "Epoch 1639/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3190 - accuracy: 0.8462 - val_loss: 0.2877 - val_accuracy: 0.9259\n",
      "Epoch 1640/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3178 - accuracy: 0.8558 - val_loss: 0.2901 - val_accuracy: 0.9259\n",
      "Epoch 1641/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3248 - accuracy: 0.87 - 0s 144us/step - loss: 0.3171 - accuracy: 0.8558 - val_loss: 0.2864 - val_accuracy: 0.9259\n",
      "Epoch 1642/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3173 - accuracy: 0.8558 - val_loss: 0.2873 - val_accuracy: 0.9630\n",
      "Epoch 1643/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3225 - accuracy: 0.8462 - val_loss: 0.2880 - val_accuracy: 0.9630\n",
      "Epoch 1644/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3199 - accuracy: 0.8462 - val_loss: 0.2881 - val_accuracy: 0.9259\n",
      "Epoch 1645/2000\n",
      "104/104 [==============================] - 0s 87us/step - loss: 0.3251 - accuracy: 0.8462 - val_loss: 0.2922 - val_accuracy: 0.9259\n",
      "Epoch 1646/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 106us/step - loss: 0.3177 - accuracy: 0.8558 - val_loss: 0.2856 - val_accuracy: 0.9630\n",
      "Epoch 1647/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3167 - accuracy: 0.8462 - val_loss: 0.2876 - val_accuracy: 0.9630\n",
      "Epoch 1648/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3241 - accuracy: 0.8558 - val_loss: 0.2875 - val_accuracy: 0.9630\n",
      "Epoch 1649/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3209 - accuracy: 0.8462 - val_loss: 0.2876 - val_accuracy: 0.9259\n",
      "Epoch 1650/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3173 - accuracy: 0.8558 - val_loss: 0.2871 - val_accuracy: 0.9259\n",
      "Epoch 1651/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3589 - accuracy: 0.87 - 0s 135us/step - loss: 0.3199 - accuracy: 0.8750 - val_loss: 0.2874 - val_accuracy: 0.9259\n",
      "Epoch 1652/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3183 - accuracy: 0.8654 - val_loss: 0.3013 - val_accuracy: 0.8519\n",
      "Epoch 1653/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3224 - accuracy: 0.8846 - val_loss: 0.2857 - val_accuracy: 0.9259\n",
      "Epoch 1654/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3279 - accuracy: 0.8365 - val_loss: 0.2928 - val_accuracy: 0.9630\n",
      "Epoch 1655/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3311 - accuracy: 0.8558 - val_loss: 0.2859 - val_accuracy: 0.9259\n",
      "Epoch 1656/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3162 - accuracy: 0.8558 - val_loss: 0.2871 - val_accuracy: 0.9259\n",
      "Epoch 1657/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3152 - accuracy: 0.8654 - val_loss: 0.2846 - val_accuracy: 0.9630\n",
      "Epoch 1658/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3189 - accuracy: 0.8462 - val_loss: 0.2844 - val_accuracy: 0.9630\n",
      "Epoch 1659/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3183 - accuracy: 0.8558 - val_loss: 0.2891 - val_accuracy: 0.9259\n",
      "Epoch 1660/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3158 - accuracy: 0.8462 - val_loss: 0.2846 - val_accuracy: 0.9259\n",
      "Epoch 1661/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3155 - accuracy: 0.8654 - val_loss: 0.2841 - val_accuracy: 0.9630\n",
      "Epoch 1662/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3252 - accuracy: 0.8558 - val_loss: 0.2869 - val_accuracy: 0.9630\n",
      "Epoch 1663/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3184 - accuracy: 0.8558 - val_loss: 0.2856 - val_accuracy: 0.9259\n",
      "Epoch 1664/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3169 - accuracy: 0.8462 - val_loss: 0.2903 - val_accuracy: 0.9259\n",
      "Epoch 1665/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3186 - accuracy: 0.8462 - val_loss: 0.2849 - val_accuracy: 0.9259\n",
      "Epoch 1666/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3257 - accuracy: 0.8462 - val_loss: 0.2871 - val_accuracy: 0.9259\n",
      "Epoch 1667/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3165 - accuracy: 0.8462 - val_loss: 0.2861 - val_accuracy: 0.9630\n",
      "Epoch 1668/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3254 - accuracy: 0.8558 - val_loss: 0.2864 - val_accuracy: 0.9630\n",
      "Epoch 1669/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3126 - accuracy: 0.8462 - val_loss: 0.2943 - val_accuracy: 0.8519\n",
      "Epoch 1670/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3287 - accuracy: 0.8846 - val_loss: 0.3282 - val_accuracy: 0.8148\n",
      "Epoch 1671/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3372 - accuracy: 0.8750 - val_loss: 0.2866 - val_accuracy: 0.9259\n",
      "Epoch 1672/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3113 - accuracy: 0.8462 - val_loss: 0.2990 - val_accuracy: 0.9630\n",
      "Epoch 1673/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3476 - accuracy: 0.8462 - val_loss: 0.2889 - val_accuracy: 0.9630\n",
      "Epoch 1674/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3228 - accuracy: 0.8558 - val_loss: 0.2956 - val_accuracy: 0.8519\n",
      "Epoch 1675/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3209 - accuracy: 0.8558 - val_loss: 0.2927 - val_accuracy: 0.8519\n",
      "Epoch 1676/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3186 - accuracy: 0.8654 - val_loss: 0.2880 - val_accuracy: 0.9259\n",
      "Epoch 1677/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3239 - accuracy: 0.8462 - val_loss: 0.2835 - val_accuracy: 0.9630\n",
      "Epoch 1678/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3121 - accuracy: 0.8558 - val_loss: 0.2905 - val_accuracy: 0.9259\n",
      "Epoch 1679/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3450 - accuracy: 0.8462 - val_loss: 0.3157 - val_accuracy: 0.8148\n",
      "Epoch 1680/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3256 - accuracy: 0.8750 - val_loss: 0.2825 - val_accuracy: 0.9630\n",
      "Epoch 1681/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3218 - accuracy: 0.8558 - val_loss: 0.3006 - val_accuracy: 0.9630\n",
      "Epoch 1682/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3434 - accuracy: 0.8558 - val_loss: 0.2851 - val_accuracy: 0.9630\n",
      "Epoch 1683/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3207 - accuracy: 0.8558 - val_loss: 0.2822 - val_accuracy: 0.9630\n",
      "Epoch 1684/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3123 - accuracy: 0.8558 - val_loss: 0.2876 - val_accuracy: 0.9259\n",
      "Epoch 1685/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3156 - accuracy: 0.8558 - val_loss: 0.2872 - val_accuracy: 0.9259\n",
      "Epoch 1686/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3164 - accuracy: 0.8462 - val_loss: 0.2884 - val_accuracy: 0.9259\n",
      "Epoch 1687/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.3167 - accuracy: 0.8654 - val_loss: 0.3014 - val_accuracy: 0.8519\n",
      "Epoch 1688/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3238 - accuracy: 0.8654 - val_loss: 0.2870 - val_accuracy: 0.9259\n",
      "Epoch 1689/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3141 - accuracy: 0.8462 - val_loss: 0.2843 - val_accuracy: 0.9259\n",
      "Epoch 1690/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3137 - accuracy: 0.8558 - val_loss: 0.2851 - val_accuracy: 0.9259\n",
      "Epoch 1691/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3139 - accuracy: 0.8462 - val_loss: 0.2836 - val_accuracy: 0.9259\n",
      "Epoch 1692/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3124 - accuracy: 0.8558 - val_loss: 0.2843 - val_accuracy: 0.9259\n",
      "Epoch 1693/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3144 - accuracy: 0.8558 - val_loss: 0.2846 - val_accuracy: 0.9259\n",
      "Epoch 1694/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3125 - accuracy: 0.8558 - val_loss: 0.2813 - val_accuracy: 0.9630\n",
      "Epoch 1695/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3171 - accuracy: 0.8558 - val_loss: 0.2851 - val_accuracy: 0.9630\n",
      "Epoch 1696/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3171 - accuracy: 0.8654 - val_loss: 0.2822 - val_accuracy: 0.9259\n",
      "Epoch 1697/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3103 - accuracy: 0.8750 - val_loss: 0.2917 - val_accuracy: 0.8519\n",
      "Epoch 1698/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3180 - accuracy: 0.8654 - val_loss: 0.2900 - val_accuracy: 0.8889\n",
      "Epoch 1699/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3207 - accuracy: 0.8462 - val_loss: 0.2816 - val_accuracy: 0.9259\n",
      "Epoch 1700/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3102 - accuracy: 0.8750 - val_loss: 0.2876 - val_accuracy: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1701/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3144 - accuracy: 0.8558 - val_loss: 0.2914 - val_accuracy: 0.8519\n",
      "Epoch 1702/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3212 - accuracy: 0.8558 - val_loss: 0.2901 - val_accuracy: 0.8889\n",
      "Epoch 1703/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3124 - accuracy: 0.8558 - val_loss: 0.2806 - val_accuracy: 0.9630\n",
      "Epoch 1704/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3213 - accuracy: 0.8462 - val_loss: 0.2837 - val_accuracy: 0.9630\n",
      "Epoch 1705/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3195 - accuracy: 0.8462 - val_loss: 0.2811 - val_accuracy: 0.9259\n",
      "Epoch 1706/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3127 - accuracy: 0.8558 - val_loss: 0.2871 - val_accuracy: 0.9259\n",
      "Epoch 1707/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3127 - accuracy: 0.8558 - val_loss: 0.2809 - val_accuracy: 0.9259\n",
      "Epoch 1708/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3120 - accuracy: 0.8654 - val_loss: 0.2805 - val_accuracy: 0.9630\n",
      "Epoch 1709/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3191 - accuracy: 0.8558 - val_loss: 0.2799 - val_accuracy: 0.9630\n",
      "Epoch 1710/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3085 - accuracy: 0.8558 - val_loss: 0.2879 - val_accuracy: 0.9259\n",
      "Epoch 1711/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3242 - accuracy: 0.8750 - val_loss: 0.3089 - val_accuracy: 0.8148\n",
      "Epoch 1712/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3234 - accuracy: 0.8558 - val_loss: 0.2794 - val_accuracy: 0.9630\n",
      "Epoch 1713/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3123 - accuracy: 0.8365 - val_loss: 0.2840 - val_accuracy: 0.9630\n",
      "Epoch 1714/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3184 - accuracy: 0.8558 - val_loss: 0.2795 - val_accuracy: 0.9630\n",
      "Epoch 1715/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3103 - accuracy: 0.8846 - val_loss: 0.3033 - val_accuracy: 0.8519\n",
      "Epoch 1716/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3221 - accuracy: 0.8846 - val_loss: 0.2835 - val_accuracy: 0.9259\n",
      "Epoch 1717/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3112 - accuracy: 0.8558 - val_loss: 0.2826 - val_accuracy: 0.9630\n",
      "Epoch 1718/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3173 - accuracy: 0.8462 - val_loss: 0.2787 - val_accuracy: 0.9630\n",
      "Epoch 1719/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3130 - accuracy: 0.8750 - val_loss: 0.2904 - val_accuracy: 0.8519\n",
      "Epoch 1720/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3148 - accuracy: 0.8558 - val_loss: 0.2848 - val_accuracy: 0.9259\n",
      "Epoch 1721/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3113 - accuracy: 0.8558 - val_loss: 0.2788 - val_accuracy: 0.9630\n",
      "Epoch 1722/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3185 - accuracy: 0.8558 - val_loss: 0.2836 - val_accuracy: 0.9630\n",
      "Epoch 1723/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3182 - accuracy: 0.8365 - val_loss: 0.2790 - val_accuracy: 0.9259\n",
      "Epoch 1724/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3155 - accuracy: 0.8558 - val_loss: 0.2865 - val_accuracy: 0.9259\n",
      "Epoch 1725/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3056 - accuracy: 0.8462 - val_loss: 0.2795 - val_accuracy: 0.9630\n",
      "Epoch 1726/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3314 - accuracy: 0.8558 - val_loss: 0.2930 - val_accuracy: 0.9630\n",
      "Epoch 1727/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3210 - accuracy: 0.8462 - val_loss: 0.2811 - val_accuracy: 0.9259\n",
      "Epoch 1728/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3202 - accuracy: 0.8558 - val_loss: 0.3163 - val_accuracy: 0.8148\n",
      "Epoch 1729/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3250 - accuracy: 0.8846 - val_loss: 0.2793 - val_accuracy: 0.9259\n",
      "Epoch 1730/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3245 - accuracy: 0.8365 - val_loss: 0.2927 - val_accuracy: 0.9630\n",
      "Epoch 1731/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3248 - accuracy: 0.8365 - val_loss: 0.2780 - val_accuracy: 0.9630\n",
      "Epoch 1732/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3103 - accuracy: 0.8558 - val_loss: 0.2935 - val_accuracy: 0.8519\n",
      "Epoch 1733/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3154 - accuracy: 0.8558 - val_loss: 0.2793 - val_accuracy: 0.9259\n",
      "Epoch 1734/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3072 - accuracy: 0.8654 - val_loss: 0.2773 - val_accuracy: 0.9630\n",
      "Epoch 1735/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3123 - accuracy: 0.8558 - val_loss: 0.2772 - val_accuracy: 0.9630\n",
      "Epoch 1736/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3115 - accuracy: 0.8462 - val_loss: 0.2822 - val_accuracy: 0.9259\n",
      "Epoch 1737/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3086 - accuracy: 0.8462 - val_loss: 0.2771 - val_accuracy: 0.9630\n",
      "Epoch 1738/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3107 - accuracy: 0.8558 - val_loss: 0.2773 - val_accuracy: 0.9630\n",
      "Epoch 1739/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3147 - accuracy: 0.8462 - val_loss: 0.2796 - val_accuracy: 0.9259\n",
      "Epoch 1740/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3091 - accuracy: 0.8750 - val_loss: 0.2766 - val_accuracy: 0.9630\n",
      "Epoch 1741/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3097 - accuracy: 0.8558 - val_loss: 0.2767 - val_accuracy: 0.9630\n",
      "Epoch 1742/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3084 - accuracy: 0.8654 - val_loss: 0.2801 - val_accuracy: 0.9259\n",
      "Epoch 1743/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3088 - accuracy: 0.8654 - val_loss: 0.2782 - val_accuracy: 0.9259\n",
      "Epoch 1744/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3095 - accuracy: 0.8750 - val_loss: 0.2763 - val_accuracy: 0.9630\n",
      "Epoch 1745/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3102 - accuracy: 0.8462 - val_loss: 0.2765 - val_accuracy: 0.9630\n",
      "Epoch 1746/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3114 - accuracy: 0.8558 - val_loss: 0.2765 - val_accuracy: 0.9630\n",
      "Epoch 1747/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3116 - accuracy: 0.8462 - val_loss: 0.2760 - val_accuracy: 0.9630\n",
      "Epoch 1748/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3088 - accuracy: 0.8654 - val_loss: 0.2814 - val_accuracy: 0.9259\n",
      "Epoch 1749/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3102 - accuracy: 0.8750 - val_loss: 0.2808 - val_accuracy: 0.9259\n",
      "Epoch 1750/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3087 - accuracy: 0.8558 - val_loss: 0.2835 - val_accuracy: 0.9259\n",
      "Epoch 1751/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3102 - accuracy: 0.8558 - val_loss: 0.2762 - val_accuracy: 0.9630\n",
      "Epoch 1752/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3088 - accuracy: 0.8558 - val_loss: 0.2772 - val_accuracy: 0.9259\n",
      "Epoch 1753/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3087 - accuracy: 0.8558 - val_loss: 0.2755 - val_accuracy: 0.9630\n",
      "Epoch 1754/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3061 - accuracy: 0.8750 - val_loss: 0.2835 - val_accuracy: 0.9259\n",
      "Epoch 1755/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3138 - accuracy: 0.8558 - val_loss: 0.2803 - val_accuracy: 0.9259\n",
      "Epoch 1756/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 135us/step - loss: 0.3087 - accuracy: 0.8462 - val_loss: 0.2778 - val_accuracy: 0.9259\n",
      "Epoch 1757/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3071 - accuracy: 0.8558 - val_loss: 0.2751 - val_accuracy: 0.9630\n",
      "Epoch 1758/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3081 - accuracy: 0.8558 - val_loss: 0.2755 - val_accuracy: 0.9630\n",
      "Epoch 1759/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3061 - accuracy: 0.8558 - val_loss: 0.2828 - val_accuracy: 0.9259\n",
      "Epoch 1760/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3113 - accuracy: 0.8558 - val_loss: 0.2855 - val_accuracy: 0.9259\n",
      "Epoch 1761/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3096 - accuracy: 0.8462 - val_loss: 0.2749 - val_accuracy: 0.9630\n",
      "Epoch 1762/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3088 - accuracy: 0.8462 - val_loss: 0.2775 - val_accuracy: 0.9259\n",
      "Epoch 1763/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3087 - accuracy: 0.8750 - val_loss: 0.2749 - val_accuracy: 0.9630\n",
      "Epoch 1764/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3070 - accuracy: 0.8558 - val_loss: 0.2832 - val_accuracy: 0.9259\n",
      "Epoch 1765/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3141 - accuracy: 0.8654 - val_loss: 0.2869 - val_accuracy: 0.8889\n",
      "Epoch 1766/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3069 - accuracy: 0.8942 - val_loss: 0.2743 - val_accuracy: 0.9630\n",
      "Epoch 1767/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3062 - accuracy: 0.8462 - val_loss: 0.2752 - val_accuracy: 0.9630\n",
      "Epoch 1768/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3084 - accuracy: 0.8462 - val_loss: 0.2754 - val_accuracy: 0.9259\n",
      "Epoch 1769/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3075 - accuracy: 0.8462 - val_loss: 0.2808 - val_accuracy: 0.9259\n",
      "Epoch 1770/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3086 - accuracy: 0.8462 - val_loss: 0.2793 - val_accuracy: 0.9259\n",
      "Epoch 1771/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3070 - accuracy: 0.8462 - val_loss: 0.2779 - val_accuracy: 0.9259\n",
      "Epoch 1772/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3051 - accuracy: 0.8558 - val_loss: 0.2740 - val_accuracy: 0.9630\n",
      "Epoch 1773/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2028 - accuracy: 0.96 - 0s 144us/step - loss: 0.3063 - accuracy: 0.8558 - val_loss: 0.2736 - val_accuracy: 0.9630\n",
      "Epoch 1774/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3066 - accuracy: 0.8558 - val_loss: 0.2736 - val_accuracy: 0.9630\n",
      "Epoch 1775/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3064 - accuracy: 0.8558 - val_loss: 0.2761 - val_accuracy: 0.9259\n",
      "Epoch 1776/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3054 - accuracy: 0.8654 - val_loss: 0.2764 - val_accuracy: 0.9259\n",
      "Epoch 1777/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3065 - accuracy: 0.8462 - val_loss: 0.2768 - val_accuracy: 0.9259\n",
      "Epoch 1778/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3064 - accuracy: 0.8558 - val_loss: 0.2735 - val_accuracy: 0.9630\n",
      "Epoch 1779/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3060 - accuracy: 0.8654 - val_loss: 0.2778 - val_accuracy: 0.9259\n",
      "Epoch 1780/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3076 - accuracy: 0.8654 - val_loss: 0.2764 - val_accuracy: 0.9259\n",
      "Epoch 1781/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.3110 - accuracy: 0.8558 - val_loss: 0.2736 - val_accuracy: 0.9630\n",
      "Epoch 1782/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3043 - accuracy: 0.8654 - val_loss: 0.2774 - val_accuracy: 0.9259\n",
      "Epoch 1783/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3112 - accuracy: 0.8654 - val_loss: 0.2845 - val_accuracy: 0.9259\n",
      "Epoch 1784/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3124 - accuracy: 0.8558 - val_loss: 0.2736 - val_accuracy: 0.9630\n",
      "Epoch 1785/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3123 - accuracy: 0.8558 - val_loss: 0.2741 - val_accuracy: 0.9630\n",
      "Epoch 1786/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3058 - accuracy: 0.8654 - val_loss: 0.2752 - val_accuracy: 0.9259\n",
      "Epoch 1787/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3105 - accuracy: 0.8750 - val_loss: 0.2811 - val_accuracy: 0.9259\n",
      "Epoch 1788/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3099 - accuracy: 0.8558 - val_loss: 0.2727 - val_accuracy: 0.9630\n",
      "Epoch 1789/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3039 - accuracy: 0.8654 - val_loss: 0.2778 - val_accuracy: 0.9259\n",
      "Epoch 1790/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3114 - accuracy: 0.8750 - val_loss: 0.3001 - val_accuracy: 0.8148\n",
      "Epoch 1791/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3150 - accuracy: 0.8750 - val_loss: 0.2749 - val_accuracy: 0.9259\n",
      "Epoch 1792/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3027 - accuracy: 0.8365 - val_loss: 0.2752 - val_accuracy: 0.9630\n",
      "Epoch 1793/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3119 - accuracy: 0.8558 - val_loss: 0.2720 - val_accuracy: 0.9630\n",
      "Epoch 1794/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3047 - accuracy: 0.8654 - val_loss: 0.2787 - val_accuracy: 0.9259\n",
      "Epoch 1795/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3063 - accuracy: 0.8558 - val_loss: 0.2812 - val_accuracy: 0.9259\n",
      "Epoch 1796/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3180 - accuracy: 0.90 - 0s 135us/step - loss: 0.3096 - accuracy: 0.8558 - val_loss: 0.2771 - val_accuracy: 0.9259\n",
      "Epoch 1797/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3043 - accuracy: 0.8558 - val_loss: 0.2727 - val_accuracy: 0.9630\n",
      "Epoch 1798/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3026 - accuracy: 0.8654 - val_loss: 0.2714 - val_accuracy: 0.9630\n",
      "Epoch 1799/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3075 - accuracy: 0.8558 - val_loss: 0.2722 - val_accuracy: 0.9630\n",
      "Epoch 1800/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3032 - accuracy: 0.8654 - val_loss: 0.2729 - val_accuracy: 0.9630\n",
      "Epoch 1801/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3153 - accuracy: 0.8558 - val_loss: 0.2730 - val_accuracy: 0.9630\n",
      "Epoch 1802/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.3047 - accuracy: 0.8654 - val_loss: 0.2772 - val_accuracy: 0.9259\n",
      "Epoch 1803/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3080 - accuracy: 0.8654 - val_loss: 0.2859 - val_accuracy: 0.8519\n",
      "Epoch 1804/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3078 - accuracy: 0.8750 - val_loss: 0.2712 - val_accuracy: 0.9630\n",
      "Epoch 1805/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3062 - accuracy: 0.8654 - val_loss: 0.2723 - val_accuracy: 0.9630\n",
      "Epoch 1806/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3060 - accuracy: 0.8558 - val_loss: 0.2720 - val_accuracy: 0.9630\n",
      "Epoch 1807/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3029 - accuracy: 0.8750 - val_loss: 0.2739 - val_accuracy: 0.9259\n",
      "Epoch 1808/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3045 - accuracy: 0.8558 - val_loss: 0.2742 - val_accuracy: 0.9259\n",
      "Epoch 1809/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3096 - accuracy: 0.8462 - val_loss: 0.2724 - val_accuracy: 0.9630\n",
      "Epoch 1810/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 0s 135us/step - loss: 0.3045 - accuracy: 0.8750 - val_loss: 0.2759 - val_accuracy: 0.9259\n",
      "Epoch 1811/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3104 - accuracy: 0.8558 - val_loss: 0.2886 - val_accuracy: 0.8519\n",
      "Epoch 1812/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3120 - accuracy: 0.8558 - val_loss: 0.2706 - val_accuracy: 0.9630\n",
      "Epoch 1813/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3134 - accuracy: 0.8558 - val_loss: 0.2701 - val_accuracy: 0.9630\n",
      "Epoch 1814/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3006 - accuracy: 0.8654 - val_loss: 0.2792 - val_accuracy: 0.9259\n",
      "Epoch 1815/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3061 - accuracy: 0.8558 - val_loss: 0.2891 - val_accuracy: 0.8519\n",
      "Epoch 1816/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3130 - accuracy: 0.8846 - val_loss: 0.2798 - val_accuracy: 0.9259\n",
      "Epoch 1817/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3038 - accuracy: 0.8846 - val_loss: 0.2696 - val_accuracy: 0.9630\n",
      "Epoch 1818/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3031 - accuracy: 0.8654 - val_loss: 0.2697 - val_accuracy: 0.9630\n",
      "Epoch 1819/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3033 - accuracy: 0.8654 - val_loss: 0.2698 - val_accuracy: 0.9630\n",
      "Epoch 1820/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3019 - accuracy: 0.8654 - val_loss: 0.2720 - val_accuracy: 0.9259\n",
      "Epoch 1821/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3024 - accuracy: 0.8750 - val_loss: 0.2704 - val_accuracy: 0.9630\n",
      "Epoch 1822/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3053 - accuracy: 0.8654 - val_loss: 0.2756 - val_accuracy: 0.9259\n",
      "Epoch 1823/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3023 - accuracy: 0.8654 - val_loss: 0.2700 - val_accuracy: 0.9630\n",
      "Epoch 1824/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3004 - accuracy: 0.8654 - val_loss: 0.2690 - val_accuracy: 0.9630\n",
      "Epoch 1825/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3064 - accuracy: 0.8654 - val_loss: 0.2693 - val_accuracy: 0.9630\n",
      "Epoch 1826/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3041 - accuracy: 0.8462 - val_loss: 0.2863 - val_accuracy: 0.8519\n",
      "Epoch 1827/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3108 - accuracy: 0.8654 - val_loss: 0.2749 - val_accuracy: 0.9259\n",
      "Epoch 1828/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3033 - accuracy: 0.8558 - val_loss: 0.2735 - val_accuracy: 0.9259\n",
      "Epoch 1829/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3014 - accuracy: 0.8558 - val_loss: 0.2807 - val_accuracy: 0.9259\n",
      "Epoch 1830/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3072 - accuracy: 0.8750 - val_loss: 0.2817 - val_accuracy: 0.9259\n",
      "Epoch 1831/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3017 - accuracy: 0.8750 - val_loss: 0.2685 - val_accuracy: 0.9630\n",
      "Epoch 1832/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3050 - accuracy: 0.8654 - val_loss: 0.2697 - val_accuracy: 0.9630\n",
      "Epoch 1833/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3089 - accuracy: 0.8462 - val_loss: 0.2735 - val_accuracy: 0.9259\n",
      "Epoch 1834/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3012 - accuracy: 0.8558 - val_loss: 0.2773 - val_accuracy: 0.9259\n",
      "Epoch 1835/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3068 - accuracy: 0.8750 - val_loss: 0.2788 - val_accuracy: 0.9259\n",
      "Epoch 1836/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3020 - accuracy: 0.8558 - val_loss: 0.2681 - val_accuracy: 0.9630\n",
      "Epoch 1837/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.3022 - accuracy: 0.8654 - val_loss: 0.2714 - val_accuracy: 0.9630\n",
      "Epoch 1838/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3074 - accuracy: 0.8558 - val_loss: 0.2678 - val_accuracy: 0.9630\n",
      "Epoch 1839/2000\n",
      "104/104 [==============================] - 0s 116us/step - loss: 0.3011 - accuracy: 0.8750 - val_loss: 0.2720 - val_accuracy: 0.9259\n",
      "Epoch 1840/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3008 - accuracy: 0.8750 - val_loss: 0.2686 - val_accuracy: 0.9630\n",
      "Epoch 1841/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2995 - accuracy: 0.8750 - val_loss: 0.2682 - val_accuracy: 0.9630\n",
      "Epoch 1842/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3001 - accuracy: 0.8750 - val_loss: 0.2698 - val_accuracy: 0.9259\n",
      "Epoch 1843/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3000 - accuracy: 0.8750 - val_loss: 0.2684 - val_accuracy: 0.9630\n",
      "Epoch 1844/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2998 - accuracy: 0.8750 - val_loss: 0.2672 - val_accuracy: 0.9630\n",
      "Epoch 1845/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2990 - accuracy: 0.8558 - val_loss: 0.2739 - val_accuracy: 0.9259\n",
      "Epoch 1846/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3037 - accuracy: 0.8654 - val_loss: 0.2725 - val_accuracy: 0.9259\n",
      "Epoch 1847/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3117 - accuracy: 0.8654 - val_loss: 0.2682 - val_accuracy: 0.9630\n",
      "Epoch 1848/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3014 - accuracy: 0.8750 - val_loss: 0.2772 - val_accuracy: 0.9259\n",
      "Epoch 1849/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3149 - accuracy: 0.8846 - val_loss: 0.2866 - val_accuracy: 0.8519\n",
      "Epoch 1850/2000\n",
      "104/104 [==============================] - 0s 116us/step - loss: 0.3123 - accuracy: 0.8654 - val_loss: 0.2770 - val_accuracy: 0.9630\n",
      "Epoch 1851/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3202 - accuracy: 0.8462 - val_loss: 0.2701 - val_accuracy: 0.9630\n",
      "Epoch 1852/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3057 - accuracy: 0.8558 - val_loss: 0.2726 - val_accuracy: 0.9259\n",
      "Epoch 1853/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3011 - accuracy: 0.8750 - val_loss: 0.2793 - val_accuracy: 0.9259\n",
      "Epoch 1854/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3025 - accuracy: 0.8654 - val_loss: 0.2692 - val_accuracy: 0.9259\n",
      "Epoch 1855/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3527 - accuracy: 0.81 - 0s 106us/step - loss: 0.2963 - accuracy: 0.8750 - val_loss: 0.2668 - val_accuracy: 0.9630\n",
      "Epoch 1856/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3064 - accuracy: 0.8654 - val_loss: 0.2675 - val_accuracy: 0.9630\n",
      "Epoch 1857/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3005 - accuracy: 0.8750 - val_loss: 0.2698 - val_accuracy: 0.9259\n",
      "Epoch 1858/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.2985 - accuracy: 0.8558 - val_loss: 0.2768 - val_accuracy: 0.9259\n",
      "Epoch 1859/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3042 - accuracy: 0.8750 - val_loss: 0.2716 - val_accuracy: 0.9259\n",
      "Epoch 1860/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3022 - accuracy: 0.8654 - val_loss: 0.2661 - val_accuracy: 0.9630\n",
      "Epoch 1861/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3021 - accuracy: 0.8654 - val_loss: 0.2730 - val_accuracy: 0.9259\n",
      "Epoch 1862/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3017 - accuracy: 0.8654 - val_loss: 0.2779 - val_accuracy: 0.9259\n",
      "Epoch 1863/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3034 - accuracy: 0.8558 - val_loss: 0.2718 - val_accuracy: 0.9259\n",
      "Epoch 1864/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.3004 - accuracy: 0.8654 - val_loss: 0.2666 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1865/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.2973 - accuracy: 0.8750 - val_loss: 0.2683 - val_accuracy: 0.9259\n",
      "Epoch 1866/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2999 - accuracy: 0.8750 - val_loss: 0.2717 - val_accuracy: 0.9259\n",
      "Epoch 1867/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3007 - accuracy: 0.8942 - val_loss: 0.2942 - val_accuracy: 0.8519\n",
      "Epoch 1868/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3160 - accuracy: 0.8846 - val_loss: 0.2743 - val_accuracy: 0.9259\n",
      "Epoch 1869/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3002 - accuracy: 0.8558 - val_loss: 0.2660 - val_accuracy: 0.9630\n",
      "Epoch 1870/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3005 - accuracy: 0.8558 - val_loss: 0.2649 - val_accuracy: 0.9630\n",
      "Epoch 1871/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3053 - accuracy: 0.8750 - val_loss: 0.2655 - val_accuracy: 0.9630\n",
      "Epoch 1872/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3130 - accuracy: 0.8750 - val_loss: 0.2980 - val_accuracy: 0.8148\n",
      "Epoch 1873/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3109 - accuracy: 0.8750 - val_loss: 0.2670 - val_accuracy: 0.9630\n",
      "Epoch 1874/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2958 - accuracy: 0.8750 - val_loss: 0.2646 - val_accuracy: 0.9630\n",
      "Epoch 1875/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2996 - accuracy: 0.8654 - val_loss: 0.2651 - val_accuracy: 0.9630\n",
      "Epoch 1876/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2967 - accuracy: 0.8750 - val_loss: 0.2699 - val_accuracy: 0.9259\n",
      "Epoch 1877/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2988 - accuracy: 0.8462 - val_loss: 0.2754 - val_accuracy: 0.9259\n",
      "Epoch 1878/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3005 - accuracy: 0.8750 - val_loss: 0.2692 - val_accuracy: 0.9259\n",
      "Epoch 1879/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2975 - accuracy: 0.8558 - val_loss: 0.2651 - val_accuracy: 0.9630\n",
      "Epoch 1880/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2972 - accuracy: 0.8654 - val_loss: 0.2660 - val_accuracy: 0.9630\n",
      "Epoch 1881/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2974 - accuracy: 0.8654 - val_loss: 0.2714 - val_accuracy: 0.9259\n",
      "Epoch 1882/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2971 - accuracy: 0.8654 - val_loss: 0.2654 - val_accuracy: 0.9630\n",
      "Epoch 1883/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3032 - accuracy: 0.8654 - val_loss: 0.2640 - val_accuracy: 0.9630\n",
      "Epoch 1884/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2956 - accuracy: 0.8654 - val_loss: 0.2877 - val_accuracy: 0.8519\n",
      "Epoch 1885/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3133 - accuracy: 0.8846 - val_loss: 0.2739 - val_accuracy: 0.9259\n",
      "Epoch 1886/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3008 - accuracy: 0.8750 - val_loss: 0.2739 - val_accuracy: 0.9630\n",
      "Epoch 1887/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3212 - accuracy: 0.8558 - val_loss: 0.2650 - val_accuracy: 0.9630\n",
      "Epoch 1888/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3023 - accuracy: 0.8846 - val_loss: 0.2749 - val_accuracy: 0.9259\n",
      "Epoch 1889/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2995 - accuracy: 0.8654 - val_loss: 0.2677 - val_accuracy: 0.9259\n",
      "Epoch 1890/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2986 - accuracy: 0.8654 - val_loss: 0.2642 - val_accuracy: 0.9630\n",
      "Epoch 1891/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3025 - accuracy: 0.8750 - val_loss: 0.2638 - val_accuracy: 0.9630\n",
      "Epoch 1892/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2942 - accuracy: 0.8654 - val_loss: 0.2846 - val_accuracy: 0.8519\n",
      "Epoch 1893/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3294 - accuracy: 0.8654 - val_loss: 0.3087 - val_accuracy: 0.8148\n",
      "Epoch 1894/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3161 - accuracy: 0.8654 - val_loss: 0.2631 - val_accuracy: 0.9630\n",
      "Epoch 1895/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2972 - accuracy: 0.8750 - val_loss: 0.2633 - val_accuracy: 0.9630\n",
      "Epoch 1896/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3012 - accuracy: 0.8654 - val_loss: 0.2635 - val_accuracy: 0.9630\n",
      "Epoch 1897/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3008 - accuracy: 0.8558 - val_loss: 0.2626 - val_accuracy: 0.9630\n",
      "Epoch 1898/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2947 - accuracy: 0.8750 - val_loss: 0.2693 - val_accuracy: 0.9259\n",
      "Epoch 1899/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3003 - accuracy: 0.8654 - val_loss: 0.2720 - val_accuracy: 0.9259\n",
      "Epoch 1900/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3039 - accuracy: 0.8750 - val_loss: 0.2906 - val_accuracy: 0.8519\n",
      "Epoch 1901/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.3552 - accuracy: 0.90 - 0s 135us/step - loss: 0.3081 - accuracy: 0.8942 - val_loss: 0.2680 - val_accuracy: 0.9259\n",
      "Epoch 1902/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2961 - accuracy: 0.8750 - val_loss: 0.2623 - val_accuracy: 0.9630\n",
      "Epoch 1903/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2965 - accuracy: 0.8654 - val_loss: 0.2628 - val_accuracy: 0.9630\n",
      "Epoch 1904/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2994 - accuracy: 0.8558 - val_loss: 0.2676 - val_accuracy: 0.9259\n",
      "Epoch 1905/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2947 - accuracy: 0.8558 - val_loss: 0.2637 - val_accuracy: 0.9630\n",
      "Epoch 1906/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3035 - accuracy: 0.8750 - val_loss: 0.2628 - val_accuracy: 0.9630\n",
      "Epoch 1907/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3014 - accuracy: 0.8654 - val_loss: 0.2686 - val_accuracy: 0.9259\n",
      "Epoch 1908/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2963 - accuracy: 0.8654 - val_loss: 0.2646 - val_accuracy: 0.9630\n",
      "Epoch 1909/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.2967 - accuracy: 0.8750 - val_loss: 0.2635 - val_accuracy: 0.9630\n",
      "Epoch 1910/2000\n",
      "104/104 [==============================] - 0s 87us/step - loss: 0.2947 - accuracy: 0.8654 - val_loss: 0.2717 - val_accuracy: 0.9259\n",
      "Epoch 1911/2000\n",
      "104/104 [==============================] - 0s 87us/step - loss: 0.2968 - accuracy: 0.8558 - val_loss: 0.2652 - val_accuracy: 0.9259\n",
      "Epoch 1912/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2963 - accuracy: 0.8654 - val_loss: 0.2617 - val_accuracy: 0.9630\n",
      "Epoch 1913/2000\n",
      "104/104 [==============================] - 0s 87us/step - loss: 0.2975 - accuracy: 0.8750 - val_loss: 0.2615 - val_accuracy: 0.9630\n",
      "Epoch 1914/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2962 - accuracy: 0.8846 - val_loss: 0.2629 - val_accuracy: 0.9630\n",
      "Epoch 1915/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2933 - accuracy: 0.8558 - val_loss: 0.2634 - val_accuracy: 0.9630\n",
      "Epoch 1916/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3053 - accuracy: 0.8654 - val_loss: 0.2641 - val_accuracy: 0.9630\n",
      "Epoch 1917/2000\n",
      "104/104 [==============================] - 0s 87us/step - loss: 0.2978 - accuracy: 0.8462 - val_loss: 0.2714 - val_accuracy: 0.9259\n",
      "Epoch 1918/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3007 - accuracy: 0.8846 - val_loss: 0.2829 - val_accuracy: 0.8519\n",
      "Epoch 1919/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3004 - accuracy: 0.8942 - val_loss: 0.2623 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1920/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.2965 - accuracy: 0.8654 - val_loss: 0.2613 - val_accuracy: 0.9630\n",
      "Epoch 1921/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2963 - accuracy: 0.8750 - val_loss: 0.2625 - val_accuracy: 0.9630\n",
      "Epoch 1922/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2947 - accuracy: 0.8750 - val_loss: 0.2629 - val_accuracy: 0.9630\n",
      "Epoch 1923/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2922 - accuracy: 0.8750 - val_loss: 0.2607 - val_accuracy: 0.9630\n",
      "Epoch 1924/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2971 - accuracy: 0.8750 - val_loss: 0.2604 - val_accuracy: 0.9630\n",
      "Epoch 1925/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2925 - accuracy: 0.8750 - val_loss: 0.2653 - val_accuracy: 0.9259\n",
      "Epoch 1926/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2961 - accuracy: 0.8558 - val_loss: 0.2743 - val_accuracy: 0.9259\n",
      "Epoch 1927/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2978 - accuracy: 0.8558 - val_loss: 0.2633 - val_accuracy: 0.9630\n",
      "Epoch 1928/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2925 - accuracy: 0.8750 - val_loss: 0.2601 - val_accuracy: 0.9630\n",
      "Epoch 1929/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2971 - accuracy: 0.8654 - val_loss: 0.2602 - val_accuracy: 0.9630\n",
      "Epoch 1930/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2910 - accuracy: 0.8654 - val_loss: 0.2671 - val_accuracy: 0.9259\n",
      "Epoch 1931/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3009 - accuracy: 0.8846 - val_loss: 0.2895 - val_accuracy: 0.8519\n",
      "Epoch 1932/2000\n",
      "104/104 [==============================] - ETA: 0s - loss: 0.2480 - accuracy: 0.96 - 0s 125us/step - loss: 0.3177 - accuracy: 0.8750 - val_loss: 0.2725 - val_accuracy: 0.9259\n",
      "Epoch 1933/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2948 - accuracy: 0.8750 - val_loss: 0.2622 - val_accuracy: 0.9630\n",
      "Epoch 1934/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.3047 - accuracy: 0.8558 - val_loss: 0.2623 - val_accuracy: 0.9630\n",
      "Epoch 1935/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2915 - accuracy: 0.8750 - val_loss: 0.2698 - val_accuracy: 0.9259\n",
      "Epoch 1936/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3098 - accuracy: 0.8558 - val_loss: 0.3204 - val_accuracy: 0.8148\n",
      "Epoch 1937/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.3332 - accuracy: 0.8558 - val_loss: 0.2798 - val_accuracy: 0.8519\n",
      "Epoch 1938/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.3004 - accuracy: 0.8846 - val_loss: 0.2603 - val_accuracy: 0.9630\n",
      "Epoch 1939/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2982 - accuracy: 0.8750 - val_loss: 0.2594 - val_accuracy: 0.9630\n",
      "Epoch 1940/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2972 - accuracy: 0.8750 - val_loss: 0.2605 - val_accuracy: 0.9630\n",
      "Epoch 1941/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2947 - accuracy: 0.8750 - val_loss: 0.2600 - val_accuracy: 0.9630\n",
      "Epoch 1942/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2885 - accuracy: 0.8846 - val_loss: 0.2743 - val_accuracy: 0.9259\n",
      "Epoch 1943/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.3004 - accuracy: 0.8942 - val_loss: 0.2713 - val_accuracy: 0.9259\n",
      "Epoch 1944/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2921 - accuracy: 0.8654 - val_loss: 0.2593 - val_accuracy: 0.9630\n",
      "Epoch 1945/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2990 - accuracy: 0.8558 - val_loss: 0.2629 - val_accuracy: 0.9630\n",
      "Epoch 1946/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3027 - accuracy: 0.8558 - val_loss: 0.2592 - val_accuracy: 0.9630\n",
      "Epoch 1947/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2940 - accuracy: 0.8750 - val_loss: 0.2593 - val_accuracy: 0.9630\n",
      "Epoch 1948/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2916 - accuracy: 0.8750 - val_loss: 0.2585 - val_accuracy: 0.9630\n",
      "Epoch 1949/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2938 - accuracy: 0.8654 - val_loss: 0.2587 - val_accuracy: 0.9630\n",
      "Epoch 1950/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2972 - accuracy: 0.8654 - val_loss: 0.2602 - val_accuracy: 0.9630\n",
      "Epoch 1951/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2964 - accuracy: 0.8750 - val_loss: 0.2587 - val_accuracy: 0.9630\n",
      "Epoch 1952/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2904 - accuracy: 0.8846 - val_loss: 0.2645 - val_accuracy: 0.9259\n",
      "Epoch 1953/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2929 - accuracy: 0.8750 - val_loss: 0.2645 - val_accuracy: 0.9259\n",
      "Epoch 1954/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2928 - accuracy: 0.8558 - val_loss: 0.2663 - val_accuracy: 0.9259\n",
      "Epoch 1955/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2924 - accuracy: 0.8654 - val_loss: 0.2606 - val_accuracy: 0.9630\n",
      "Epoch 1956/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2891 - accuracy: 0.8750 - val_loss: 0.2581 - val_accuracy: 0.9630\n",
      "Epoch 1957/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2936 - accuracy: 0.8750 - val_loss: 0.2581 - val_accuracy: 0.9630\n",
      "Epoch 1958/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2961 - accuracy: 0.8750 - val_loss: 0.2577 - val_accuracy: 0.9630\n",
      "Epoch 1959/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2893 - accuracy: 0.8846 - val_loss: 0.2623 - val_accuracy: 0.9259\n",
      "Epoch 1960/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2905 - accuracy: 0.8654 - val_loss: 0.2685 - val_accuracy: 0.9259\n",
      "Epoch 1961/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2942 - accuracy: 0.8750 - val_loss: 0.2671 - val_accuracy: 0.9259\n",
      "Epoch 1962/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2925 - accuracy: 0.8654 - val_loss: 0.2606 - val_accuracy: 0.9630\n",
      "Epoch 1963/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2894 - accuracy: 0.8750 - val_loss: 0.2576 - val_accuracy: 0.9630\n",
      "Epoch 1964/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2918 - accuracy: 0.8654 - val_loss: 0.2579 - val_accuracy: 0.9630\n",
      "Epoch 1965/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2893 - accuracy: 0.8846 - val_loss: 0.2628 - val_accuracy: 0.9259\n",
      "Epoch 1966/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.2954 - accuracy: 0.8558 - val_loss: 0.2664 - val_accuracy: 0.9259\n",
      "Epoch 1967/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2903 - accuracy: 0.8750 - val_loss: 0.2574 - val_accuracy: 0.9630\n",
      "Epoch 1968/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2959 - accuracy: 0.8654 - val_loss: 0.2613 - val_accuracy: 0.9630\n",
      "Epoch 1969/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.3046 - accuracy: 0.8558 - val_loss: 0.2568 - val_accuracy: 0.9630\n",
      "Epoch 1970/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2901 - accuracy: 0.8654 - val_loss: 0.2592 - val_accuracy: 0.9630\n",
      "Epoch 1971/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2913 - accuracy: 0.8750 - val_loss: 0.2727 - val_accuracy: 0.9259\n",
      "Epoch 1972/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2972 - accuracy: 0.8846 - val_loss: 0.2653 - val_accuracy: 0.9259\n",
      "Epoch 1973/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2901 - accuracy: 0.8750 - val_loss: 0.2569 - val_accuracy: 0.9630\n",
      "Epoch 1974/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2891 - accuracy: 0.8846 - val_loss: 0.2582 - val_accuracy: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1975/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2969 - accuracy: 0.8750 - val_loss: 0.2563 - val_accuracy: 0.9630\n",
      "Epoch 1976/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2903 - accuracy: 0.8654 - val_loss: 0.2564 - val_accuracy: 0.9630\n",
      "Epoch 1977/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2881 - accuracy: 0.8846 - val_loss: 0.2611 - val_accuracy: 0.9259\n",
      "Epoch 1978/2000\n",
      "104/104 [==============================] - 0s 96us/step - loss: 0.2916 - accuracy: 0.8654 - val_loss: 0.2700 - val_accuracy: 0.9259\n",
      "Epoch 1979/2000\n",
      "104/104 [==============================] - 0s 106us/step - loss: 0.2928 - accuracy: 0.8846 - val_loss: 0.2584 - val_accuracy: 0.9630\n",
      "Epoch 1980/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2915 - accuracy: 0.8654 - val_loss: 0.2559 - val_accuracy: 0.9630\n",
      "Epoch 1981/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2892 - accuracy: 0.8654 - val_loss: 0.2578 - val_accuracy: 0.9630\n",
      "Epoch 1982/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2868 - accuracy: 0.8846 - val_loss: 0.2664 - val_accuracy: 0.9259\n",
      "Epoch 1983/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2930 - accuracy: 0.8654 - val_loss: 0.2677 - val_accuracy: 0.9259\n",
      "Epoch 1984/2000\n",
      "104/104 [==============================] - 0s 115us/step - loss: 0.2909 - accuracy: 0.8558 - val_loss: 0.2566 - val_accuracy: 0.9630\n",
      "Epoch 1985/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2938 - accuracy: 0.8846 - val_loss: 0.2558 - val_accuracy: 0.9630\n",
      "Epoch 1986/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2886 - accuracy: 0.8750 - val_loss: 0.2609 - val_accuracy: 0.9259\n",
      "Epoch 1987/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2910 - accuracy: 0.8654 - val_loss: 0.2703 - val_accuracy: 0.9259\n",
      "Epoch 1988/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2925 - accuracy: 0.8750 - val_loss: 0.2581 - val_accuracy: 0.9630\n",
      "Epoch 1989/2000\n",
      "104/104 [==============================] - 0s 183us/step - loss: 0.2890 - accuracy: 0.8846 - val_loss: 0.2553 - val_accuracy: 0.9630\n",
      "Epoch 1990/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2881 - accuracy: 0.8750 - val_loss: 0.2588 - val_accuracy: 0.9630\n",
      "Epoch 1991/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2872 - accuracy: 0.8558 - val_loss: 0.2689 - val_accuracy: 0.9259\n",
      "Epoch 1992/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2946 - accuracy: 0.8942 - val_loss: 0.2708 - val_accuracy: 0.9259\n",
      "Epoch 1993/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2918 - accuracy: 0.8750 - val_loss: 0.2567 - val_accuracy: 0.9630\n",
      "Epoch 1994/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2865 - accuracy: 0.8846 - val_loss: 0.2547 - val_accuracy: 0.9630\n",
      "Epoch 1995/2000\n",
      "104/104 [==============================] - 0s 135us/step - loss: 0.2956 - accuracy: 0.8654 - val_loss: 0.2552 - val_accuracy: 0.9630\n",
      "Epoch 1996/2000\n",
      "104/104 [==============================] - 0s 173us/step - loss: 0.2884 - accuracy: 0.8846 - val_loss: 0.2613 - val_accuracy: 0.9259\n",
      "Epoch 1997/2000\n",
      "104/104 [==============================] - 0s 144us/step - loss: 0.2896 - accuracy: 0.8750 - val_loss: 0.2691 - val_accuracy: 0.9259\n",
      "Epoch 1998/2000\n",
      "104/104 [==============================] - 0s 163us/step - loss: 0.2918 - accuracy: 0.8750 - val_loss: 0.2572 - val_accuracy: 0.9630\n",
      "Epoch 1999/2000\n",
      "104/104 [==============================] - 0s 125us/step - loss: 0.2857 - accuracy: 0.8846 - val_loss: 0.2552 - val_accuracy: 0.9630\n",
      "Epoch 2000/2000\n",
      "104/104 [==============================] - 0s 154us/step - loss: 0.2908 - accuracy: 0.8750 - val_loss: 0.2548 - val_accuracy: 0.9630\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data,new_train_target,epochs=2000,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c30e43cb38>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c30e4a0eb8>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'],'r')\n",
    "plt.plot(history.history['val_accuracy'],'g')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 133us/step\n",
      "[0.11533168703317642, 1.0]\n"
     ]
    }
   ],
   "source": [
    "new_test_target = np_utils.to_categorical(test_target)\n",
    "\n",
    "print(model.evaluate(test_data , new_test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 10        \n",
      "=================================================================\n",
      "Total params: 70\n",
      "Trainable params: 70\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Mango_Size_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8535302  0.14646979]\n",
      " [0.99165934 0.0083406 ]\n",
      " [0.93076885 0.06923113]\n",
      " [0.72466254 0.27533746]\n",
      " [0.17981505 0.82018495]\n",
      " [0.968117   0.03188298]\n",
      " [0.9924946  0.00750538]\n",
      " [0.9099323  0.09006766]\n",
      " [0.06673627 0.9332638 ]\n",
      " [0.8439765  0.1560235 ]\n",
      " [0.7592394  0.24076065]\n",
      " [0.9664569  0.0335431 ]\n",
      " [0.09026983 0.90973014]\n",
      " [0.9987877  0.00121232]\n",
      " [0.17536147 0.8246385 ]]\n",
      "[[11  0]\n",
      " [ 0  4]]\n"
     ]
    }
   ],
   "source": [
    "predicted_target=model.predict(test_data)\n",
    "print(predicted_target)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781838555078/6/ch06lvl1sec34/confusion-matrix\n",
    "#cm=confusion_matrix(y_test,y_pred_class)\n",
    "cm=confusion_matrix(np.argmax(new_test_target,axis=1),np.argmax(predicted_target,axis=1))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
