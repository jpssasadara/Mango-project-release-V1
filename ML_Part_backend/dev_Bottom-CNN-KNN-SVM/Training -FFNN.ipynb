{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data=np.load('data.npy')\n",
    "target=np.load('target.npy')\n",
    "\n",
    "#loading the save numpy arrays in the previous code\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data,train_target,test_target=train_test_split(data,target,\n",
    "                                                              test_size=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense #fully connected layers\n",
    "from keras.models import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "#an empty Neural Network\n",
    "\n",
    "model.add(Dense(16,input_dim=8,activation='relu'))\n",
    "#1st Hidden Layer\n",
    "model.add(Dense(8,input_dim=16,activation='relu'))\n",
    "#2nd Hideen Layer\n",
    "model.add(Dense(4,input_dim=8,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 316\n",
      "Trainable params: 316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 2 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "new_train_target=np_utils.to_categorical(train_target)\n",
    "print(new_train_target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 63 samples, validate on 16 samples\n",
      "Epoch 1/1000\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 24.5525 - accuracy: 0.0952 - val_loss: 24.4473 - val_accuracy: 0.1250\n",
      "Epoch 2/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 21.4193 - accuracy: 0.1587 - val_loss: 21.9809 - val_accuracy: 0.2500\n",
      "Epoch 3/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 18.9189 - accuracy: 0.2222 - val_loss: 19.9385 - val_accuracy: 0.2500\n",
      "Epoch 4/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 16.5455 - accuracy: 0.2381 - val_loss: 17.9447 - val_accuracy: 0.2500\n",
      "Epoch 5/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 14.1633 - accuracy: 0.2381 - val_loss: 15.9124 - val_accuracy: 0.2500\n",
      "Epoch 6/1000\n",
      "63/63 [==============================] - 0s 192us/step - loss: 11.9821 - accuracy: 0.2698 - val_loss: 13.8399 - val_accuracy: 0.2500\n",
      "Epoch 7/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 9.5363 - accuracy: 0.2857 - val_loss: 11.7775 - val_accuracy: 0.2500\n",
      "Epoch 8/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 7.4592 - accuracy: 0.4127 - val_loss: 10.2921 - val_accuracy: 0.4375\n",
      "Epoch 9/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 6.6304 - accuracy: 0.5873 - val_loss: 9.8263 - val_accuracy: 0.5000\n",
      "Epoch 10/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 6.7443 - accuracy: 0.5397 - val_loss: 9.5677 - val_accuracy: 0.5000\n",
      "Epoch 11/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 6.9754 - accuracy: 0.5397 - val_loss: 9.2183 - val_accuracy: 0.5000\n",
      "Epoch 12/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 6.9453 - accuracy: 0.5397 - val_loss: 8.8115 - val_accuracy: 0.5000\n",
      "Epoch 13/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 6.7121 - accuracy: 0.5397 - val_loss: 8.3955 - val_accuracy: 0.5000\n",
      "Epoch 14/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 6.4075 - accuracy: 0.5556 - val_loss: 7.9772 - val_accuracy: 0.5000\n",
      "Epoch 15/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 6.0189 - accuracy: 0.5556 - val_loss: 7.5760 - val_accuracy: 0.5000\n",
      "Epoch 16/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 5.7595 - accuracy: 0.5397 - val_loss: 7.2061 - val_accuracy: 0.5000\n",
      "Epoch 17/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 5.6218 - accuracy: 0.5238 - val_loss: 6.8957 - val_accuracy: 0.5000\n",
      "Epoch 18/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 5.5104 - accuracy: 0.5238 - val_loss: 6.5859 - val_accuracy: 0.5000\n",
      "Epoch 19/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 5.3703 - accuracy: 0.5079 - val_loss: 6.2756 - val_accuracy: 0.4375\n",
      "Epoch 20/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 5.1234 - accuracy: 0.5079 - val_loss: 5.8916 - val_accuracy: 0.5000\n",
      "Epoch 21/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 4.8093 - accuracy: 0.5079 - val_loss: 5.4397 - val_accuracy: 0.5000\n",
      "Epoch 22/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 4.4699 - accuracy: 0.5238 - val_loss: 4.9352 - val_accuracy: 0.5000\n",
      "Epoch 23/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 4.0508 - accuracy: 0.5397 - val_loss: 4.4311 - val_accuracy: 0.5000\n",
      "Epoch 24/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 3.6095 - accuracy: 0.5397 - val_loss: 3.9183 - val_accuracy: 0.5000\n",
      "Epoch 25/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 3.1397 - accuracy: 0.5397 - val_loss: 3.3600 - val_accuracy: 0.5000\n",
      "Epoch 26/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 2.7540 - accuracy: 0.5238 - val_loss: 2.7506 - val_accuracy: 0.4375\n",
      "Epoch 27/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 2.2373 - accuracy: 0.5556 - val_loss: 2.2912 - val_accuracy: 0.5000\n",
      "Epoch 28/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 1.8166 - accuracy: 0.5397 - val_loss: 1.9164 - val_accuracy: 0.5625\n",
      "Epoch 29/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 1.4974 - accuracy: 0.5873 - val_loss: 1.7936 - val_accuracy: 0.5000\n",
      "Epoch 30/1000\n",
      "63/63 [==============================] - 0s 207us/step - loss: 1.5396 - accuracy: 0.3810 - val_loss: 1.8460 - val_accuracy: 0.3750\n",
      "Epoch 31/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 1.5847 - accuracy: 0.3175 - val_loss: 1.8475 - val_accuracy: 0.3750\n",
      "Epoch 32/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 1.4989 - accuracy: 0.3333 - val_loss: 1.7918 - val_accuracy: 0.5000\n",
      "Epoch 33/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 1.3535 - accuracy: 0.3810 - val_loss: 1.8452 - val_accuracy: 0.5625\n",
      "Epoch 34/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 1.2233 - accuracy: 0.5079 - val_loss: 1.9869 - val_accuracy: 0.6875\n",
      "Epoch 35/1000\n",
      "63/63 [==============================] - 0s 302us/step - loss: 1.2320 - accuracy: 0.5714 - val_loss: 2.0988 - val_accuracy: 0.6250\n",
      "Epoch 36/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 1.2628 - accuracy: 0.5714 - val_loss: 2.1535 - val_accuracy: 0.6250\n",
      "Epoch 37/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 1.2246 - accuracy: 0.6190 - val_loss: 2.1113 - val_accuracy: 0.6250\n",
      "Epoch 38/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 1.1363 - accuracy: 0.6349 - val_loss: 1.9798 - val_accuracy: 0.5625\n",
      "Epoch 39/1000\n",
      "63/63 [==============================] - 0s 126us/step - loss: 1.0870 - accuracy: 0.6349 - val_loss: 1.8618 - val_accuracy: 0.5000\n",
      "Epoch 40/1000\n",
      "63/63 [==============================] - 0s 0us/step - loss: 1.1078 - accuracy: 0.6508 - val_loss: 1.8121 - val_accuracy: 0.4375\n",
      "Epoch 41/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 1.1197 - accuracy: 0.6349 - val_loss: 1.8425 - val_accuracy: 0.4375\n",
      "Epoch 42/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 1.0878 - accuracy: 0.6508 - val_loss: 1.8748 - val_accuracy: 0.4375\n",
      "Epoch 43/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 1.0625 - accuracy: 0.6825 - val_loss: 1.9271 - val_accuracy: 0.5000\n",
      "Epoch 44/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 1.0502 - accuracy: 0.6508 - val_loss: 1.9930 - val_accuracy: 0.4375\n",
      "Epoch 45/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 1.0511 - accuracy: 0.6349 - val_loss: 2.0465 - val_accuracy: 0.5000\n",
      "Epoch 46/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 1.0648 - accuracy: 0.6349 - val_loss: 2.0670 - val_accuracy: 0.5000\n",
      "Epoch 47/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 1.0561 - accuracy: 0.6190 - val_loss: 2.0318 - val_accuracy: 0.4375\n",
      "Epoch 48/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 1.0391 - accuracy: 0.6349 - val_loss: 1.9842 - val_accuracy: 0.4375\n",
      "Epoch 49/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 1.0416 - accuracy: 0.6508 - val_loss: 1.9335 - val_accuracy: 0.5000\n",
      "Epoch 50/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 1.0436 - accuracy: 0.6508 - val_loss: 1.9036 - val_accuracy: 0.5000\n",
      "Epoch 51/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 1.0448 - accuracy: 0.6825 - val_loss: 1.9176 - val_accuracy: 0.5000\n",
      "Epoch 52/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 1.0208 - accuracy: 0.6667 - val_loss: 1.9123 - val_accuracy: 0.5625\n",
      "Epoch 53/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 1.0118 - accuracy: 0.6667 - val_loss: 1.8970 - val_accuracy: 0.5625\n",
      "Epoch 54/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 1.0177 - accuracy: 0.6508 - val_loss: 1.8943 - val_accuracy: 0.5625\n",
      "Epoch 55/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 1.0030 - accuracy: 0.6349 - val_loss: 1.8880 - val_accuracy: 0.5625\n",
      "Epoch 56/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 1.0096 - accuracy: 0.6349 - val_loss: 1.8591 - val_accuracy: 0.5625\n",
      "Epoch 57/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 159us/step - loss: 0.9960 - accuracy: 0.6508 - val_loss: 1.8404 - val_accuracy: 0.6250\n",
      "Epoch 58/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.9965 - accuracy: 0.6667 - val_loss: 1.8365 - val_accuracy: 0.6250\n",
      "Epoch 59/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 1.0114 - accuracy: 0.6825 - val_loss: 1.7703 - val_accuracy: 0.5625\n",
      "Epoch 60/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9954 - accuracy: 0.6667 - val_loss: 1.7587 - val_accuracy: 0.5625\n",
      "Epoch 61/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.9904 - accuracy: 0.6667 - val_loss: 1.7867 - val_accuracy: 0.6250\n",
      "Epoch 62/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.9960 - accuracy: 0.6667 - val_loss: 1.8236 - val_accuracy: 0.6250\n",
      "Epoch 63/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9822 - accuracy: 0.6349 - val_loss: 1.8185 - val_accuracy: 0.6250\n",
      "Epoch 64/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9918 - accuracy: 0.6349 - val_loss: 1.8105 - val_accuracy: 0.6250\n",
      "Epoch 65/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9784 - accuracy: 0.6508 - val_loss: 1.7812 - val_accuracy: 0.6250\n",
      "Epoch 66/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9690 - accuracy: 0.6508 - val_loss: 1.7365 - val_accuracy: 0.6250\n",
      "Epoch 67/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.9739 - accuracy: 0.6825 - val_loss: 1.7292 - val_accuracy: 0.6250\n",
      "Epoch 68/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9869 - accuracy: 0.6825 - val_loss: 1.6835 - val_accuracy: 0.6250\n",
      "Epoch 69/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9807 - accuracy: 0.6825 - val_loss: 1.7460 - val_accuracy: 0.6250\n",
      "Epoch 70/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9652 - accuracy: 0.6667 - val_loss: 1.7822 - val_accuracy: 0.6250\n",
      "Epoch 71/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9601 - accuracy: 0.6508 - val_loss: 1.7925 - val_accuracy: 0.6250\n",
      "Epoch 72/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9603 - accuracy: 0.6349 - val_loss: 1.7542 - val_accuracy: 0.6250\n",
      "Epoch 73/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9529 - accuracy: 0.6508 - val_loss: 1.7441 - val_accuracy: 0.6250\n",
      "Epoch 74/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9551 - accuracy: 0.6667 - val_loss: 1.7080 - val_accuracy: 0.6250\n",
      "Epoch 75/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.9474 - accuracy: 0.6667 - val_loss: 1.7096 - val_accuracy: 0.6250\n",
      "Epoch 76/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.9478 - accuracy: 0.6667 - val_loss: 1.7053 - val_accuracy: 0.6250\n",
      "Epoch 77/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9562 - accuracy: 0.6667 - val_loss: 1.7416 - val_accuracy: 0.6250\n",
      "Epoch 78/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 1.2506 - accuracy: 0.59 - 0s 175us/step - loss: 0.9503 - accuracy: 0.6508 - val_loss: 1.7553 - val_accuracy: 0.6250\n",
      "Epoch 79/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9405 - accuracy: 0.6667 - val_loss: 1.7122 - val_accuracy: 0.6250\n",
      "Epoch 80/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.9396 - accuracy: 0.6508 - val_loss: 1.6550 - val_accuracy: 0.6250\n",
      "Epoch 81/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.9406 - accuracy: 0.6667 - val_loss: 1.6186 - val_accuracy: 0.6250\n",
      "Epoch 82/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9367 - accuracy: 0.6508 - val_loss: 1.6379 - val_accuracy: 0.6250\n",
      "Epoch 83/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.9297 - accuracy: 0.6667 - val_loss: 1.6614 - val_accuracy: 0.6250\n",
      "Epoch 84/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.9286 - accuracy: 0.6667 - val_loss: 1.6951 - val_accuracy: 0.6250\n",
      "Epoch 85/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9066 - accuracy: 0.65 - 0s 222us/step - loss: 0.9283 - accuracy: 0.6667 - val_loss: 1.7079 - val_accuracy: 0.6250\n",
      "Epoch 86/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9275 - accuracy: 0.6667 - val_loss: 1.6714 - val_accuracy: 0.6250\n",
      "Epoch 87/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.9198 - accuracy: 0.6825 - val_loss: 1.6450 - val_accuracy: 0.6250\n",
      "Epoch 88/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.9252 - accuracy: 0.6667 - val_loss: 1.6096 - val_accuracy: 0.6250\n",
      "Epoch 89/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9246 - accuracy: 0.6667 - val_loss: 1.6052 - val_accuracy: 0.6250\n",
      "Epoch 90/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9147 - accuracy: 0.6825 - val_loss: 1.6500 - val_accuracy: 0.6250\n",
      "Epoch 91/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9217 - accuracy: 0.6825 - val_loss: 1.6513 - val_accuracy: 0.6250\n",
      "Epoch 92/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.9283 - accuracy: 0.6825 - val_loss: 1.7286 - val_accuracy: 0.6250\n",
      "Epoch 93/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.9261 - accuracy: 0.6667 - val_loss: 1.6754 - val_accuracy: 0.6250\n",
      "Epoch 94/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.9078 - accuracy: 0.6667 - val_loss: 1.6378 - val_accuracy: 0.6250\n",
      "Epoch 95/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9180 - accuracy: 0.6667 - val_loss: 1.5670 - val_accuracy: 0.6250\n",
      "Epoch 96/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9367 - accuracy: 0.6508 - val_loss: 1.5219 - val_accuracy: 0.6250\n",
      "Epoch 97/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.9110 - accuracy: 0.6667 - val_loss: 1.6068 - val_accuracy: 0.6250\n",
      "Epoch 98/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.9063 - accuracy: 0.6825 - val_loss: 1.6186 - val_accuracy: 0.6250\n",
      "Epoch 99/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8861 - accuracy: 0.62 - 0s 111us/step - loss: 0.9305 - accuracy: 0.6349 - val_loss: 1.7137 - val_accuracy: 0.5625\n",
      "Epoch 100/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.9098 - accuracy: 0.6508 - val_loss: 1.6810 - val_accuracy: 0.6250\n",
      "Epoch 101/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8967 - accuracy: 0.6667 - val_loss: 1.6062 - val_accuracy: 0.6250\n",
      "Epoch 102/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8900 - accuracy: 0.6825 - val_loss: 1.5212 - val_accuracy: 0.6250\n",
      "Epoch 103/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.9241 - accuracy: 0.6508 - val_loss: 1.4556 - val_accuracy: 0.6250\n",
      "Epoch 104/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.9042 - accuracy: 0.6508 - val_loss: 1.5313 - val_accuracy: 0.5625\n",
      "Epoch 105/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.8849 - accuracy: 0.6667 - val_loss: 1.6027 - val_accuracy: 0.5625\n",
      "Epoch 106/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.8886 - accuracy: 0.6508 - val_loss: 1.6595 - val_accuracy: 0.5000\n",
      "Epoch 107/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8909 - accuracy: 0.6508 - val_loss: 1.6417 - val_accuracy: 0.6250\n",
      "Epoch 108/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8860 - accuracy: 0.6667 - val_loss: 1.5981 - val_accuracy: 0.6250\n",
      "Epoch 109/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.8816 - accuracy: 0.6667 - val_loss: 1.5395 - val_accuracy: 0.6250\n",
      "Epoch 110/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.8872 - accuracy: 0.6825 - val_loss: 1.4600 - val_accuracy: 0.6250\n",
      "Epoch 111/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8814 - accuracy: 0.6508 - val_loss: 1.4748 - val_accuracy: 0.6250\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 190us/step - loss: 0.8760 - accuracy: 0.6667 - val_loss: 1.5205 - val_accuracy: 0.5625\n",
      "Epoch 113/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.8775 - accuracy: 0.6508 - val_loss: 1.5920 - val_accuracy: 0.5625\n",
      "Epoch 114/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.8723 - accuracy: 0.6667 - val_loss: 1.5777 - val_accuracy: 0.5625\n",
      "Epoch 115/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.8691 - accuracy: 0.6508 - val_loss: 1.5677 - val_accuracy: 0.5625\n",
      "Epoch 116/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.8805 - accuracy: 0.6667 - val_loss: 1.5516 - val_accuracy: 0.6250\n",
      "Epoch 117/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.8633 - accuracy: 0.6508 - val_loss: 1.4908 - val_accuracy: 0.6250\n",
      "Epoch 118/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8675 - accuracy: 0.6825 - val_loss: 1.4341 - val_accuracy: 0.6250\n",
      "Epoch 119/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8928 - accuracy: 0.6667 - val_loss: 1.4220 - val_accuracy: 0.5625\n",
      "Epoch 120/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8831 - accuracy: 0.6508 - val_loss: 1.5444 - val_accuracy: 0.5625\n",
      "Epoch 121/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8612 - accuracy: 0.6667 - val_loss: 1.5492 - val_accuracy: 0.5625\n",
      "Epoch 122/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8581 - accuracy: 0.6508 - val_loss: 1.5531 - val_accuracy: 0.5625\n",
      "Epoch 123/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8842 - accuracy: 0.6508 - val_loss: 1.4695 - val_accuracy: 0.6250\n",
      "Epoch 124/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8553 - accuracy: 0.6667 - val_loss: 1.4871 - val_accuracy: 0.6250\n",
      "Epoch 125/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8640 - accuracy: 0.6825 - val_loss: 1.4536 - val_accuracy: 0.5625\n",
      "Epoch 126/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.8495 - accuracy: 0.6667 - val_loss: 1.4655 - val_accuracy: 0.5625\n",
      "Epoch 127/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.8474 - accuracy: 0.6667 - val_loss: 1.5030 - val_accuracy: 0.5625\n",
      "Epoch 128/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.9070 - accuracy: 0.62 - 0s 159us/step - loss: 0.8502 - accuracy: 0.6508 - val_loss: 1.5201 - val_accuracy: 0.5625\n",
      "Epoch 129/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8532 - accuracy: 0.6508 - val_loss: 1.5037 - val_accuracy: 0.6250\n",
      "Epoch 130/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8406 - accuracy: 0.6667 - val_loss: 1.4387 - val_accuracy: 0.6250\n",
      "Epoch 131/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.8397 - accuracy: 0.6825 - val_loss: 1.3988 - val_accuracy: 0.6250\n",
      "Epoch 132/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8462 - accuracy: 0.6825 - val_loss: 1.3779 - val_accuracy: 0.6250\n",
      "Epoch 133/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8421 - accuracy: 0.6667 - val_loss: 1.4117 - val_accuracy: 0.5625\n",
      "Epoch 134/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8353 - accuracy: 0.6667 - val_loss: 1.4780 - val_accuracy: 0.5625\n",
      "Epoch 135/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8547 - accuracy: 0.6349 - val_loss: 1.5425 - val_accuracy: 0.5625\n",
      "Epoch 136/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8413 - accuracy: 0.6508 - val_loss: 1.4726 - val_accuracy: 0.5625\n",
      "Epoch 137/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8397 - accuracy: 0.6667 - val_loss: 1.3850 - val_accuracy: 0.6250\n",
      "Epoch 138/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8363 - accuracy: 0.6984 - val_loss: 1.3863 - val_accuracy: 0.6250\n",
      "Epoch 139/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8428 - accuracy: 0.6825 - val_loss: 1.4172 - val_accuracy: 0.5625\n",
      "Epoch 140/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8276 - accuracy: 0.6667 - val_loss: 1.4153 - val_accuracy: 0.5625\n",
      "Epoch 141/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.8299 - accuracy: 0.6825 - val_loss: 1.4070 - val_accuracy: 0.5625\n",
      "Epoch 142/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8231 - accuracy: 0.6508 - val_loss: 1.3746 - val_accuracy: 0.5625\n",
      "Epoch 143/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.8239 - accuracy: 0.6825 - val_loss: 1.3793 - val_accuracy: 0.5625\n",
      "Epoch 144/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8192 - accuracy: 0.6825 - val_loss: 1.3806 - val_accuracy: 0.5625\n",
      "Epoch 145/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8278 - accuracy: 0.6984 - val_loss: 1.3627 - val_accuracy: 0.5625\n",
      "Epoch 146/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8184 - accuracy: 0.6667 - val_loss: 1.4012 - val_accuracy: 0.5625\n",
      "Epoch 147/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.8167 - accuracy: 0.6508 - val_loss: 1.4441 - val_accuracy: 0.5625\n",
      "Epoch 148/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.8180 - accuracy: 0.6508 - val_loss: 1.4380 - val_accuracy: 0.5625\n",
      "Epoch 149/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.8184 - accuracy: 0.6825 - val_loss: 1.3733 - val_accuracy: 0.5625\n",
      "Epoch 150/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.8125 - accuracy: 0.6825 - val_loss: 1.3624 - val_accuracy: 0.5625\n",
      "Epoch 151/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8136 - accuracy: 0.6984 - val_loss: 1.3600 - val_accuracy: 0.5625\n",
      "Epoch 152/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.8078 - accuracy: 0.6825 - val_loss: 1.3543 - val_accuracy: 0.5625\n",
      "Epoch 153/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8256 - accuracy: 0.6667 - val_loss: 1.3258 - val_accuracy: 0.5625\n",
      "Epoch 154/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.8147 - accuracy: 0.6667 - val_loss: 1.3927 - val_accuracy: 0.5625\n",
      "Epoch 155/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8040 - accuracy: 0.6825 - val_loss: 1.3979 - val_accuracy: 0.5625\n",
      "Epoch 156/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.8119 - accuracy: 0.6508 - val_loss: 1.4127 - val_accuracy: 0.5625\n",
      "Epoch 157/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.8225 - accuracy: 0.6508 - val_loss: 1.3142 - val_accuracy: 0.6250\n",
      "Epoch 158/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8065 - accuracy: 0.6984 - val_loss: 1.2924 - val_accuracy: 0.6250\n",
      "Epoch 159/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8246 - accuracy: 0.6984 - val_loss: 1.2906 - val_accuracy: 0.5625\n",
      "Epoch 160/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7988 - accuracy: 0.6825 - val_loss: 1.3734 - val_accuracy: 0.5625\n",
      "Epoch 161/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.7952 - accuracy: 0.6508 - val_loss: 1.4118 - val_accuracy: 0.5625\n",
      "Epoch 162/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.8103 - accuracy: 0.6349 - val_loss: 1.4255 - val_accuracy: 0.5625\n",
      "Epoch 163/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7984 - accuracy: 0.6667 - val_loss: 1.3396 - val_accuracy: 0.5625\n",
      "Epoch 164/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7909 - accuracy: 0.7143 - val_loss: 1.2673 - val_accuracy: 0.6250\n",
      "Epoch 165/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.8047 - accuracy: 0.6984 - val_loss: 1.2360 - val_accuracy: 0.5625\n",
      "Epoch 166/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.7966 - accuracy: 0.6984 - val_loss: 1.3005 - val_accuracy: 0.5625\n",
      "Epoch 167/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.8006 - accuracy: 0.6508 - val_loss: 1.3789 - val_accuracy: 0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.7918 - accuracy: 0.6508 - val_loss: 1.3430 - val_accuracy: 0.5625\n",
      "Epoch 169/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7854 - accuracy: 0.6825 - val_loss: 1.3018 - val_accuracy: 0.5625\n",
      "Epoch 170/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7923 - accuracy: 0.7143 - val_loss: 1.2662 - val_accuracy: 0.6250\n",
      "Epoch 171/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7952 - accuracy: 0.6984 - val_loss: 1.2736 - val_accuracy: 0.5625\n",
      "Epoch 172/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7840 - accuracy: 0.6667 - val_loss: 1.3572 - val_accuracy: 0.5625\n",
      "Epoch 173/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.7890 - accuracy: 0.6349 - val_loss: 1.3779 - val_accuracy: 0.5625\n",
      "Epoch 174/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7840 - accuracy: 0.6508 - val_loss: 1.3207 - val_accuracy: 0.5625\n",
      "Epoch 175/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7789 - accuracy: 0.6825 - val_loss: 1.2487 - val_accuracy: 0.5625\n",
      "Epoch 176/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7763 - accuracy: 0.6984 - val_loss: 1.2283 - val_accuracy: 0.5625\n",
      "Epoch 177/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7758 - accuracy: 0.6984 - val_loss: 1.2523 - val_accuracy: 0.5625\n",
      "Epoch 178/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7949 - accuracy: 0.75 - 0s 143us/step - loss: 0.7729 - accuracy: 0.7143 - val_loss: 1.2905 - val_accuracy: 0.5625\n",
      "Epoch 179/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7698 - accuracy: 0.6984 - val_loss: 1.3174 - val_accuracy: 0.5625\n",
      "Epoch 180/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7713 - accuracy: 0.6508 - val_loss: 1.3080 - val_accuracy: 0.5625\n",
      "Epoch 181/1000\n",
      "63/63 [==============================] - 0s 345us/step - loss: 0.7724 - accuracy: 0.6667 - val_loss: 1.2912 - val_accuracy: 0.5625\n",
      "Epoch 182/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7726 - accuracy: 0.6825 - val_loss: 1.2622 - val_accuracy: 0.5625\n",
      "Epoch 183/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7724 - accuracy: 0.6825 - val_loss: 1.2264 - val_accuracy: 0.5625\n",
      "Epoch 184/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.7711 - accuracy: 0.6825 - val_loss: 1.2617 - val_accuracy: 0.5625\n",
      "Epoch 185/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7773 - accuracy: 0.6984 - val_loss: 1.2939 - val_accuracy: 0.5625\n",
      "Epoch 186/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7747 - accuracy: 0.6825 - val_loss: 1.2910 - val_accuracy: 0.5625\n",
      "Epoch 187/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7723 - accuracy: 0.6825 - val_loss: 1.2426 - val_accuracy: 0.5625\n",
      "Epoch 188/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.7552 - accuracy: 0.7302 - val_loss: 1.1879 - val_accuracy: 0.5625\n",
      "Epoch 189/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7752 - accuracy: 0.6984 - val_loss: 1.2106 - val_accuracy: 0.5625\n",
      "Epoch 190/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7672 - accuracy: 0.6825 - val_loss: 1.2222 - val_accuracy: 0.5625\n",
      "Epoch 191/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7639 - accuracy: 0.6984 - val_loss: 1.2008 - val_accuracy: 0.5625\n",
      "Epoch 192/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7625 - accuracy: 0.6984 - val_loss: 1.2071 - val_accuracy: 0.5625\n",
      "Epoch 193/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7783 - accuracy: 0.6825 - val_loss: 1.2871 - val_accuracy: 0.5625\n",
      "Epoch 194/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7686 - accuracy: 0.6825 - val_loss: 1.2489 - val_accuracy: 0.5625\n",
      "Epoch 195/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7597 - accuracy: 0.6984 - val_loss: 1.2226 - val_accuracy: 0.5625\n",
      "Epoch 196/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.7529 - accuracy: 0.6984 - val_loss: 1.2376 - val_accuracy: 0.5625\n",
      "Epoch 197/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7509 - accuracy: 0.6667 - val_loss: 1.2632 - val_accuracy: 0.5625\n",
      "Epoch 198/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7509 - accuracy: 0.6667 - val_loss: 1.2379 - val_accuracy: 0.5625\n",
      "Epoch 199/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7459 - accuracy: 0.6825 - val_loss: 1.2165 - val_accuracy: 0.5625\n",
      "Epoch 200/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7579 - accuracy: 0.7302 - val_loss: 1.1714 - val_accuracy: 0.5625\n",
      "Epoch 201/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7484 - accuracy: 0.7143 - val_loss: 1.1977 - val_accuracy: 0.6250\n",
      "Epoch 202/1000\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.7428 - accuracy: 0.7143 - val_loss: 1.2299 - val_accuracy: 0.5625\n",
      "Epoch 203/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7425 - accuracy: 0.6825 - val_loss: 1.2622 - val_accuracy: 0.5625\n",
      "Epoch 204/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7575 - accuracy: 0.6667 - val_loss: 1.2266 - val_accuracy: 0.5625\n",
      "Epoch 205/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7442 - accuracy: 0.6667 - val_loss: 1.1899 - val_accuracy: 0.5625\n",
      "Epoch 206/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7388 - accuracy: 0.6984 - val_loss: 1.1818 - val_accuracy: 0.5625\n",
      "Epoch 207/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7397 - accuracy: 0.6984 - val_loss: 1.1799 - val_accuracy: 0.5625\n",
      "Epoch 208/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7346 - accuracy: 0.7143 - val_loss: 1.2194 - val_accuracy: 0.5625\n",
      "Epoch 209/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7521 - accuracy: 0.6508 - val_loss: 1.2635 - val_accuracy: 0.5625\n",
      "Epoch 210/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7392 - accuracy: 0.6667 - val_loss: 1.1825 - val_accuracy: 0.5625\n",
      "Epoch 211/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7387 - accuracy: 0.7143 - val_loss: 1.1326 - val_accuracy: 0.5625\n",
      "Epoch 212/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.7360 - accuracy: 0.7143 - val_loss: 1.1632 - val_accuracy: 0.5625\n",
      "Epoch 213/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.7382 - accuracy: 0.6984 - val_loss: 1.2250 - val_accuracy: 0.5625\n",
      "Epoch 214/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7316 - accuracy: 0.6508 - val_loss: 1.2232 - val_accuracy: 0.5625\n",
      "Epoch 215/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7407 - accuracy: 0.6667 - val_loss: 1.2038 - val_accuracy: 0.5625\n",
      "Epoch 216/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7258 - accuracy: 0.7143 - val_loss: 1.1256 - val_accuracy: 0.5625\n",
      "Epoch 217/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6331 - accuracy: 0.75 - 0s 206us/step - loss: 0.7370 - accuracy: 0.6984 - val_loss: 1.0836 - val_accuracy: 0.5625\n",
      "Epoch 218/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7344 - accuracy: 0.6984 - val_loss: 1.1558 - val_accuracy: 0.5625\n",
      "Epoch 219/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7243 - accuracy: 0.6825 - val_loss: 1.2146 - val_accuracy: 0.5625\n",
      "Epoch 220/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.7255 - accuracy: 0.6667 - val_loss: 1.2327 - val_accuracy: 0.5625\n",
      "Epoch 221/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7228 - accuracy: 0.6508 - val_loss: 1.1812 - val_accuracy: 0.5625\n",
      "Epoch 222/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7369 - accuracy: 0.7143 - val_loss: 1.1096 - val_accuracy: 0.5625\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 175us/step - loss: 0.7257 - accuracy: 0.7143 - val_loss: 1.1546 - val_accuracy: 0.5625\n",
      "Epoch 224/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.7239 - accuracy: 0.6825 - val_loss: 1.1959 - val_accuracy: 0.5625\n",
      "Epoch 225/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7158 - accuracy: 0.6667 - val_loss: 1.1779 - val_accuracy: 0.5625\n",
      "Epoch 226/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7150 - accuracy: 0.6984 - val_loss: 1.1281 - val_accuracy: 0.5625\n",
      "Epoch 227/1000\n",
      "63/63 [==============================] - 0s 207us/step - loss: 0.7141 - accuracy: 0.7143 - val_loss: 1.1146 - val_accuracy: 0.5625\n",
      "Epoch 228/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7273 - accuracy: 0.7143 - val_loss: 1.1065 - val_accuracy: 0.5625\n",
      "Epoch 229/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7136 - accuracy: 0.6984 - val_loss: 1.1864 - val_accuracy: 0.5625\n",
      "Epoch 230/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7130 - accuracy: 0.6508 - val_loss: 1.1836 - val_accuracy: 0.5625\n",
      "Epoch 231/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7119 - accuracy: 0.6508 - val_loss: 1.1778 - val_accuracy: 0.5625\n",
      "Epoch 232/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.7161 - accuracy: 0.6825 - val_loss: 1.1227 - val_accuracy: 0.5625\n",
      "Epoch 233/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7117 - accuracy: 0.6984 - val_loss: 1.0970 - val_accuracy: 0.5625\n",
      "Epoch 234/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.8105 - accuracy: 0.65 - 0s 127us/step - loss: 0.7291 - accuracy: 0.6984 - val_loss: 1.1578 - val_accuracy: 0.5625\n",
      "Epoch 235/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.7079 - accuracy: 0.6825 - val_loss: 1.1538 - val_accuracy: 0.5625\n",
      "Epoch 236/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7053 - accuracy: 0.6984 - val_loss: 1.1095 - val_accuracy: 0.5625\n",
      "Epoch 237/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7036 - accuracy: 0.7143 - val_loss: 1.0915 - val_accuracy: 0.5625\n",
      "Epoch 238/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.7147 - accuracy: 0.6825 - val_loss: 1.1363 - val_accuracy: 0.5625\n",
      "Epoch 239/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6988 - accuracy: 0.6825 - val_loss: 1.1250 - val_accuracy: 0.5625\n",
      "Epoch 240/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7093 - accuracy: 0.6984 - val_loss: 1.0912 - val_accuracy: 0.5625\n",
      "Epoch 241/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.7011 - accuracy: 0.7143 - val_loss: 1.1186 - val_accuracy: 0.5625\n",
      "Epoch 242/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6994 - accuracy: 0.65 - 0s 143us/step - loss: 0.7030 - accuracy: 0.6984 - val_loss: 1.1192 - val_accuracy: 0.5625\n",
      "Epoch 243/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6946 - accuracy: 0.7143 - val_loss: 1.1542 - val_accuracy: 0.5625\n",
      "Epoch 244/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7017 - accuracy: 0.6508 - val_loss: 1.1628 - val_accuracy: 0.5625\n",
      "Epoch 245/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.7074 - accuracy: 0.6508 - val_loss: 1.1325 - val_accuracy: 0.5625\n",
      "Epoch 246/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6904 - accuracy: 0.7143 - val_loss: 1.0559 - val_accuracy: 0.5625\n",
      "Epoch 247/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6936 - accuracy: 0.6984 - val_loss: 1.0522 - val_accuracy: 0.5625\n",
      "Epoch 248/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.7040 - accuracy: 0.6984 - val_loss: 1.0531 - val_accuracy: 0.5625\n",
      "Epoch 249/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.7103 - accuracy: 0.6825 - val_loss: 1.1424 - val_accuracy: 0.5625\n",
      "Epoch 250/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6878 - accuracy: 0.6508 - val_loss: 1.1383 - val_accuracy: 0.5625\n",
      "Epoch 251/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6880 - accuracy: 0.6984 - val_loss: 1.1029 - val_accuracy: 0.5625\n",
      "Epoch 252/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6885 - accuracy: 0.7143 - val_loss: 1.0930 - val_accuracy: 0.5625\n",
      "Epoch 253/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.6849 - accuracy: 0.7302 - val_loss: 1.0718 - val_accuracy: 0.5625\n",
      "Epoch 254/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6855 - accuracy: 0.7143 - val_loss: 1.0923 - val_accuracy: 0.5625\n",
      "Epoch 255/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6858 - accuracy: 0.6825 - val_loss: 1.0959 - val_accuracy: 0.5625\n",
      "Epoch 256/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.6822 - accuracy: 0.6825 - val_loss: 1.1009 - val_accuracy: 0.5625\n",
      "Epoch 257/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6795 - accuracy: 0.6984 - val_loss: 1.0851 - val_accuracy: 0.5625\n",
      "Epoch 258/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.6780 - accuracy: 0.7302 - val_loss: 1.0752 - val_accuracy: 0.5625\n",
      "Epoch 259/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6827 - accuracy: 0.7302 - val_loss: 1.0815 - val_accuracy: 0.5625\n",
      "Epoch 260/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6866 - accuracy: 0.7302 - val_loss: 1.0628 - val_accuracy: 0.5625\n",
      "Epoch 261/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6762 - accuracy: 0.6984 - val_loss: 1.1059 - val_accuracy: 0.5625\n",
      "Epoch 262/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6775 - accuracy: 0.6825 - val_loss: 1.1027 - val_accuracy: 0.5625\n",
      "Epoch 263/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6749 - accuracy: 0.6825 - val_loss: 1.0907 - val_accuracy: 0.5625\n",
      "Epoch 264/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6794 - accuracy: 0.7143 - val_loss: 1.0494 - val_accuracy: 0.5625\n",
      "Epoch 265/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6828 - accuracy: 0.6984 - val_loss: 1.0875 - val_accuracy: 0.5625\n",
      "Epoch 266/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6718 - accuracy: 0.7143 - val_loss: 1.0630 - val_accuracy: 0.5625\n",
      "Epoch 267/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6710 - accuracy: 0.7302 - val_loss: 1.0632 - val_accuracy: 0.5625\n",
      "Epoch 268/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6704 - accuracy: 0.7143 - val_loss: 1.0421 - val_accuracy: 0.5625\n",
      "Epoch 269/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6694 - accuracy: 0.6984 - val_loss: 1.0486 - val_accuracy: 0.5625\n",
      "Epoch 270/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6680 - accuracy: 0.6984 - val_loss: 1.0706 - val_accuracy: 0.5625\n",
      "Epoch 271/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6749 - accuracy: 0.6825 - val_loss: 1.1047 - val_accuracy: 0.5625\n",
      "Epoch 272/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6792 - accuracy: 0.6984 - val_loss: 1.0325 - val_accuracy: 0.5625\n",
      "Epoch 273/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6671 - accuracy: 0.7302 - val_loss: 1.0567 - val_accuracy: 0.5625\n",
      "Epoch 274/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6618 - accuracy: 0.7302 - val_loss: 1.0467 - val_accuracy: 0.5625\n",
      "Epoch 275/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6615 - accuracy: 0.7302 - val_loss: 1.0548 - val_accuracy: 0.5625\n",
      "Epoch 276/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6668 - accuracy: 0.6984 - val_loss: 1.0322 - val_accuracy: 0.5625\n",
      "Epoch 277/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6593 - accuracy: 0.6984 - val_loss: 1.0552 - val_accuracy: 0.5625\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 191us/step - loss: 0.6590 - accuracy: 0.6825 - val_loss: 1.0905 - val_accuracy: 0.5625\n",
      "Epoch 279/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6633 - accuracy: 0.6667 - val_loss: 1.0934 - val_accuracy: 0.5625\n",
      "Epoch 280/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6631 - accuracy: 0.6984 - val_loss: 1.0165 - val_accuracy: 0.5625\n",
      "Epoch 281/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6565 - accuracy: 0.7460 - val_loss: 0.9990 - val_accuracy: 0.5625\n",
      "Epoch 282/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6712 - accuracy: 0.7302 - val_loss: 0.9996 - val_accuracy: 0.5625\n",
      "Epoch 283/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6504 - accuracy: 0.7143 - val_loss: 1.0707 - val_accuracy: 0.5625\n",
      "Epoch 284/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6498 - accuracy: 0.6825 - val_loss: 1.1020 - val_accuracy: 0.5625\n",
      "Epoch 285/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6618 - accuracy: 0.6667 - val_loss: 1.0759 - val_accuracy: 0.5625\n",
      "Epoch 286/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.6524 - accuracy: 0.6825 - val_loss: 1.0384 - val_accuracy: 0.5625\n",
      "Epoch 287/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6536 - accuracy: 0.7143 - val_loss: 1.0284 - val_accuracy: 0.5625\n",
      "Epoch 288/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.6600 - accuracy: 0.7302 - val_loss: 0.9758 - val_accuracy: 0.5625\n",
      "Epoch 289/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6616 - accuracy: 0.7143 - val_loss: 1.0156 - val_accuracy: 0.5625\n",
      "Epoch 290/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6569 - accuracy: 0.6984 - val_loss: 1.0380 - val_accuracy: 0.5625\n",
      "Epoch 291/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.6487 - accuracy: 0.6984 - val_loss: 1.0599 - val_accuracy: 0.5625\n",
      "Epoch 292/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.6588 - accuracy: 0.6984 - val_loss: 1.0094 - val_accuracy: 0.5625\n",
      "Epoch 293/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6506 - accuracy: 0.7302 - val_loss: 1.0354 - val_accuracy: 0.5625\n",
      "Epoch 294/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.6516 - accuracy: 0.6984 - val_loss: 1.0397 - val_accuracy: 0.5625\n",
      "Epoch 295/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6387 - accuracy: 0.6984 - val_loss: 1.0176 - val_accuracy: 0.5625\n",
      "Epoch 296/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6393 - accuracy: 0.6984 - val_loss: 0.9942 - val_accuracy: 0.5625\n",
      "Epoch 297/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.6402 - accuracy: 0.6984 - val_loss: 0.9730 - val_accuracy: 0.5625\n",
      "Epoch 298/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6415 - accuracy: 0.7460 - val_loss: 1.0045 - val_accuracy: 0.5625\n",
      "Epoch 299/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6377 - accuracy: 0.6984 - val_loss: 1.0366 - val_accuracy: 0.5625\n",
      "Epoch 300/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6437 - accuracy: 0.6825 - val_loss: 1.0203 - val_accuracy: 0.5625\n",
      "Epoch 301/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6457 - accuracy: 0.6508 - val_loss: 1.0591 - val_accuracy: 0.5625\n",
      "Epoch 302/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6357 - accuracy: 0.6508 - val_loss: 1.0275 - val_accuracy: 0.5625\n",
      "Epoch 303/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6368 - accuracy: 0.6825 - val_loss: 0.9627 - val_accuracy: 0.5625\n",
      "Epoch 304/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6315 - accuracy: 0.7302 - val_loss: 0.9703 - val_accuracy: 0.5625\n",
      "Epoch 305/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6294 - accuracy: 0.6984 - val_loss: 0.9975 - val_accuracy: 0.5625\n",
      "Epoch 306/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6299 - accuracy: 0.6984 - val_loss: 1.0175 - val_accuracy: 0.5625\n",
      "Epoch 307/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6315 - accuracy: 0.6825 - val_loss: 1.0236 - val_accuracy: 0.5625\n",
      "Epoch 308/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6264 - accuracy: 0.6984 - val_loss: 0.9862 - val_accuracy: 0.5625\n",
      "Epoch 309/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6292 - accuracy: 0.7460 - val_loss: 0.9677 - val_accuracy: 0.5625\n",
      "Epoch 310/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6120 - accuracy: 0.75 - 0s 143us/step - loss: 0.6382 - accuracy: 0.7302 - val_loss: 0.9261 - val_accuracy: 0.5625\n",
      "Epoch 311/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6308 - accuracy: 0.7460 - val_loss: 0.9829 - val_accuracy: 0.5625\n",
      "Epoch 312/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6270 - accuracy: 0.71 - 0s 159us/step - loss: 0.6328 - accuracy: 0.6984 - val_loss: 1.0372 - val_accuracy: 0.6250\n",
      "Epoch 313/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6259 - accuracy: 0.6667 - val_loss: 1.0143 - val_accuracy: 0.5625\n",
      "Epoch 314/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.6268 - accuracy: 0.6984 - val_loss: 0.9664 - val_accuracy: 0.5625\n",
      "Epoch 315/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6481 - accuracy: 0.7302 - val_loss: 0.9027 - val_accuracy: 0.5625\n",
      "Epoch 316/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6334 - accuracy: 0.7302 - val_loss: 0.9416 - val_accuracy: 0.5625\n",
      "Epoch 317/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6158 - accuracy: 0.7302 - val_loss: 1.0119 - val_accuracy: 0.6250\n",
      "Epoch 318/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6218 - accuracy: 0.6825 - val_loss: 1.0887 - val_accuracy: 0.6250\n",
      "Epoch 319/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6322 - accuracy: 0.6667 - val_loss: 1.0429 - val_accuracy: 0.6250\n",
      "Epoch 320/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6183 - accuracy: 0.6667 - val_loss: 0.9686 - val_accuracy: 0.5625\n",
      "Epoch 321/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6153 - accuracy: 0.7460 - val_loss: 0.9304 - val_accuracy: 0.5625\n",
      "Epoch 322/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6175 - accuracy: 0.7460 - val_loss: 0.9124 - val_accuracy: 0.5625\n",
      "Epoch 323/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6255 - accuracy: 0.7143 - val_loss: 0.9832 - val_accuracy: 0.6250\n",
      "Epoch 324/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.6153 - accuracy: 0.6984 - val_loss: 0.9813 - val_accuracy: 0.6250\n",
      "Epoch 325/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.6148 - accuracy: 0.6984 - val_loss: 1.0132 - val_accuracy: 0.6250\n",
      "Epoch 326/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6093 - accuracy: 0.6984 - val_loss: 0.9762 - val_accuracy: 0.6250\n",
      "Epoch 327/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6067 - accuracy: 0.7143 - val_loss: 0.9393 - val_accuracy: 0.5625\n",
      "Epoch 328/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6235 - accuracy: 0.7460 - val_loss: 0.9551 - val_accuracy: 0.5625\n",
      "Epoch 329/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6075 - accuracy: 0.7460 - val_loss: 0.9382 - val_accuracy: 0.5625\n",
      "Epoch 330/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6068 - accuracy: 0.6984 - val_loss: 0.9415 - val_accuracy: 0.6250\n",
      "Epoch 331/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6071 - accuracy: 0.7143 - val_loss: 0.9272 - val_accuracy: 0.5625\n",
      "Epoch 332/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6030 - accuracy: 0.7460 - val_loss: 0.9564 - val_accuracy: 0.6250\n",
      "Epoch 333/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 127us/step - loss: 0.6007 - accuracy: 0.7460 - val_loss: 0.9749 - val_accuracy: 0.6250\n",
      "Epoch 334/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.6024 - accuracy: 0.6984 - val_loss: 0.9619 - val_accuracy: 0.6250\n",
      "Epoch 335/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.6001 - accuracy: 0.7143 - val_loss: 0.9597 - val_accuracy: 0.6250\n",
      "Epoch 336/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6056 - accuracy: 0.7143 - val_loss: 0.9376 - val_accuracy: 0.6250\n",
      "Epoch 337/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6001 - accuracy: 0.7143 - val_loss: 0.9448 - val_accuracy: 0.6250\n",
      "Epoch 338/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5960 - accuracy: 0.6984 - val_loss: 0.9680 - val_accuracy: 0.6250\n",
      "Epoch 339/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.6003 - accuracy: 0.7460 - val_loss: 0.9533 - val_accuracy: 0.6250\n",
      "Epoch 340/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5979 - accuracy: 0.7460 - val_loss: 0.9328 - val_accuracy: 0.6250\n",
      "Epoch 341/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6602 - accuracy: 0.68 - 0s 159us/step - loss: 0.5943 - accuracy: 0.7460 - val_loss: 0.9156 - val_accuracy: 0.6250\n",
      "Epoch 342/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5949 - accuracy: 0.7143 - val_loss: 0.9432 - val_accuracy: 0.6250\n",
      "Epoch 343/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5946 - accuracy: 0.7143 - val_loss: 0.9373 - val_accuracy: 0.6250\n",
      "Epoch 344/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6148 - accuracy: 0.65 - 0s 159us/step - loss: 0.5910 - accuracy: 0.7143 - val_loss: 0.9399 - val_accuracy: 0.6250\n",
      "Epoch 345/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5883 - accuracy: 0.7302 - val_loss: 0.9301 - val_accuracy: 0.6250\n",
      "Epoch 346/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5900 - accuracy: 0.7460 - val_loss: 0.9279 - val_accuracy: 0.6250\n",
      "Epoch 347/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5996 - accuracy: 0.7302 - val_loss: 0.9141 - val_accuracy: 0.6250\n",
      "Epoch 348/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.5920 - accuracy: 0.7460 - val_loss: 0.9133 - val_accuracy: 0.6250\n",
      "Epoch 349/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.5900 - accuracy: 0.7143 - val_loss: 0.9710 - val_accuracy: 0.6250\n",
      "Epoch 350/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.6002 - accuracy: 0.7143 - val_loss: 0.9348 - val_accuracy: 0.6250\n",
      "Epoch 351/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5908 - accuracy: 0.7302 - val_loss: 0.9357 - val_accuracy: 0.6250\n",
      "Epoch 352/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.5829 - accuracy: 0.7302 - val_loss: 0.9394 - val_accuracy: 0.6250\n",
      "Epoch 353/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5929 - accuracy: 0.7302 - val_loss: 0.9006 - val_accuracy: 0.6250\n",
      "Epoch 354/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5813 - accuracy: 0.7460 - val_loss: 0.9182 - val_accuracy: 0.6250\n",
      "Epoch 355/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.5832 - accuracy: 0.7143 - val_loss: 0.9165 - val_accuracy: 0.6250\n",
      "Epoch 356/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5802 - accuracy: 0.7302 - val_loss: 0.9238 - val_accuracy: 0.6250\n",
      "Epoch 357/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5780 - accuracy: 0.7302 - val_loss: 0.9282 - val_accuracy: 0.6250\n",
      "Epoch 358/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5830 - accuracy: 0.7302 - val_loss: 0.9103 - val_accuracy: 0.6250\n",
      "Epoch 359/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5760 - accuracy: 0.7302 - val_loss: 0.9104 - val_accuracy: 0.6250\n",
      "Epoch 360/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5760 - accuracy: 0.7460 - val_loss: 0.9279 - val_accuracy: 0.6250\n",
      "Epoch 361/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5852 - accuracy: 0.7460 - val_loss: 0.8927 - val_accuracy: 0.6250\n",
      "Epoch 362/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5732 - accuracy: 0.7460 - val_loss: 0.9067 - val_accuracy: 0.6250\n",
      "Epoch 363/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5846 - accuracy: 0.7302 - val_loss: 0.9046 - val_accuracy: 0.6250\n",
      "Epoch 364/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5726 - accuracy: 0.7302 - val_loss: 0.9243 - val_accuracy: 0.6250\n",
      "Epoch 365/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.7017 - accuracy: 0.65 - 0s 222us/step - loss: 0.5737 - accuracy: 0.7302 - val_loss: 0.9240 - val_accuracy: 0.6250\n",
      "Epoch 366/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6566 - accuracy: 0.62 - 0s 175us/step - loss: 0.5821 - accuracy: 0.7302 - val_loss: 0.8894 - val_accuracy: 0.6875\n",
      "Epoch 367/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5720 - accuracy: 0.7460 - val_loss: 0.8623 - val_accuracy: 0.6250\n",
      "Epoch 368/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5708 - accuracy: 0.7143 - val_loss: 0.8680 - val_accuracy: 0.6250\n",
      "Epoch 369/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5693 - accuracy: 0.7302 - val_loss: 0.8939 - val_accuracy: 0.6250\n",
      "Epoch 370/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5703 - accuracy: 0.7302 - val_loss: 0.9054 - val_accuracy: 0.6250\n",
      "Epoch 371/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5689 - accuracy: 0.7302 - val_loss: 0.8920 - val_accuracy: 0.6250\n",
      "Epoch 372/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5734 - accuracy: 0.7460 - val_loss: 0.8994 - val_accuracy: 0.6250\n",
      "Epoch 373/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5651 - accuracy: 0.7619 - val_loss: 0.8762 - val_accuracy: 0.6250\n",
      "Epoch 374/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5656 - accuracy: 0.7460 - val_loss: 0.8323 - val_accuracy: 0.6875\n",
      "Epoch 375/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.5869 - accuracy: 0.7460 - val_loss: 0.8348 - val_accuracy: 0.6875\n",
      "Epoch 376/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5678 - accuracy: 0.7302 - val_loss: 0.9114 - val_accuracy: 0.6250\n",
      "Epoch 377/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5633 - accuracy: 0.7143 - val_loss: 0.9281 - val_accuracy: 0.6250\n",
      "Epoch 378/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5647 - accuracy: 0.7302 - val_loss: 0.8986 - val_accuracy: 0.6250\n",
      "Epoch 379/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5578 - accuracy: 0.7619 - val_loss: 0.8586 - val_accuracy: 0.6875\n",
      "Epoch 380/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5570 - accuracy: 0.7460 - val_loss: 0.8428 - val_accuracy: 0.6875\n",
      "Epoch 381/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5590 - accuracy: 0.7302 - val_loss: 0.8290 - val_accuracy: 0.6875\n",
      "Epoch 382/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5583 - accuracy: 0.7302 - val_loss: 0.8675 - val_accuracy: 0.6250\n",
      "Epoch 383/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5511 - accuracy: 0.7302 - val_loss: 0.8840 - val_accuracy: 0.6250\n",
      "Epoch 384/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5773 - accuracy: 0.7460 - val_loss: 0.8433 - val_accuracy: 0.7500\n",
      "Epoch 385/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5501 - accuracy: 0.7619 - val_loss: 0.8715 - val_accuracy: 0.6875\n",
      "Epoch 386/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5551 - accuracy: 0.7460 - val_loss: 0.9062 - val_accuracy: 0.6250\n",
      "Epoch 387/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5525 - accuracy: 0.7302 - val_loss: 0.8709 - val_accuracy: 0.6250\n",
      "Epoch 388/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 222us/step - loss: 0.5520 - accuracy: 0.7302 - val_loss: 0.8204 - val_accuracy: 0.6875\n",
      "Epoch 389/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5608 - accuracy: 0.7460 - val_loss: 0.8097 - val_accuracy: 0.8125\n",
      "Epoch 390/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.5515 - accuracy: 0.7302 - val_loss: 0.8737 - val_accuracy: 0.6875\n",
      "Epoch 391/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5487 - accuracy: 0.7302 - val_loss: 0.8773 - val_accuracy: 0.6875\n",
      "Epoch 392/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5456 - accuracy: 0.7302 - val_loss: 0.8805 - val_accuracy: 0.6875\n",
      "Epoch 393/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5483 - accuracy: 0.7302 - val_loss: 0.8475 - val_accuracy: 0.6875\n",
      "Epoch 394/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5470 - accuracy: 0.7460 - val_loss: 0.8382 - val_accuracy: 0.6875\n",
      "Epoch 395/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5445 - accuracy: 0.7302 - val_loss: 0.8539 - val_accuracy: 0.6875\n",
      "Epoch 396/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5439 - accuracy: 0.7302 - val_loss: 0.8245 - val_accuracy: 0.6875\n",
      "Epoch 397/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5415 - accuracy: 0.7619 - val_loss: 0.8235 - val_accuracy: 0.8125\n",
      "Epoch 398/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5405 - accuracy: 0.7460 - val_loss: 0.8490 - val_accuracy: 0.7500\n",
      "Epoch 399/1000\n",
      "63/63 [==============================] - 0s 142us/step - loss: 0.5376 - accuracy: 0.7460 - val_loss: 0.8766 - val_accuracy: 0.6875\n",
      "Epoch 400/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5415 - accuracy: 0.7302 - val_loss: 0.8787 - val_accuracy: 0.6875\n",
      "Epoch 401/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5374 - accuracy: 0.7302 - val_loss: 0.8350 - val_accuracy: 0.6875\n",
      "Epoch 402/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5333 - accuracy: 0.7302 - val_loss: 0.8186 - val_accuracy: 0.8125\n",
      "Epoch 403/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5330 - accuracy: 0.7619 - val_loss: 0.8151 - val_accuracy: 0.8125\n",
      "Epoch 404/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5505 - accuracy: 0.7619 - val_loss: 0.8623 - val_accuracy: 0.6875\n",
      "Epoch 405/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5398 - accuracy: 0.7302 - val_loss: 0.8621 - val_accuracy: 0.6875\n",
      "Epoch 406/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5315 - accuracy: 0.7302 - val_loss: 0.8171 - val_accuracy: 0.6875\n",
      "Epoch 407/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5369 - accuracy: 0.7460 - val_loss: 0.7829 - val_accuracy: 0.8125\n",
      "Epoch 408/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5440 - accuracy: 0.7778 - val_loss: 0.7930 - val_accuracy: 0.8125\n",
      "Epoch 409/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5299 - accuracy: 0.7460 - val_loss: 0.8807 - val_accuracy: 0.6875\n",
      "Epoch 410/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5317 - accuracy: 0.7143 - val_loss: 0.9046 - val_accuracy: 0.6875\n",
      "Epoch 411/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5453 - accuracy: 0.7143 - val_loss: 0.8391 - val_accuracy: 0.7500\n",
      "Epoch 412/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5295 - accuracy: 0.7619 - val_loss: 0.8240 - val_accuracy: 0.6875\n",
      "Epoch 413/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.5280 - accuracy: 0.7302 - val_loss: 0.8259 - val_accuracy: 0.6875\n",
      "Epoch 414/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5338 - accuracy: 0.7460 - val_loss: 0.7961 - val_accuracy: 0.8125\n",
      "Epoch 415/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5281 - accuracy: 0.7460 - val_loss: 0.8396 - val_accuracy: 0.6875\n",
      "Epoch 416/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5220 - accuracy: 0.7460 - val_loss: 0.8496 - val_accuracy: 0.6875\n",
      "Epoch 417/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.5222 - accuracy: 0.7460 - val_loss: 0.8264 - val_accuracy: 0.8125\n",
      "Epoch 418/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5201 - accuracy: 0.7460 - val_loss: 0.8183 - val_accuracy: 0.8125\n",
      "Epoch 419/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5182 - accuracy: 0.7460 - val_loss: 0.8189 - val_accuracy: 0.7500\n",
      "Epoch 420/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5334 - accuracy: 0.7302 - val_loss: 0.8050 - val_accuracy: 0.7500\n",
      "Epoch 421/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5256 - accuracy: 0.7302 - val_loss: 0.8636 - val_accuracy: 0.6875\n",
      "Epoch 422/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5186 - accuracy: 0.7302 - val_loss: 0.8465 - val_accuracy: 0.7500\n",
      "Epoch 423/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5208 - accuracy: 0.7460 - val_loss: 0.8128 - val_accuracy: 0.8125\n",
      "Epoch 424/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.5164 - accuracy: 0.7619 - val_loss: 0.8095 - val_accuracy: 0.8125\n",
      "Epoch 425/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5173 - accuracy: 0.7619 - val_loss: 0.8114 - val_accuracy: 0.8125\n",
      "Epoch 426/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5207 - accuracy: 0.7460 - val_loss: 0.7927 - val_accuracy: 0.7500\n",
      "Epoch 427/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5191 - accuracy: 0.7302 - val_loss: 0.8228 - val_accuracy: 0.7500\n",
      "Epoch 428/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5130 - accuracy: 0.7302 - val_loss: 0.8164 - val_accuracy: 0.7500\n",
      "Epoch 429/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5432 - accuracy: 0.7619 - val_loss: 0.7797 - val_accuracy: 0.8125\n",
      "Epoch 430/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5159 - accuracy: 0.7619 - val_loss: 0.8121 - val_accuracy: 0.8125\n",
      "Epoch 431/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.5142 - accuracy: 0.7302 - val_loss: 0.8678 - val_accuracy: 0.6875\n",
      "Epoch 432/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5207 - accuracy: 0.7460 - val_loss: 0.8836 - val_accuracy: 0.6875\n",
      "Epoch 433/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5224 - accuracy: 0.7143 - val_loss: 0.8125 - val_accuracy: 0.7500\n",
      "Epoch 434/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5166 - accuracy: 0.7619 - val_loss: 0.7566 - val_accuracy: 0.8125\n",
      "Epoch 435/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5116 - accuracy: 0.7778 - val_loss: 0.7762 - val_accuracy: 0.8125\n",
      "Epoch 436/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5044 - accuracy: 0.7778 - val_loss: 0.8263 - val_accuracy: 0.7500\n",
      "Epoch 437/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.75 - 0s 175us/step - loss: 0.5112 - accuracy: 0.7302 - val_loss: 0.8713 - val_accuracy: 0.7500\n",
      "Epoch 438/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.5170 - accuracy: 0.6984 - val_loss: 0.8222 - val_accuracy: 0.7500\n",
      "Epoch 439/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5049 - accuracy: 0.7302 - val_loss: 0.8048 - val_accuracy: 0.8125\n",
      "Epoch 440/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.5041 - accuracy: 0.7460 - val_loss: 0.7663 - val_accuracy: 0.8125\n",
      "Epoch 441/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5052 - accuracy: 0.7778 - val_loss: 0.7712 - val_accuracy: 0.8125\n",
      "Epoch 442/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5045 - accuracy: 0.7778 - val_loss: 0.8113 - val_accuracy: 0.8125\n",
      "Epoch 443/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5087 - accuracy: 0.7302 - val_loss: 0.8464 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.5095 - accuracy: 0.7302 - val_loss: 0.7851 - val_accuracy: 0.8125\n",
      "Epoch 445/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5010 - accuracy: 0.7619 - val_loss: 0.7705 - val_accuracy: 0.8125\n",
      "Epoch 446/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.5122 - accuracy: 0.78 - 0s 159us/step - loss: 0.4983 - accuracy: 0.7619 - val_loss: 0.7983 - val_accuracy: 0.8125\n",
      "Epoch 447/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6117 - accuracy: 0.71 - 0s 159us/step - loss: 0.5109 - accuracy: 0.7778 - val_loss: 0.8361 - val_accuracy: 0.7500\n",
      "Epoch 448/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4973 - accuracy: 0.7460 - val_loss: 0.8025 - val_accuracy: 0.8125\n",
      "Epoch 449/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4981 - accuracy: 0.7619 - val_loss: 0.7543 - val_accuracy: 0.8125\n",
      "Epoch 450/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4975 - accuracy: 0.7778 - val_loss: 0.7627 - val_accuracy: 0.8125\n",
      "Epoch 451/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5094 - accuracy: 0.7778 - val_loss: 0.8102 - val_accuracy: 0.8125\n",
      "Epoch 452/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.5019 - accuracy: 0.7778 - val_loss: 0.8070 - val_accuracy: 0.8125\n",
      "Epoch 453/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4895 - accuracy: 0.7460 - val_loss: 0.8171 - val_accuracy: 0.7500\n",
      "Epoch 454/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4919 - accuracy: 0.7302 - val_loss: 0.8096 - val_accuracy: 0.7500\n",
      "Epoch 455/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.4974 - accuracy: 0.7302 - val_loss: 0.7762 - val_accuracy: 0.7500\n",
      "Epoch 456/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4971 - accuracy: 0.7460 - val_loss: 0.7666 - val_accuracy: 0.8125\n",
      "Epoch 457/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.4376 - accuracy: 0.81 - 0s 238us/step - loss: 0.4931 - accuracy: 0.7778 - val_loss: 0.8109 - val_accuracy: 0.8125\n",
      "Epoch 458/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4973 - accuracy: 0.7778 - val_loss: 0.8194 - val_accuracy: 0.8125\n",
      "Epoch 459/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4914 - accuracy: 0.7937 - val_loss: 0.7965 - val_accuracy: 0.8125\n",
      "Epoch 460/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4904 - accuracy: 0.7460 - val_loss: 0.7545 - val_accuracy: 0.7500\n",
      "Epoch 461/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.5149 - accuracy: 0.7937 - val_loss: 0.7407 - val_accuracy: 0.7500\n",
      "Epoch 462/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.5007 - accuracy: 0.7778 - val_loss: 0.8164 - val_accuracy: 0.7500\n",
      "Epoch 463/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4879 - accuracy: 0.7619 - val_loss: 0.8350 - val_accuracy: 0.8125\n",
      "Epoch 464/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4906 - accuracy: 0.7619 - val_loss: 0.8088 - val_accuracy: 0.8125\n",
      "Epoch 465/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4845 - accuracy: 0.7778 - val_loss: 0.7904 - val_accuracy: 0.8125\n",
      "Epoch 466/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4800 - accuracy: 0.7460 - val_loss: 0.7597 - val_accuracy: 0.8125\n",
      "Epoch 467/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4897 - accuracy: 0.7778 - val_loss: 0.7390 - val_accuracy: 0.8125\n",
      "Epoch 468/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.71 - 0s 191us/step - loss: 0.4818 - accuracy: 0.7619 - val_loss: 0.7772 - val_accuracy: 0.8125\n",
      "Epoch 469/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4827 - accuracy: 0.7778 - val_loss: 0.8138 - val_accuracy: 0.8125\n",
      "Epoch 470/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4901 - accuracy: 0.7619 - val_loss: 0.8212 - val_accuracy: 0.8125\n",
      "Epoch 471/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4871 - accuracy: 0.7460 - val_loss: 0.7660 - val_accuracy: 0.8125\n",
      "Epoch 472/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4869 - accuracy: 0.7619 - val_loss: 0.7204 - val_accuracy: 0.8125\n",
      "Epoch 473/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.5053 - accuracy: 0.8095 - val_loss: 0.7252 - val_accuracy: 0.8125\n",
      "Epoch 474/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4767 - accuracy: 0.7778 - val_loss: 0.8130 - val_accuracy: 0.8125\n",
      "Epoch 475/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4769 - accuracy: 0.7619 - val_loss: 0.8373 - val_accuracy: 0.7500\n",
      "Epoch 476/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4946 - accuracy: 0.7302 - val_loss: 0.8407 - val_accuracy: 0.7500\n",
      "Epoch 477/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4765 - accuracy: 0.7778 - val_loss: 0.7604 - val_accuracy: 0.8125\n",
      "Epoch 478/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4798 - accuracy: 0.7937 - val_loss: 0.6959 - val_accuracy: 0.8125\n",
      "Epoch 479/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4895 - accuracy: 0.8254 - val_loss: 0.7332 - val_accuracy: 0.8125\n",
      "Epoch 480/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4708 - accuracy: 0.7619 - val_loss: 0.7727 - val_accuracy: 0.8125\n",
      "Epoch 481/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4705 - accuracy: 0.7619 - val_loss: 0.8089 - val_accuracy: 0.8125\n",
      "Epoch 482/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4922 - accuracy: 0.7460 - val_loss: 0.8277 - val_accuracy: 0.7500\n",
      "Epoch 483/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4726 - accuracy: 0.7460 - val_loss: 0.7430 - val_accuracy: 0.8125\n",
      "Epoch 484/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4727 - accuracy: 0.7937 - val_loss: 0.7047 - val_accuracy: 0.8125\n",
      "Epoch 485/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.4775 - accuracy: 0.8254 - val_loss: 0.7366 - val_accuracy: 0.8125\n",
      "Epoch 486/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4713 - accuracy: 0.7778 - val_loss: 0.7979 - val_accuracy: 0.8125\n",
      "Epoch 487/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4715 - accuracy: 0.7778 - val_loss: 0.8201 - val_accuracy: 0.7500\n",
      "Epoch 488/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4720 - accuracy: 0.7460 - val_loss: 0.7619 - val_accuracy: 0.8125\n",
      "Epoch 489/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4629 - accuracy: 0.7460 - val_loss: 0.7450 - val_accuracy: 0.8125\n",
      "Epoch 490/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4672 - accuracy: 0.7778 - val_loss: 0.7380 - val_accuracy: 0.8125\n",
      "Epoch 491/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.7698 - val_accuracy: 0.8125\n",
      "Epoch 492/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.4647 - accuracy: 0.7460 - val_loss: 0.7903 - val_accuracy: 0.8125\n",
      "Epoch 493/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4663 - accuracy: 0.7619 - val_loss: 0.7565 - val_accuracy: 0.8125\n",
      "Epoch 494/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.4616 - accuracy: 0.7460 - val_loss: 0.7402 - val_accuracy: 0.8125\n",
      "Epoch 495/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4621 - accuracy: 0.7778 - val_loss: 0.7614 - val_accuracy: 0.8125\n",
      "Epoch 496/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4648 - accuracy: 0.7460 - val_loss: 0.7576 - val_accuracy: 0.8125\n",
      "Epoch 497/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4711 - accuracy: 0.7619 - val_loss: 0.7877 - val_accuracy: 0.8125\n",
      "Epoch 498/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.4632 - accuracy: 0.7460 - val_loss: 0.7452 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4562 - accuracy: 0.7619 - val_loss: 0.7480 - val_accuracy: 0.8125\n",
      "Epoch 500/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4582 - accuracy: 0.7778 - val_loss: 0.7406 - val_accuracy: 0.8125\n",
      "Epoch 501/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4541 - accuracy: 0.7937 - val_loss: 0.7593 - val_accuracy: 0.8125\n",
      "Epoch 502/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4528 - accuracy: 0.7937 - val_loss: 0.7786 - val_accuracy: 0.8125\n",
      "Epoch 503/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4651 - accuracy: 0.7619 - val_loss: 0.7974 - val_accuracy: 0.8125\n",
      "Epoch 504/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4550 - accuracy: 0.7619 - val_loss: 0.7510 - val_accuracy: 0.8125\n",
      "Epoch 505/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4514 - accuracy: 0.7937 - val_loss: 0.7183 - val_accuracy: 0.8125\n",
      "Epoch 506/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4622 - accuracy: 0.7619 - val_loss: 0.7349 - val_accuracy: 0.8125\n",
      "Epoch 507/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4535 - accuracy: 0.7619 - val_loss: 0.7564 - val_accuracy: 0.8125\n",
      "Epoch 508/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4546 - accuracy: 0.7619 - val_loss: 0.7775 - val_accuracy: 0.8125\n",
      "Epoch 509/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4596 - accuracy: 0.7619 - val_loss: 0.7723 - val_accuracy: 0.8125\n",
      "Epoch 510/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4469 - accuracy: 0.7619 - val_loss: 0.7221 - val_accuracy: 0.8125\n",
      "Epoch 511/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4499 - accuracy: 0.7937 - val_loss: 0.7124 - val_accuracy: 0.8125\n",
      "Epoch 512/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4495 - accuracy: 0.7937 - val_loss: 0.7160 - val_accuracy: 0.8125\n",
      "Epoch 513/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4594 - accuracy: 0.7778 - val_loss: 0.7692 - val_accuracy: 0.8125\n",
      "Epoch 514/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4494 - accuracy: 0.7937 - val_loss: 0.7769 - val_accuracy: 0.8125\n",
      "Epoch 515/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4480 - accuracy: 0.7619 - val_loss: 0.7654 - val_accuracy: 0.8125\n",
      "Epoch 516/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4699 - accuracy: 0.7619 - val_loss: 0.7055 - val_accuracy: 0.8125\n",
      "Epoch 517/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4507 - accuracy: 0.7778 - val_loss: 0.7272 - val_accuracy: 0.8125\n",
      "Epoch 518/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.7512 - val_accuracy: 0.8125\n",
      "Epoch 519/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4458 - accuracy: 0.7937 - val_loss: 0.7957 - val_accuracy: 0.8125\n",
      "Epoch 520/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4511 - accuracy: 0.7619 - val_loss: 0.7715 - val_accuracy: 0.8125\n",
      "Epoch 521/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4406 - accuracy: 0.7619 - val_loss: 0.7474 - val_accuracy: 0.8125\n",
      "Epoch 522/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4392 - accuracy: 0.7619 - val_loss: 0.7197 - val_accuracy: 0.8125\n",
      "Epoch 523/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4436 - accuracy: 0.7937 - val_loss: 0.7207 - val_accuracy: 0.8125\n",
      "Epoch 524/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4454 - accuracy: 0.7778 - val_loss: 0.7300 - val_accuracy: 0.8125\n",
      "Epoch 525/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4459 - accuracy: 0.7619 - val_loss: 0.7802 - val_accuracy: 0.8125\n",
      "Epoch 526/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4402 - accuracy: 0.7619 - val_loss: 0.7676 - val_accuracy: 0.8125\n",
      "Epoch 527/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4395 - accuracy: 0.7619 - val_loss: 0.7310 - val_accuracy: 0.8125\n",
      "Epoch 528/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4415 - accuracy: 0.8095 - val_loss: 0.7031 - val_accuracy: 0.8125\n",
      "Epoch 529/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4380 - accuracy: 0.8095 - val_loss: 0.7370 - val_accuracy: 0.8125\n",
      "Epoch 530/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4342 - accuracy: 0.7937 - val_loss: 0.7594 - val_accuracy: 0.8125\n",
      "Epoch 531/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4355 - accuracy: 0.7619 - val_loss: 0.7569 - val_accuracy: 0.8125\n",
      "Epoch 532/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4336 - accuracy: 0.7619 - val_loss: 0.7438 - val_accuracy: 0.8125\n",
      "Epoch 533/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4426 - accuracy: 0.8095 - val_loss: 0.7062 - val_accuracy: 0.8125\n",
      "Epoch 534/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4346 - accuracy: 0.7937 - val_loss: 0.7322 - val_accuracy: 0.8125\n",
      "Epoch 535/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4302 - accuracy: 0.7619 - val_loss: 0.7491 - val_accuracy: 0.8125\n",
      "Epoch 536/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4295 - accuracy: 0.7619 - val_loss: 0.7587 - val_accuracy: 0.8125\n",
      "Epoch 537/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4329 - accuracy: 0.7778 - val_loss: 0.7423 - val_accuracy: 0.8125\n",
      "Epoch 538/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4279 - accuracy: 0.7619 - val_loss: 0.7434 - val_accuracy: 0.8125\n",
      "Epoch 539/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4296 - accuracy: 0.7778 - val_loss: 0.7428 - val_accuracy: 0.8125\n",
      "Epoch 540/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4266 - accuracy: 0.7778 - val_loss: 0.7246 - val_accuracy: 0.8125\n",
      "Epoch 541/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4341 - accuracy: 0.7778 - val_loss: 0.7079 - val_accuracy: 0.8125\n",
      "Epoch 542/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4554 - accuracy: 0.7778 - val_loss: 0.7584 - val_accuracy: 0.8125\n",
      "Epoch 543/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4289 - accuracy: 0.7937 - val_loss: 0.7516 - val_accuracy: 0.8125\n",
      "Epoch 544/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.4296 - accuracy: 0.7619 - val_loss: 0.7511 - val_accuracy: 0.8125\n",
      "Epoch 545/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4292 - accuracy: 0.7619 - val_loss: 0.7124 - val_accuracy: 0.8125\n",
      "Epoch 546/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4287 - accuracy: 0.7778 - val_loss: 0.6968 - val_accuracy: 0.8125\n",
      "Epoch 547/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4277 - accuracy: 0.7937 - val_loss: 0.7190 - val_accuracy: 0.8125\n",
      "Epoch 548/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4275 - accuracy: 0.7778 - val_loss: 0.7557 - val_accuracy: 0.8125\n",
      "Epoch 549/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4229 - accuracy: 0.7937 - val_loss: 0.7531 - val_accuracy: 0.8125\n",
      "Epoch 550/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4232 - accuracy: 0.7778 - val_loss: 0.7332 - val_accuracy: 0.8125\n",
      "Epoch 551/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4272 - accuracy: 0.7778 - val_loss: 0.7353 - val_accuracy: 0.8125\n",
      "Epoch 552/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4207 - accuracy: 0.7937 - val_loss: 0.7117 - val_accuracy: 0.8125\n",
      "Epoch 553/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4184 - accuracy: 0.8095 - val_loss: 0.7126 - val_accuracy: 0.8125\n",
      "Epoch 554/1000\n",
      "63/63 [==============================] - 0s 207us/step - loss: 0.4238 - accuracy: 0.8095 - val_loss: 0.7137 - val_accuracy: 0.8125\n",
      "Epoch 555/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 127us/step - loss: 0.4332 - accuracy: 0.7619 - val_loss: 0.7344 - val_accuracy: 0.8125\n",
      "Epoch 556/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4167 - accuracy: 0.7778 - val_loss: 0.7513 - val_accuracy: 0.8125\n",
      "Epoch 557/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.4203 - accuracy: 0.7778 - val_loss: 0.7616 - val_accuracy: 0.8125\n",
      "Epoch 558/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4198 - accuracy: 0.7778 - val_loss: 0.7213 - val_accuracy: 0.8125\n",
      "Epoch 559/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4191 - accuracy: 0.8095 - val_loss: 0.7257 - val_accuracy: 0.8125\n",
      "Epoch 560/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4176 - accuracy: 0.8095 - val_loss: 0.7076 - val_accuracy: 0.8125\n",
      "Epoch 561/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4187 - accuracy: 0.7937 - val_loss: 0.6971 - val_accuracy: 0.8125\n",
      "Epoch 562/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4170 - accuracy: 0.7619 - val_loss: 0.7397 - val_accuracy: 0.8125\n",
      "Epoch 563/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4157 - accuracy: 0.7778 - val_loss: 0.7543 - val_accuracy: 0.8125\n",
      "Epoch 564/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4163 - accuracy: 0.7619 - val_loss: 0.7334 - val_accuracy: 0.8125\n",
      "Epoch 565/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4110 - accuracy: 0.7937 - val_loss: 0.6953 - val_accuracy: 0.8125\n",
      "Epoch 566/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.4127 - accuracy: 0.7778 - val_loss: 0.6941 - val_accuracy: 0.8125\n",
      "Epoch 567/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4107 - accuracy: 0.7937 - val_loss: 0.7202 - val_accuracy: 0.8125\n",
      "Epoch 568/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.4184 - accuracy: 0.7778 - val_loss: 0.7564 - val_accuracy: 0.8125\n",
      "Epoch 569/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4101 - accuracy: 0.7778 - val_loss: 0.7350 - val_accuracy: 0.8125\n",
      "Epoch 570/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4109 - accuracy: 0.7937 - val_loss: 0.7066 - val_accuracy: 0.8125\n",
      "Epoch 571/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.4076 - accuracy: 0.7937 - val_loss: 0.6899 - val_accuracy: 0.8125\n",
      "Epoch 572/1000\n",
      "63/63 [==============================] - 0s 349us/step - loss: 0.4112 - accuracy: 0.7778 - val_loss: 0.7130 - val_accuracy: 0.8125\n",
      "Epoch 573/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4099 - accuracy: 0.7778 - val_loss: 0.7360 - val_accuracy: 0.8125\n",
      "Epoch 574/1000\n",
      "63/63 [==============================] - 0s 286us/step - loss: 0.4067 - accuracy: 0.7778 - val_loss: 0.7175 - val_accuracy: 0.8125\n",
      "Epoch 575/1000\n",
      "63/63 [==============================] - 0s 302us/step - loss: 0.4064 - accuracy: 0.7778 - val_loss: 0.7224 - val_accuracy: 0.8125\n",
      "Epoch 576/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4041 - accuracy: 0.8095 - val_loss: 0.6988 - val_accuracy: 0.8125\n",
      "Epoch 577/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.4042 - accuracy: 0.7937 - val_loss: 0.7097 - val_accuracy: 0.8125\n",
      "Epoch 578/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.4027 - accuracy: 0.8095 - val_loss: 0.7135 - val_accuracy: 0.8125\n",
      "Epoch 579/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4068 - accuracy: 0.7937 - val_loss: 0.7438 - val_accuracy: 0.8125\n",
      "Epoch 580/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4031 - accuracy: 0.7778 - val_loss: 0.7287 - val_accuracy: 0.8125\n",
      "Epoch 581/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.4016 - accuracy: 0.7778 - val_loss: 0.6974 - val_accuracy: 0.8125\n",
      "Epoch 582/1000\n",
      "63/63 [==============================] - 0s 317us/step - loss: 0.4022 - accuracy: 0.7778 - val_loss: 0.6873 - val_accuracy: 0.8125\n",
      "Epoch 583/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3994 - accuracy: 0.8095 - val_loss: 0.7125 - val_accuracy: 0.8125\n",
      "Epoch 584/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3999 - accuracy: 0.8095 - val_loss: 0.7425 - val_accuracy: 0.8125\n",
      "Epoch 585/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.4016 - accuracy: 0.7778 - val_loss: 0.7437 - val_accuracy: 0.8125\n",
      "Epoch 586/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.3973 - accuracy: 0.7937 - val_loss: 0.7127 - val_accuracy: 0.8125\n",
      "Epoch 587/1000\n",
      "63/63 [==============================] - 0s 302us/step - loss: 0.3955 - accuracy: 0.7778 - val_loss: 0.6919 - val_accuracy: 0.8125\n",
      "Epoch 588/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.4060 - accuracy: 0.7778 - val_loss: 0.6929 - val_accuracy: 0.8125\n",
      "Epoch 589/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.3990 - accuracy: 0.7937 - val_loss: 0.7089 - val_accuracy: 0.8125\n",
      "Epoch 590/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3938 - accuracy: 0.7937 - val_loss: 0.7292 - val_accuracy: 0.8125\n",
      "Epoch 591/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3940 - accuracy: 0.7778 - val_loss: 0.7312 - val_accuracy: 0.8125\n",
      "Epoch 592/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3965 - accuracy: 0.7778 - val_loss: 0.7011 - val_accuracy: 0.8125\n",
      "Epoch 593/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3927 - accuracy: 0.7937 - val_loss: 0.6998 - val_accuracy: 0.8125\n",
      "Epoch 594/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3453 - accuracy: 0.87 - 0s 143us/step - loss: 0.3932 - accuracy: 0.7937 - val_loss: 0.7156 - val_accuracy: 0.8125\n",
      "Epoch 595/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3916 - accuracy: 0.7937 - val_loss: 0.7211 - val_accuracy: 0.8125\n",
      "Epoch 596/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.3914 - accuracy: 0.7937 - val_loss: 0.7308 - val_accuracy: 0.8125\n",
      "Epoch 597/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3976 - accuracy: 0.7937 - val_loss: 0.7293 - val_accuracy: 0.8125\n",
      "Epoch 598/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3898 - accuracy: 0.7937 - val_loss: 0.7002 - val_accuracy: 0.8125\n",
      "Epoch 599/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.3892 - accuracy: 0.8095 - val_loss: 0.6722 - val_accuracy: 0.8125\n",
      "Epoch 600/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3926 - accuracy: 0.8254 - val_loss: 0.6852 - val_accuracy: 0.8125\n",
      "Epoch 601/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3895 - accuracy: 0.7778 - val_loss: 0.7163 - val_accuracy: 0.8125\n",
      "Epoch 602/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3874 - accuracy: 0.7778 - val_loss: 0.7348 - val_accuracy: 0.8125\n",
      "Epoch 603/1000\n",
      "63/63 [==============================] - 0s 381us/step - loss: 0.3911 - accuracy: 0.7937 - val_loss: 0.7272 - val_accuracy: 0.8125\n",
      "Epoch 604/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3890 - accuracy: 0.8095 - val_loss: 0.7130 - val_accuracy: 0.8125\n",
      "Epoch 605/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3918 - accuracy: 0.7937 - val_loss: 0.6717 - val_accuracy: 0.8125\n",
      "Epoch 606/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.3934 - accuracy: 0.8095 - val_loss: 0.7028 - val_accuracy: 0.8125\n",
      "Epoch 607/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3941 - accuracy: 0.7778 - val_loss: 0.7260 - val_accuracy: 0.8125\n",
      "Epoch 608/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.3829 - accuracy: 0.7778 - val_loss: 0.7135 - val_accuracy: 0.8125\n",
      "Epoch 609/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3969 - accuracy: 0.7778 - val_loss: 0.6832 - val_accuracy: 0.8750\n",
      "Epoch 610/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3902 - accuracy: 0.8254 - val_loss: 0.6949 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 611/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3802 - accuracy: 0.8095 - val_loss: 0.7327 - val_accuracy: 0.8125\n",
      "Epoch 612/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3841 - accuracy: 0.7937 - val_loss: 0.7459 - val_accuracy: 0.8125\n",
      "Epoch 613/1000\n",
      "63/63 [==============================] - 0s 270us/step - loss: 0.3837 - accuracy: 0.7778 - val_loss: 0.7384 - val_accuracy: 0.8125\n",
      "Epoch 614/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3819 - accuracy: 0.7778 - val_loss: 0.7045 - val_accuracy: 0.8125\n",
      "Epoch 615/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3885 - accuracy: 0.7937 - val_loss: 0.6799 - val_accuracy: 0.8750\n",
      "Epoch 616/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.81 - 0s 175us/step - loss: 0.3828 - accuracy: 0.8095 - val_loss: 0.7107 - val_accuracy: 0.8125\n",
      "Epoch 617/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3822 - accuracy: 0.7937 - val_loss: 0.7333 - val_accuracy: 0.8125\n",
      "Epoch 618/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3800 - accuracy: 0.7778 - val_loss: 0.7177 - val_accuracy: 0.8125\n",
      "Epoch 619/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3841 - accuracy: 0.7937 - val_loss: 0.6917 - val_accuracy: 0.8125\n",
      "Epoch 620/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3819 - accuracy: 0.8095 - val_loss: 0.6803 - val_accuracy: 0.8750\n",
      "Epoch 621/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3862 - accuracy: 0.7937 - val_loss: 0.7081 - val_accuracy: 0.8125\n",
      "Epoch 622/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3813 - accuracy: 0.7937 - val_loss: 0.6883 - val_accuracy: 0.8750\n",
      "Epoch 623/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3769 - accuracy: 0.8254 - val_loss: 0.7008 - val_accuracy: 0.8125\n",
      "Epoch 624/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3827 - accuracy: 0.7937 - val_loss: 0.7463 - val_accuracy: 0.8125\n",
      "Epoch 625/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3777 - accuracy: 0.7778 - val_loss: 0.7314 - val_accuracy: 0.8125\n",
      "Epoch 626/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3835 - accuracy: 0.7937 - val_loss: 0.6792 - val_accuracy: 0.8750\n",
      "Epoch 627/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3749 - accuracy: 0.8095 - val_loss: 0.6757 - val_accuracy: 0.8750\n",
      "Epoch 628/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3716 - accuracy: 0.8095 - val_loss: 0.7040 - val_accuracy: 0.8125\n",
      "Epoch 629/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3723 - accuracy: 0.7778 - val_loss: 0.7361 - val_accuracy: 0.8125\n",
      "Epoch 630/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3744 - accuracy: 0.7778 - val_loss: 0.7173 - val_accuracy: 0.8125\n",
      "Epoch 631/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3729 - accuracy: 0.7778 - val_loss: 0.6986 - val_accuracy: 0.8125\n",
      "Epoch 632/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.3678 - accuracy: 0.8095 - val_loss: 0.7012 - val_accuracy: 0.8750\n",
      "Epoch 633/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3701 - accuracy: 0.7937 - val_loss: 0.7154 - val_accuracy: 0.8125\n",
      "Epoch 634/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3695 - accuracy: 0.7937 - val_loss: 0.7185 - val_accuracy: 0.8125\n",
      "Epoch 635/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3683 - accuracy: 0.7937 - val_loss: 0.7095 - val_accuracy: 0.8125\n",
      "Epoch 636/1000\n",
      "63/63 [==============================] - 0s 397us/step - loss: 0.3886 - accuracy: 0.7937 - val_loss: 0.6749 - val_accuracy: 0.8750\n",
      "Epoch 637/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3691 - accuracy: 0.8095 - val_loss: 0.7031 - val_accuracy: 0.8750\n",
      "Epoch 638/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3851 - accuracy: 0.8095 - val_loss: 0.7708 - val_accuracy: 0.8125\n",
      "Epoch 639/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3770 - accuracy: 0.8254 - val_loss: 0.7403 - val_accuracy: 0.8125\n",
      "Epoch 640/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3711 - accuracy: 0.7937 - val_loss: 0.6741 - val_accuracy: 0.8750\n",
      "Epoch 641/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3755 - accuracy: 0.7937 - val_loss: 0.6645 - val_accuracy: 0.8750\n",
      "Epoch 642/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3676 - accuracy: 0.8095 - val_loss: 0.7031 - val_accuracy: 0.8750\n",
      "Epoch 643/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3621 - accuracy: 0.8095 - val_loss: 0.7317 - val_accuracy: 0.8750\n",
      "Epoch 644/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3681 - accuracy: 0.8413 - val_loss: 0.7469 - val_accuracy: 0.8125\n",
      "Epoch 645/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3703 - accuracy: 0.8413 - val_loss: 0.7092 - val_accuracy: 0.8125\n",
      "Epoch 646/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3610 - accuracy: 0.7937 - val_loss: 0.6978 - val_accuracy: 0.8125\n",
      "Epoch 647/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3668 - accuracy: 0.7937 - val_loss: 0.6971 - val_accuracy: 0.8125\n",
      "Epoch 648/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3617 - accuracy: 0.8095 - val_loss: 0.6930 - val_accuracy: 0.8750\n",
      "Epoch 649/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3741 - accuracy: 0.8095 - val_loss: 0.6853 - val_accuracy: 0.8750\n",
      "Epoch 650/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3628 - accuracy: 0.8095 - val_loss: 0.7062 - val_accuracy: 0.8750\n",
      "Epoch 651/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3599 - accuracy: 0.7937 - val_loss: 0.7250 - val_accuracy: 0.8125\n",
      "Epoch 652/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3648 - accuracy: 0.8095 - val_loss: 0.7097 - val_accuracy: 0.8125\n",
      "Epoch 653/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3609 - accuracy: 0.7937 - val_loss: 0.7006 - val_accuracy: 0.8750\n",
      "Epoch 654/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3671 - accuracy: 0.8095 - val_loss: 0.6738 - val_accuracy: 0.8750\n",
      "Epoch 655/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3616 - accuracy: 0.8254 - val_loss: 0.6882 - val_accuracy: 0.8750\n",
      "Epoch 656/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3609 - accuracy: 0.7937 - val_loss: 0.7155 - val_accuracy: 0.8125\n",
      "Epoch 657/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3612 - accuracy: 0.8254 - val_loss: 0.7648 - val_accuracy: 0.8125\n",
      "Epoch 658/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3757 - accuracy: 0.8413 - val_loss: 0.7531 - val_accuracy: 0.8125\n",
      "Epoch 659/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3552 - accuracy: 0.8413 - val_loss: 0.6654 - val_accuracy: 0.8750\n",
      "Epoch 660/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3566 - accuracy: 0.8254 - val_loss: 0.6510 - val_accuracy: 0.8750\n",
      "Epoch 661/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3664 - accuracy: 0.8095 - val_loss: 0.6578 - val_accuracy: 0.8750\n",
      "Epoch 662/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3607 - accuracy: 0.8254 - val_loss: 0.7247 - val_accuracy: 0.8750\n",
      "Epoch 663/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3645 - accuracy: 0.8254 - val_loss: 0.7622 - val_accuracy: 0.8125\n",
      "Epoch 664/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3572 - accuracy: 0.8413 - val_loss: 0.7201 - val_accuracy: 0.8125\n",
      "Epoch 665/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3576 - accuracy: 0.8095 - val_loss: 0.6762 - val_accuracy: 0.8750\n",
      "Epoch 666/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3537 - accuracy: 0.8254 - val_loss: 0.6646 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 667/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3535 - accuracy: 0.8413 - val_loss: 0.6660 - val_accuracy: 0.8750\n",
      "Epoch 668/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3559 - accuracy: 0.8095 - val_loss: 0.7013 - val_accuracy: 0.8750\n",
      "Epoch 669/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3625 - accuracy: 0.7937 - val_loss: 0.7476 - val_accuracy: 0.8125\n",
      "Epoch 670/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3569 - accuracy: 0.8254 - val_loss: 0.7007 - val_accuracy: 0.8750\n",
      "Epoch 671/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3661 - accuracy: 0.7937 - val_loss: 0.6613 - val_accuracy: 0.8750\n",
      "Epoch 672/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3524 - accuracy: 0.8254 - val_loss: 0.6956 - val_accuracy: 0.8750\n",
      "Epoch 673/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3470 - accuracy: 0.8254 - val_loss: 0.7206 - val_accuracy: 0.8750\n",
      "Epoch 674/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3618 - accuracy: 0.8571 - val_loss: 0.7573 - val_accuracy: 0.8750\n",
      "Epoch 675/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3528 - accuracy: 0.8413 - val_loss: 0.6997 - val_accuracy: 0.8750\n",
      "Epoch 676/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3459 - accuracy: 0.8413 - val_loss: 0.6717 - val_accuracy: 0.8750\n",
      "Epoch 677/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3457 - accuracy: 0.8095 - val_loss: 0.6850 - val_accuracy: 0.8750\n",
      "Epoch 678/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3515 - accuracy: 0.8254 - val_loss: 0.7187 - val_accuracy: 0.8750\n",
      "Epoch 679/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3456 - accuracy: 0.8254 - val_loss: 0.7142 - val_accuracy: 0.8750\n",
      "Epoch 680/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3447 - accuracy: 0.8413 - val_loss: 0.7188 - val_accuracy: 0.8750\n",
      "Epoch 681/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.3449 - accuracy: 0.8254 - val_loss: 0.6971 - val_accuracy: 0.8750\n",
      "Epoch 682/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3419 - accuracy: 0.8254 - val_loss: 0.6998 - val_accuracy: 0.8750\n",
      "Epoch 683/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.3411 - accuracy: 0.8413 - val_loss: 0.6995 - val_accuracy: 0.8750\n",
      "Epoch 684/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3421 - accuracy: 0.8413 - val_loss: 0.7142 - val_accuracy: 0.8750\n",
      "Epoch 685/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3396 - accuracy: 0.8413 - val_loss: 0.7056 - val_accuracy: 0.8750\n",
      "Epoch 686/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3530 - accuracy: 0.8254 - val_loss: 0.6804 - val_accuracy: 0.8750\n",
      "Epoch 687/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.3410 - accuracy: 0.8254 - val_loss: 0.7050 - val_accuracy: 0.8750\n",
      "Epoch 688/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3484 - accuracy: 0.8254 - val_loss: 0.7353 - val_accuracy: 0.8750\n",
      "Epoch 689/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3420 - accuracy: 0.8413 - val_loss: 0.6972 - val_accuracy: 0.8750\n",
      "Epoch 690/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3436 - accuracy: 0.8413 - val_loss: 0.6738 - val_accuracy: 0.8750\n",
      "Epoch 691/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3413 - accuracy: 0.8413 - val_loss: 0.6905 - val_accuracy: 0.8750\n",
      "Epoch 692/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3385 - accuracy: 0.8254 - val_loss: 0.7340 - val_accuracy: 0.8750\n",
      "Epoch 693/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3417 - accuracy: 0.8413 - val_loss: 0.7565 - val_accuracy: 0.8750\n",
      "Epoch 694/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3437 - accuracy: 0.8571 - val_loss: 0.7212 - val_accuracy: 0.8750\n",
      "Epoch 695/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.3345 - accuracy: 0.8571 - val_loss: 0.6773 - val_accuracy: 0.8750\n",
      "Epoch 696/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3491 - accuracy: 0.8413 - val_loss: 0.6466 - val_accuracy: 0.8750\n",
      "Epoch 697/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3474 - accuracy: 0.8254 - val_loss: 0.6922 - val_accuracy: 0.8750\n",
      "Epoch 698/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3356 - accuracy: 0.8254 - val_loss: 0.7471 - val_accuracy: 0.8750\n",
      "Epoch 699/1000\n",
      "63/63 [==============================] - 0s 207us/step - loss: 0.3381 - accuracy: 0.8571 - val_loss: 0.7506 - val_accuracy: 0.8750\n",
      "Epoch 700/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3375 - accuracy: 0.8571 - val_loss: 0.7155 - val_accuracy: 0.8750\n",
      "Epoch 701/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3313 - accuracy: 0.8413 - val_loss: 0.6710 - val_accuracy: 0.8750\n",
      "Epoch 702/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2596 - accuracy: 0.90 - 0s 175us/step - loss: 0.3556 - accuracy: 0.8095 - val_loss: 0.6522 - val_accuracy: 0.8750\n",
      "Epoch 703/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.3361 - accuracy: 0.8254 - val_loss: 0.7053 - val_accuracy: 0.8750\n",
      "Epoch 704/1000\n",
      "63/63 [==============================] - 0s 226us/step - loss: 0.3355 - accuracy: 0.8730 - val_loss: 0.7726 - val_accuracy: 0.8750\n",
      "Epoch 705/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3386 - accuracy: 0.8730 - val_loss: 0.7492 - val_accuracy: 0.8750\n",
      "Epoch 706/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3322 - accuracy: 0.8571 - val_loss: 0.7012 - val_accuracy: 0.8750\n",
      "Epoch 707/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3292 - accuracy: 0.8413 - val_loss: 0.6679 - val_accuracy: 0.8750\n",
      "Epoch 708/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3427 - accuracy: 0.8095 - val_loss: 0.6631 - val_accuracy: 0.8750\n",
      "Epoch 709/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3321 - accuracy: 0.8413 - val_loss: 0.7144 - val_accuracy: 0.8750\n",
      "Epoch 710/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3299 - accuracy: 0.8095 - val_loss: 0.7501 - val_accuracy: 0.8750\n",
      "Epoch 711/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3345 - accuracy: 0.8571 - val_loss: 0.7501 - val_accuracy: 0.8750\n",
      "Epoch 712/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3332 - accuracy: 0.8571 - val_loss: 0.7115 - val_accuracy: 0.8750\n",
      "Epoch 713/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3279 - accuracy: 0.8413 - val_loss: 0.6843 - val_accuracy: 0.8750\n",
      "Epoch 714/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3317 - accuracy: 0.8413 - val_loss: 0.6865 - val_accuracy: 0.8750\n",
      "Epoch 715/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.3288 - accuracy: 0.8254 - val_loss: 0.6932 - val_accuracy: 0.8750\n",
      "Epoch 716/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3276 - accuracy: 0.8413 - val_loss: 0.7002 - val_accuracy: 0.8750\n",
      "Epoch 717/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3268 - accuracy: 0.8254 - val_loss: 0.6928 - val_accuracy: 0.8750\n",
      "Epoch 718/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3239 - accuracy: 0.8254 - val_loss: 0.7160 - val_accuracy: 0.8750\n",
      "Epoch 719/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3356 - accuracy: 0.8730 - val_loss: 0.7441 - val_accuracy: 0.8750\n",
      "Epoch 720/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3261 - accuracy: 0.8571 - val_loss: 0.7056 - val_accuracy: 0.8750\n",
      "Epoch 721/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3314 - accuracy: 0.8254 - val_loss: 0.6709 - val_accuracy: 0.8750\n",
      "Epoch 722/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3460 - accuracy: 0.8095 - val_loss: 0.6615 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 723/1000\n",
      "63/63 [==============================] - 0s 207us/step - loss: 0.3308 - accuracy: 0.8730 - val_loss: 0.7469 - val_accuracy: 0.8750\n",
      "Epoch 724/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3246 - accuracy: 0.8571 - val_loss: 0.7642 - val_accuracy: 0.8750\n",
      "Epoch 725/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3306 - accuracy: 0.8730 - val_loss: 0.7552 - val_accuracy: 0.8750\n",
      "Epoch 726/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3332 - accuracy: 0.8571 - val_loss: 0.6860 - val_accuracy: 0.8750\n",
      "Epoch 727/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3486 - accuracy: 0.8254 - val_loss: 0.6581 - val_accuracy: 0.8750\n",
      "Epoch 728/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3244 - accuracy: 0.8571 - val_loss: 0.7082 - val_accuracy: 0.8750\n",
      "Epoch 729/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3261 - accuracy: 0.8254 - val_loss: 0.7646 - val_accuracy: 0.8750\n",
      "Epoch 730/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3245 - accuracy: 0.8571 - val_loss: 0.7509 - val_accuracy: 0.8750\n",
      "Epoch 731/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3249 - accuracy: 0.8571 - val_loss: 0.7054 - val_accuracy: 0.8750\n",
      "Epoch 732/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3182 - accuracy: 0.8571 - val_loss: 0.6797 - val_accuracy: 0.8750\n",
      "Epoch 733/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3197 - accuracy: 0.8571 - val_loss: 0.6822 - val_accuracy: 0.8750\n",
      "Epoch 734/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3346 - accuracy: 0.8413 - val_loss: 0.7338 - val_accuracy: 0.8750\n",
      "Epoch 735/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3171 - accuracy: 0.8730 - val_loss: 0.7260 - val_accuracy: 0.8750\n",
      "Epoch 736/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3159 - accuracy: 0.8571 - val_loss: 0.7099 - val_accuracy: 0.8750\n",
      "Epoch 737/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3192 - accuracy: 0.8413 - val_loss: 0.6964 - val_accuracy: 0.8750\n",
      "Epoch 738/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3180 - accuracy: 0.8413 - val_loss: 0.7012 - val_accuracy: 0.8750\n",
      "Epoch 739/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3186 - accuracy: 0.8571 - val_loss: 0.7321 - val_accuracy: 0.8750\n",
      "Epoch 740/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3230 - accuracy: 0.8730 - val_loss: 0.7294 - val_accuracy: 0.8750\n",
      "Epoch 741/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3142 - accuracy: 0.8571 - val_loss: 0.6947 - val_accuracy: 0.8750\n",
      "Epoch 742/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3143 - accuracy: 0.8571 - val_loss: 0.6855 - val_accuracy: 0.8750\n",
      "Epoch 743/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3182 - accuracy: 0.8571 - val_loss: 0.6928 - val_accuracy: 0.8750\n",
      "Epoch 744/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3120 - accuracy: 0.8571 - val_loss: 0.7373 - val_accuracy: 0.8750\n",
      "Epoch 745/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3208 - accuracy: 0.8571 - val_loss: 0.7522 - val_accuracy: 0.8750\n",
      "Epoch 746/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3170 - accuracy: 0.8571 - val_loss: 0.7056 - val_accuracy: 0.8750\n",
      "Epoch 747/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3137 - accuracy: 0.8730 - val_loss: 0.6863 - val_accuracy: 0.8750\n",
      "Epoch 748/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3241 - accuracy: 0.8571 - val_loss: 0.7132 - val_accuracy: 0.8750\n",
      "Epoch 749/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3158 - accuracy: 0.8413 - val_loss: 0.7162 - val_accuracy: 0.8750\n",
      "Epoch 750/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.3127 - accuracy: 0.8571 - val_loss: 0.7565 - val_accuracy: 0.8750\n",
      "Epoch 751/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3283 - accuracy: 0.8571 - val_loss: 0.7357 - val_accuracy: 0.8750\n",
      "Epoch 752/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3119 - accuracy: 0.8889 - val_loss: 0.7161 - val_accuracy: 0.8750\n",
      "Epoch 753/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3075 - accuracy: 0.8730 - val_loss: 0.6915 - val_accuracy: 0.8750\n",
      "Epoch 754/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3175 - accuracy: 0.8413 - val_loss: 0.6752 - val_accuracy: 0.8750\n",
      "Epoch 755/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3187 - accuracy: 0.8571 - val_loss: 0.7070 - val_accuracy: 0.8750\n",
      "Epoch 756/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3121 - accuracy: 0.8571 - val_loss: 0.7289 - val_accuracy: 0.8750\n",
      "Epoch 757/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3081 - accuracy: 0.8571 - val_loss: 0.7322 - val_accuracy: 0.8750\n",
      "Epoch 758/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3084 - accuracy: 0.8730 - val_loss: 0.7343 - val_accuracy: 0.8750\n",
      "Epoch 759/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3148 - accuracy: 0.8571 - val_loss: 0.6982 - val_accuracy: 0.8750\n",
      "Epoch 760/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3082 - accuracy: 0.8571 - val_loss: 0.7072 - val_accuracy: 0.8750\n",
      "Epoch 761/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3053 - accuracy: 0.8413 - val_loss: 0.7222 - val_accuracy: 0.8750\n",
      "Epoch 762/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3112 - accuracy: 0.8571 - val_loss: 0.7370 - val_accuracy: 0.8750\n",
      "Epoch 763/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.3050 - accuracy: 0.9048 - val_loss: 0.7028 - val_accuracy: 0.8750\n",
      "Epoch 764/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3075 - accuracy: 0.8730 - val_loss: 0.7057 - val_accuracy: 0.8750\n",
      "Epoch 765/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3047 - accuracy: 0.8730 - val_loss: 0.6960 - val_accuracy: 0.8750\n",
      "Epoch 766/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3052 - accuracy: 0.8730 - val_loss: 0.7109 - val_accuracy: 0.8750\n",
      "Epoch 767/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3100 - accuracy: 0.8413 - val_loss: 0.7140 - val_accuracy: 0.8750\n",
      "Epoch 768/1000\n",
      "63/63 [==============================] - 0s 142us/step - loss: 0.3067 - accuracy: 0.8413 - val_loss: 0.6980 - val_accuracy: 0.8750\n",
      "Epoch 769/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3068 - accuracy: 0.8730 - val_loss: 0.7079 - val_accuracy: 0.8750\n",
      "Epoch 770/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3009 - accuracy: 0.8730 - val_loss: 0.7491 - val_accuracy: 0.8750\n",
      "Epoch 771/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3044 - accuracy: 0.8730 - val_loss: 0.7636 - val_accuracy: 0.8750\n",
      "Epoch 772/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3062 - accuracy: 0.8889 - val_loss: 0.7387 - val_accuracy: 0.8750\n",
      "Epoch 773/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.3003 - accuracy: 0.8889 - val_loss: 0.6866 - val_accuracy: 0.8750\n",
      "Epoch 774/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3182 - accuracy: 0.8413 - val_loss: 0.6646 - val_accuracy: 0.8750\n",
      "Epoch 775/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3054 - accuracy: 0.8413 - val_loss: 0.7187 - val_accuracy: 0.8750\n",
      "Epoch 776/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3121 - accuracy: 0.8730 - val_loss: 0.7885 - val_accuracy: 0.8125\n",
      "Epoch 777/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3185 - accuracy: 0.84 - 0s 159us/step - loss: 0.3091 - accuracy: 0.8889 - val_loss: 0.7383 - val_accuracy: 0.8750\n",
      "Epoch 778/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.3204 - accuracy: 0.8571 - val_loss: 0.6851 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.3018 - accuracy: 0.8571 - val_loss: 0.7033 - val_accuracy: 0.8750\n",
      "Epoch 780/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3047 - accuracy: 0.8889 - val_loss: 0.7562 - val_accuracy: 0.8750\n",
      "Epoch 781/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.2996 - accuracy: 0.9048 - val_loss: 0.7484 - val_accuracy: 0.8750\n",
      "Epoch 782/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2988 - accuracy: 0.9048 - val_loss: 0.7191 - val_accuracy: 0.8750\n",
      "Epoch 783/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2962 - accuracy: 0.8413 - val_loss: 0.6999 - val_accuracy: 0.8750\n",
      "Epoch 784/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2978 - accuracy: 0.8730 - val_loss: 0.7060 - val_accuracy: 0.8750\n",
      "Epoch 785/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3025 - accuracy: 0.8730 - val_loss: 0.7093 - val_accuracy: 0.8750\n",
      "Epoch 786/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2972 - accuracy: 0.8730 - val_loss: 0.7621 - val_accuracy: 0.8750\n",
      "Epoch 787/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3004 - accuracy: 0.8889 - val_loss: 0.7663 - val_accuracy: 0.8125\n",
      "Epoch 788/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3001 - accuracy: 0.8889 - val_loss: 0.7284 - val_accuracy: 0.8750\n",
      "Epoch 789/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.3112 - accuracy: 0.8571 - val_loss: 0.6716 - val_accuracy: 0.8750\n",
      "Epoch 790/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.3059 - accuracy: 0.8730 - val_loss: 0.7063 - val_accuracy: 0.8750\n",
      "Epoch 791/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2946 - accuracy: 0.8730 - val_loss: 0.7457 - val_accuracy: 0.8750\n",
      "Epoch 792/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.3002 - accuracy: 0.9048 - val_loss: 0.7482 - val_accuracy: 0.8750\n",
      "Epoch 793/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2948 - accuracy: 0.8889 - val_loss: 0.7312 - val_accuracy: 0.8750\n",
      "Epoch 794/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2921 - accuracy: 0.8730 - val_loss: 0.7047 - val_accuracy: 0.8750\n",
      "Epoch 795/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.2949 - accuracy: 0.8730 - val_loss: 0.7161 - val_accuracy: 0.8750\n",
      "Epoch 796/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2941 - accuracy: 0.8730 - val_loss: 0.7224 - val_accuracy: 0.8750\n",
      "Epoch 797/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2938 - accuracy: 0.8730 - val_loss: 0.7519 - val_accuracy: 0.8750\n",
      "Epoch 798/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.3016 - accuracy: 0.8571 - val_loss: 0.7164 - val_accuracy: 0.8750\n",
      "Epoch 799/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.3075 - accuracy: 0.8571 - val_loss: 0.6985 - val_accuracy: 0.8750\n",
      "Epoch 800/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2931 - accuracy: 0.8571 - val_loss: 0.7480 - val_accuracy: 0.8750\n",
      "Epoch 801/1000\n",
      "63/63 [==============================] - 0s 158us/step - loss: 0.2926 - accuracy: 0.8889 - val_loss: 0.7647 - val_accuracy: 0.8750\n",
      "Epoch 802/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2965 - accuracy: 0.8730 - val_loss: 0.7532 - val_accuracy: 0.8750\n",
      "Epoch 803/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.2891 - accuracy: 0.8889 - val_loss: 0.7040 - val_accuracy: 0.8750\n",
      "Epoch 804/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2930 - accuracy: 0.8571 - val_loss: 0.6840 - val_accuracy: 0.8750\n",
      "Epoch 805/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2968 - accuracy: 0.8571 - val_loss: 0.6996 - val_accuracy: 0.8750\n",
      "Epoch 806/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.3044 - accuracy: 0.8730 - val_loss: 0.7829 - val_accuracy: 0.8125\n",
      "Epoch 807/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.2950 - accuracy: 0.8889 - val_loss: 0.7769 - val_accuracy: 0.8125\n",
      "Epoch 808/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2893 - accuracy: 0.9048 - val_loss: 0.7263 - val_accuracy: 0.8750\n",
      "Epoch 809/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2855 - accuracy: 0.8730 - val_loss: 0.6995 - val_accuracy: 0.8750\n",
      "Epoch 810/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.2929 - accuracy: 0.8730 - val_loss: 0.6907 - val_accuracy: 0.8750\n",
      "Epoch 811/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2895 - accuracy: 0.8889 - val_loss: 0.7146 - val_accuracy: 0.8750\n",
      "Epoch 812/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2869 - accuracy: 0.8889 - val_loss: 0.7591 - val_accuracy: 0.8750\n",
      "Epoch 813/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.2889 - accuracy: 0.9048 - val_loss: 0.7682 - val_accuracy: 0.8125\n",
      "Epoch 814/1000\n",
      "63/63 [==============================] - 0s 413us/step - loss: 0.2890 - accuracy: 0.9048 - val_loss: 0.7363 - val_accuracy: 0.8750\n",
      "Epoch 815/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2837 - accuracy: 0.9048 - val_loss: 0.6975 - val_accuracy: 0.8750\n",
      "Epoch 816/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2934 - accuracy: 0.8889 - val_loss: 0.6955 - val_accuracy: 0.8750\n",
      "Epoch 817/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2888 - accuracy: 0.8571 - val_loss: 0.7483 - val_accuracy: 0.8750\n",
      "Epoch 818/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2843 - accuracy: 0.9048 - val_loss: 0.7706 - val_accuracy: 0.8125\n",
      "Epoch 819/1000\n",
      "63/63 [==============================] - 0s 95us/step - loss: 0.2879 - accuracy: 0.9048 - val_loss: 0.7442 - val_accuracy: 0.8750\n",
      "Epoch 820/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2822 - accuracy: 0.9048 - val_loss: 0.7275 - val_accuracy: 0.8750\n",
      "Epoch 821/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2831 - accuracy: 0.8730 - val_loss: 0.7165 - val_accuracy: 0.8750\n",
      "Epoch 822/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2855 - accuracy: 0.8730 - val_loss: 0.7330 - val_accuracy: 0.8750\n",
      "Epoch 823/1000\n",
      "63/63 [==============================] - 0s 317us/step - loss: 0.2915 - accuracy: 0.8730 - val_loss: 0.7192 - val_accuracy: 0.8750\n",
      "Epoch 824/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2833 - accuracy: 0.8889 - val_loss: 0.7570 - val_accuracy: 0.8750\n",
      "Epoch 825/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2850 - accuracy: 0.8889 - val_loss: 0.7621 - val_accuracy: 0.8125\n",
      "Epoch 826/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2846 - accuracy: 0.9048 - val_loss: 0.7259 - val_accuracy: 0.8750\n",
      "Epoch 827/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2844 - accuracy: 0.8889 - val_loss: 0.7085 - val_accuracy: 0.8750\n",
      "Epoch 828/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2871 - accuracy: 0.8730 - val_loss: 0.7332 - val_accuracy: 0.8750\n",
      "Epoch 829/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2830 - accuracy: 0.9048 - val_loss: 0.7690 - val_accuracy: 0.8125\n",
      "Epoch 830/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2836 - accuracy: 0.8889 - val_loss: 0.7570 - val_accuracy: 0.8125\n",
      "Epoch 831/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2891 - accuracy: 0.8730 - val_loss: 0.7033 - val_accuracy: 0.8750\n",
      "Epoch 832/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2831 - accuracy: 0.8889 - val_loss: 0.7237 - val_accuracy: 0.8750\n",
      "Epoch 833/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2787 - accuracy: 0.8730 - val_loss: 0.7490 - val_accuracy: 0.8750\n",
      "Epoch 834/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2786 - accuracy: 0.9048 - val_loss: 0.7605 - val_accuracy: 0.8750\n",
      "Epoch 835/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 191us/step - loss: 0.2786 - accuracy: 0.9048 - val_loss: 0.7501 - val_accuracy: 0.8750\n",
      "Epoch 836/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2796 - accuracy: 0.9048 - val_loss: 0.7280 - val_accuracy: 0.8750\n",
      "Epoch 837/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2819 - accuracy: 0.8730 - val_loss: 0.7071 - val_accuracy: 0.8750\n",
      "Epoch 838/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2793 - accuracy: 0.8571 - val_loss: 0.7410 - val_accuracy: 0.8750\n",
      "Epoch 839/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2778 - accuracy: 0.8889 - val_loss: 0.7499 - val_accuracy: 0.8750\n",
      "Epoch 840/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2805 - accuracy: 0.9048 - val_loss: 0.7576 - val_accuracy: 0.8750\n",
      "Epoch 841/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2791 - accuracy: 0.9048 - val_loss: 0.7569 - val_accuracy: 0.8750\n",
      "Epoch 842/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2762 - accuracy: 0.8889 - val_loss: 0.7251 - val_accuracy: 0.8750\n",
      "Epoch 843/1000\n",
      "63/63 [==============================] - 0s 158us/step - loss: 0.2786 - accuracy: 0.8730 - val_loss: 0.7247 - val_accuracy: 0.8750\n",
      "Epoch 844/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2874 - accuracy: 0.8730 - val_loss: 0.7133 - val_accuracy: 0.8750\n",
      "Epoch 845/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2851 - accuracy: 0.8571 - val_loss: 0.7787 - val_accuracy: 0.8125\n",
      "Epoch 846/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2798 - accuracy: 0.8889 - val_loss: 0.7785 - val_accuracy: 0.8125\n",
      "Epoch 847/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2783 - accuracy: 0.9206 - val_loss: 0.7437 - val_accuracy: 0.8750\n",
      "Epoch 848/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2832 - accuracy: 0.8889 - val_loss: 0.7156 - val_accuracy: 0.8750\n",
      "Epoch 849/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2744 - accuracy: 0.8730 - val_loss: 0.7355 - val_accuracy: 0.8750\n",
      "Epoch 850/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2894 - accuracy: 0.8889 - val_loss: 0.7934 - val_accuracy: 0.8125\n",
      "Epoch 851/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2796 - accuracy: 0.8889 - val_loss: 0.7585 - val_accuracy: 0.8750\n",
      "Epoch 852/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2832 - accuracy: 0.8730 - val_loss: 0.7204 - val_accuracy: 0.8750\n",
      "Epoch 853/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2796 - accuracy: 0.8889 - val_loss: 0.7541 - val_accuracy: 0.8750\n",
      "Epoch 854/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2751 - accuracy: 0.9048 - val_loss: 0.7605 - val_accuracy: 0.8125\n",
      "Epoch 855/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2771 - accuracy: 0.8889 - val_loss: 0.7728 - val_accuracy: 0.8125\n",
      "Epoch 856/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2739 - accuracy: 0.8889 - val_loss: 0.7491 - val_accuracy: 0.8750\n",
      "Epoch 857/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.2707 - accuracy: 0.9048 - val_loss: 0.7192 - val_accuracy: 0.8750\n",
      "Epoch 858/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.2818 - accuracy: 0.8889 - val_loss: 0.7126 - val_accuracy: 0.8750\n",
      "Epoch 859/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2705 - accuracy: 0.8889 - val_loss: 0.7645 - val_accuracy: 0.8125\n",
      "Epoch 860/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2798 - accuracy: 0.8889 - val_loss: 0.8063 - val_accuracy: 0.8125\n",
      "Epoch 861/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2746 - accuracy: 0.9048 - val_loss: 0.7775 - val_accuracy: 0.8125\n",
      "Epoch 862/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2705 - accuracy: 0.8889 - val_loss: 0.7432 - val_accuracy: 0.8750\n",
      "Epoch 863/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2860 - accuracy: 0.8730 - val_loss: 0.7103 - val_accuracy: 0.8750\n",
      "Epoch 864/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2809 - accuracy: 0.8571 - val_loss: 0.7679 - val_accuracy: 0.8125\n",
      "Epoch 865/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2811 - accuracy: 0.8889 - val_loss: 0.7984 - val_accuracy: 0.8125\n",
      "Epoch 866/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2731 - accuracy: 0.9048 - val_loss: 0.7635 - val_accuracy: 0.8125\n",
      "Epoch 867/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2719 - accuracy: 0.9048 - val_loss: 0.7147 - val_accuracy: 0.8750\n",
      "Epoch 868/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2761 - accuracy: 0.9048 - val_loss: 0.7190 - val_accuracy: 0.8750\n",
      "Epoch 869/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2730 - accuracy: 0.8730 - val_loss: 0.7583 - val_accuracy: 0.8125\n",
      "Epoch 870/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2774 - accuracy: 0.8889 - val_loss: 0.7852 - val_accuracy: 0.8125\n",
      "Epoch 871/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2720 - accuracy: 0.9048 - val_loss: 0.7966 - val_accuracy: 0.8125\n",
      "Epoch 872/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2723 - accuracy: 0.9048 - val_loss: 0.7723 - val_accuracy: 0.8125\n",
      "Epoch 873/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2877 - accuracy: 0.8571 - val_loss: 0.7023 - val_accuracy: 0.8750\n",
      "Epoch 874/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2729 - accuracy: 0.8889 - val_loss: 0.7243 - val_accuracy: 0.8750\n",
      "Epoch 875/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2793 - accuracy: 0.8571 - val_loss: 0.7873 - val_accuracy: 0.8125\n",
      "Epoch 876/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2746 - accuracy: 0.9206 - val_loss: 0.7639 - val_accuracy: 0.8750\n",
      "Epoch 877/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2734 - accuracy: 0.9048 - val_loss: 0.7571 - val_accuracy: 0.8125\n",
      "Epoch 878/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.2641 - accuracy: 0.9048 - val_loss: 0.7675 - val_accuracy: 0.8125\n",
      "Epoch 879/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2790 - accuracy: 0.9048 - val_loss: 0.7886 - val_accuracy: 0.8125\n",
      "Epoch 880/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2658 - accuracy: 0.9048 - val_loss: 0.7313 - val_accuracy: 0.8750\n",
      "Epoch 881/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.2649 - accuracy: 0.8730 - val_loss: 0.7265 - val_accuracy: 0.8750\n",
      "Epoch 882/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2666 - accuracy: 0.8571 - val_loss: 0.7407 - val_accuracy: 0.8750\n",
      "Epoch 883/1000\n",
      "63/63 [==============================] - 0s 222us/step - loss: 0.2625 - accuracy: 0.8889 - val_loss: 0.7649 - val_accuracy: 0.8125\n",
      "Epoch 884/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.2630 - accuracy: 0.9048 - val_loss: 0.7836 - val_accuracy: 0.8125\n",
      "Epoch 885/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2646 - accuracy: 0.9048 - val_loss: 0.7959 - val_accuracy: 0.8125\n",
      "Epoch 886/1000\n",
      "63/63 [==============================] - 0s 158us/step - loss: 0.2653 - accuracy: 0.9048 - val_loss: 0.7707 - val_accuracy: 0.8125\n",
      "Epoch 887/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2750 - accuracy: 0.8889 - val_loss: 0.7159 - val_accuracy: 0.8750\n",
      "Epoch 888/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2676 - accuracy: 0.8889 - val_loss: 0.7345 - val_accuracy: 0.8750\n",
      "Epoch 889/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2624 - accuracy: 0.8889 - val_loss: 0.7968 - val_accuracy: 0.8125\n",
      "Epoch 890/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2656 - accuracy: 0.9048 - val_loss: 0.8072 - val_accuracy: 0.8125\n",
      "Epoch 891/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 143us/step - loss: 0.2703 - accuracy: 0.9048 - val_loss: 0.7462 - val_accuracy: 0.8750\n",
      "Epoch 892/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.2636 - accuracy: 0.8889 - val_loss: 0.7555 - val_accuracy: 0.8750\n",
      "Epoch 893/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2608 - accuracy: 0.9048 - val_loss: 0.7560 - val_accuracy: 0.8750\n",
      "Epoch 894/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2613 - accuracy: 0.8889 - val_loss: 0.7520 - val_accuracy: 0.8750\n",
      "Epoch 895/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2621 - accuracy: 0.8889 - val_loss: 0.7830 - val_accuracy: 0.8125\n",
      "Epoch 896/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.2655 - accuracy: 0.9048 - val_loss: 0.7910 - val_accuracy: 0.8125\n",
      "Epoch 897/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2590 - accuracy: 0.9048 - val_loss: 0.7585 - val_accuracy: 0.8750\n",
      "Epoch 898/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2755 - accuracy: 0.8889 - val_loss: 0.7158 - val_accuracy: 0.8750\n",
      "Epoch 899/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2678 - accuracy: 0.8730 - val_loss: 0.7593 - val_accuracy: 0.8125\n",
      "Epoch 900/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2609 - accuracy: 0.8889 - val_loss: 0.8071 - val_accuracy: 0.8125\n",
      "Epoch 901/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2619 - accuracy: 0.9048 - val_loss: 0.8114 - val_accuracy: 0.8125\n",
      "Epoch 902/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2595 - accuracy: 0.9048 - val_loss: 0.7732 - val_accuracy: 0.8125\n",
      "Epoch 903/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2562 - accuracy: 0.9048 - val_loss: 0.7454 - val_accuracy: 0.8750\n",
      "Epoch 904/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2581 - accuracy: 0.8730 - val_loss: 0.7482 - val_accuracy: 0.8750\n",
      "Epoch 905/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.2572 - accuracy: 0.8889 - val_loss: 0.7667 - val_accuracy: 0.8125\n",
      "Epoch 906/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2565 - accuracy: 0.9048 - val_loss: 0.7888 - val_accuracy: 0.8125\n",
      "Epoch 907/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2605 - accuracy: 0.9048 - val_loss: 0.7825 - val_accuracy: 0.8125\n",
      "Epoch 908/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2598 - accuracy: 0.9048 - val_loss: 0.7758 - val_accuracy: 0.8125\n",
      "Epoch 909/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2556 - accuracy: 0.9048 - val_loss: 0.7746 - val_accuracy: 0.8125\n",
      "Epoch 910/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2546 - accuracy: 0.9048 - val_loss: 0.7830 - val_accuracy: 0.8125\n",
      "Epoch 911/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2604 - accuracy: 0.9048 - val_loss: 0.7911 - val_accuracy: 0.8125\n",
      "Epoch 912/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1658 - accuracy: 0.93 - 0s 143us/step - loss: 0.2612 - accuracy: 0.8889 - val_loss: 0.7492 - val_accuracy: 0.8750\n",
      "Epoch 913/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.93 - 0s 175us/step - loss: 0.2642 - accuracy: 0.8730 - val_loss: 0.7477 - val_accuracy: 0.8750\n",
      "Epoch 914/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2575 - accuracy: 0.9048 - val_loss: 0.8112 - val_accuracy: 0.8125\n",
      "Epoch 915/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2622 - accuracy: 0.9048 - val_loss: 0.8342 - val_accuracy: 0.8125\n",
      "Epoch 916/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2565 - accuracy: 0.9206 - val_loss: 0.7796 - val_accuracy: 0.8125\n",
      "Epoch 917/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.2623 - accuracy: 0.8571 - val_loss: 0.7268 - val_accuracy: 0.8750\n",
      "Epoch 918/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2608 - accuracy: 0.8571 - val_loss: 0.7609 - val_accuracy: 0.8125\n",
      "Epoch 919/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2528 - accuracy: 0.8889 - val_loss: 0.7880 - val_accuracy: 0.8125\n",
      "Epoch 920/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.3017 - accuracy: 0.84 - 0s 254us/step - loss: 0.2552 - accuracy: 0.9048 - val_loss: 0.8184 - val_accuracy: 0.8125\n",
      "Epoch 921/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2552 - accuracy: 0.9048 - val_loss: 0.7938 - val_accuracy: 0.8125\n",
      "Epoch 922/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2536 - accuracy: 0.9048 - val_loss: 0.7682 - val_accuracy: 0.8125\n",
      "Epoch 923/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2520 - accuracy: 0.8889 - val_loss: 0.7514 - val_accuracy: 0.8750\n",
      "Epoch 924/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2583 - accuracy: 0.8571 - val_loss: 0.7540 - val_accuracy: 0.8750\n",
      "Epoch 925/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2557 - accuracy: 0.8730 - val_loss: 0.8136 - val_accuracy: 0.8125\n",
      "Epoch 926/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.93 - 0s 175us/step - loss: 0.2572 - accuracy: 0.9048 - val_loss: 0.8225 - val_accuracy: 0.8125\n",
      "Epoch 927/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2535 - accuracy: 0.9206 - val_loss: 0.7852 - val_accuracy: 0.8125\n",
      "Epoch 928/1000\n",
      "63/63 [==============================] - 0s 111us/step - loss: 0.2589 - accuracy: 0.8889 - val_loss: 0.7608 - val_accuracy: 0.8750\n",
      "Epoch 929/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2509 - accuracy: 0.8889 - val_loss: 0.7908 - val_accuracy: 0.8125\n",
      "Epoch 930/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2539 - accuracy: 0.9048 - val_loss: 0.8170 - val_accuracy: 0.8125\n",
      "Epoch 931/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2540 - accuracy: 0.8889 - val_loss: 0.7866 - val_accuracy: 0.8125\n",
      "Epoch 932/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2488 - accuracy: 0.9048 - val_loss: 0.7701 - val_accuracy: 0.8125\n",
      "Epoch 933/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2553 - accuracy: 0.8889 - val_loss: 0.7716 - val_accuracy: 0.8125\n",
      "Epoch 934/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2504 - accuracy: 0.9048 - val_loss: 0.8140 - val_accuracy: 0.8125\n",
      "Epoch 935/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2512 - accuracy: 0.8889 - val_loss: 0.8291 - val_accuracy: 0.8125\n",
      "Epoch 936/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2516 - accuracy: 0.9048 - val_loss: 0.7841 - val_accuracy: 0.8125\n",
      "Epoch 937/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2554 - accuracy: 0.8730 - val_loss: 0.7711 - val_accuracy: 0.8125\n",
      "Epoch 938/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2556 - accuracy: 0.9048 - val_loss: 0.8058 - val_accuracy: 0.8125\n",
      "Epoch 939/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2493 - accuracy: 0.9048 - val_loss: 0.7995 - val_accuracy: 0.8125\n",
      "Epoch 940/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2553 - accuracy: 0.9048 - val_loss: 0.7792 - val_accuracy: 0.8125\n",
      "Epoch 941/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2513 - accuracy: 0.8889 - val_loss: 0.7731 - val_accuracy: 0.8125\n",
      "Epoch 942/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2546 - accuracy: 0.8730 - val_loss: 0.8015 - val_accuracy: 0.8125\n",
      "Epoch 943/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2519 - accuracy: 0.9048 - val_loss: 0.8495 - val_accuracy: 0.8125\n",
      "Epoch 944/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2537 - accuracy: 0.9206 - val_loss: 0.8432 - val_accuracy: 0.8125\n",
      "Epoch 945/1000\n",
      "63/63 [==============================] - 0s 127us/step - loss: 0.2506 - accuracy: 0.9206 - val_loss: 0.7671 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 946/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2599 - accuracy: 0.8889 - val_loss: 0.7626 - val_accuracy: 0.8750\n",
      "Epoch 947/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2584 - accuracy: 0.8730 - val_loss: 0.7647 - val_accuracy: 0.8125\n",
      "Epoch 948/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2663 - accuracy: 0.8889 - val_loss: 0.8559 - val_accuracy: 0.7500\n",
      "Epoch 949/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2562 - accuracy: 0.9048 - val_loss: 0.8135 - val_accuracy: 0.8125\n",
      "Epoch 950/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.2442 - accuracy: 0.9048 - val_loss: 0.7838 - val_accuracy: 0.8125\n",
      "Epoch 951/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2484 - accuracy: 0.9206 - val_loss: 0.7810 - val_accuracy: 0.8125\n",
      "Epoch 952/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2451 - accuracy: 0.9048 - val_loss: 0.7938 - val_accuracy: 0.8125\n",
      "Epoch 953/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2449 - accuracy: 0.8889 - val_loss: 0.8261 - val_accuracy: 0.8125\n",
      "Epoch 954/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2476 - accuracy: 0.8889 - val_loss: 0.8151 - val_accuracy: 0.8125\n",
      "Epoch 955/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2457 - accuracy: 0.9048 - val_loss: 0.7791 - val_accuracy: 0.8125\n",
      "Epoch 956/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2472 - accuracy: 0.9206 - val_loss: 0.7946 - val_accuracy: 0.8125\n",
      "Epoch 957/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2448 - accuracy: 0.9206 - val_loss: 0.8134 - val_accuracy: 0.8125\n",
      "Epoch 958/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2429 - accuracy: 0.8889 - val_loss: 0.8072 - val_accuracy: 0.8125\n",
      "Epoch 959/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2489 - accuracy: 0.8889 - val_loss: 0.7880 - val_accuracy: 0.8125\n",
      "Epoch 960/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2541 - accuracy: 0.8889 - val_loss: 0.8124 - val_accuracy: 0.8125\n",
      "Epoch 961/1000\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.93 - 0s 159us/step - loss: 0.2477 - accuracy: 0.9206 - val_loss: 0.8102 - val_accuracy: 0.8125\n",
      "Epoch 962/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.2500 - accuracy: 0.9206 - val_loss: 0.7888 - val_accuracy: 0.8125\n",
      "Epoch 963/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2455 - accuracy: 0.9206 - val_loss: 0.8187 - val_accuracy: 0.8125\n",
      "Epoch 964/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2518 - accuracy: 0.9048 - val_loss: 0.8242 - val_accuracy: 0.8125\n",
      "Epoch 965/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2553 - accuracy: 0.8889 - val_loss: 0.7831 - val_accuracy: 0.8125\n",
      "Epoch 966/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2502 - accuracy: 0.9206 - val_loss: 0.8116 - val_accuracy: 0.8125\n",
      "Epoch 967/1000\n",
      "63/63 [==============================] - 0s 206us/step - loss: 0.2420 - accuracy: 0.9206 - val_loss: 0.8193 - val_accuracy: 0.8125\n",
      "Epoch 968/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2403 - accuracy: 0.9048 - val_loss: 0.7983 - val_accuracy: 0.8125\n",
      "Epoch 969/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.2438 - accuracy: 0.8889 - val_loss: 0.8017 - val_accuracy: 0.8125\n",
      "Epoch 970/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2410 - accuracy: 0.8889 - val_loss: 0.7858 - val_accuracy: 0.8125\n",
      "Epoch 971/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.2432 - accuracy: 0.9048 - val_loss: 0.8027 - val_accuracy: 0.8125\n",
      "Epoch 972/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2450 - accuracy: 0.9206 - val_loss: 0.8009 - val_accuracy: 0.8125\n",
      "Epoch 973/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2466 - accuracy: 0.9048 - val_loss: 0.8164 - val_accuracy: 0.8125\n",
      "Epoch 974/1000\n",
      "63/63 [==============================] - 0s 238us/step - loss: 0.2406 - accuracy: 0.8889 - val_loss: 0.8163 - val_accuracy: 0.8125\n",
      "Epoch 975/1000\n",
      "63/63 [==============================] - 0s 174us/step - loss: 0.2413 - accuracy: 0.9048 - val_loss: 0.8190 - val_accuracy: 0.8125\n",
      "Epoch 976/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2402 - accuracy: 0.9048 - val_loss: 0.8071 - val_accuracy: 0.8125\n",
      "Epoch 977/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2468 - accuracy: 0.9206 - val_loss: 0.8105 - val_accuracy: 0.8125\n",
      "Epoch 978/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2388 - accuracy: 0.9048 - val_loss: 0.8165 - val_accuracy: 0.8125\n",
      "Epoch 979/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2471 - accuracy: 0.8889 - val_loss: 0.7981 - val_accuracy: 0.8125\n",
      "Epoch 980/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2445 - accuracy: 0.8889 - val_loss: 0.8007 - val_accuracy: 0.8125\n",
      "Epoch 981/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2428 - accuracy: 0.8889 - val_loss: 0.8398 - val_accuracy: 0.8125\n",
      "Epoch 982/1000\n",
      "63/63 [==============================] - 0s 190us/step - loss: 0.2406 - accuracy: 0.9206 - val_loss: 0.8415 - val_accuracy: 0.8125\n",
      "Epoch 983/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2442 - accuracy: 0.9206 - val_loss: 0.8195 - val_accuracy: 0.8125\n",
      "Epoch 984/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2388 - accuracy: 0.9048 - val_loss: 0.8137 - val_accuracy: 0.8125\n",
      "Epoch 985/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2440 - accuracy: 0.8889 - val_loss: 0.8367 - val_accuracy: 0.8125\n",
      "Epoch 986/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2433 - accuracy: 0.8889 - val_loss: 0.7966 - val_accuracy: 0.8125\n",
      "Epoch 987/1000\n",
      "63/63 [==============================] - 0s 191us/step - loss: 0.2404 - accuracy: 0.8730 - val_loss: 0.7968 - val_accuracy: 0.8125\n",
      "Epoch 988/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2376 - accuracy: 0.8889 - val_loss: 0.8464 - val_accuracy: 0.8125\n",
      "Epoch 989/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2409 - accuracy: 0.8889 - val_loss: 0.8381 - val_accuracy: 0.8125\n",
      "Epoch 990/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2415 - accuracy: 0.9206 - val_loss: 0.8533 - val_accuracy: 0.8125\n",
      "Epoch 991/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2440 - accuracy: 0.9206 - val_loss: 0.8401 - val_accuracy: 0.8125\n",
      "Epoch 992/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2338 - accuracy: 0.9206 - val_loss: 0.7887 - val_accuracy: 0.8125\n",
      "Epoch 993/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2481 - accuracy: 0.8571 - val_loss: 0.7698 - val_accuracy: 0.8125\n",
      "Epoch 994/1000\n",
      "63/63 [==============================] - 0s 254us/step - loss: 0.2450 - accuracy: 0.8730 - val_loss: 0.8545 - val_accuracy: 0.7500\n",
      "Epoch 995/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2602 - accuracy: 0.9048 - val_loss: 0.8996 - val_accuracy: 0.7500\n",
      "Epoch 996/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2529 - accuracy: 0.9048 - val_loss: 0.8045 - val_accuracy: 0.8125\n",
      "Epoch 997/1000\n",
      "63/63 [==============================] - 0s 143us/step - loss: 0.2517 - accuracy: 0.8889 - val_loss: 0.7618 - val_accuracy: 0.8750\n",
      "Epoch 998/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2423 - accuracy: 0.9048 - val_loss: 0.8268 - val_accuracy: 0.7500\n",
      "Epoch 999/1000\n",
      "63/63 [==============================] - 0s 159us/step - loss: 0.2417 - accuracy: 0.9048 - val_loss: 0.8684 - val_accuracy: 0.7500\n",
      "Epoch 1000/1000\n",
      "63/63 [==============================] - 0s 175us/step - loss: 0.2362 - accuracy: 0.9206 - val_loss: 0.8577 - val_accuracy: 0.7500\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_data,new_train_target,epochs=1000,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25d6feed048>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25d6ff414e0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU5b3H8c8zk32DbOxLAKOIiqCIKNK6oKJWvbWb2s3WXm9va9W2t71ab22v3Wy9tYu1Xu3mrW21trUVFaXWtQoioIKsEiBgWCQkIUC2ycw89485M5mZzCSTkIUz832/Xrwyc+Zk8hyG1zcPv/MsxlqLiIi4n2e4GyAiIgNDgS4ikiYU6CIiaUKBLiKSJhToIiJpImu4fnBFRYWtqqoarh8vIuJKq1ev3m+trUz02rAFelVVFatWrRquHy8i4krGmB3JXlPJRUQkTSjQRUTShAJdRCRNKNBFRNKEAl1EJE0o0EVE0oQCXUQkTQzbOHQRkf5av7uZ9s4gp04uTXrOsq37GV2Sx7TKopTec+Oegxzu8HNaVRntnQEeX7ObD546AWMMAMGg5YFltcybWs7OxhbGjMhnxbYGRuRns7OxleK8bOZNLaPNF6D+cAeTywtZub2RT55ZxR9W7KCsKJcLZozmp89u4YITxjBr4sgB+buIpkAXEde55KcvA1B7xyVJz7n6Fyt6PSfaRT/5Z+T87zy5kQdf3cH4kfmceUwFAFv2Heb2JzYwqayAnY2tKbe1OC+Lbz6+AYBXbj6Xn7+wlcnlBYMS6Cq5iIjEqW1oAcAXCEaO7T/cAdCnMAfYEXV+42EfAKUFOUfaxIQU6CIicdp8AQCyvV0R2dji69d77T7QFnlcf7gdgLLCwQl0lVxEZMAcaPXxo2fe5paLjycv2xs5/tvltew60MYtFx3P2+8eYvGbu/nyBcdG6tMrtjXw1q5mtu9v4c13DjB2RD6fnl/FU+v2sutAGxeeMJpnN+6jrDAnJgxf297Ij//xNjPGlpCd5SEvy8tzm/dRWdR1zs1/WUtji4+K4lwee2MXk8oLmT6mGF8gyI6GFkYV53G4wx85/19/u4pVO5oA+OgvVxzx38mupq5A//QDofWrBivQzXDtKTpnzhyrxblE0sttj63jt8t38L0rTuKquZMix6tufhKA7d+7mAU/eJ66pjZW3rqQyuLcmNejzZwwgrV1zYPe5pwsDz5/sPcT+2nsiDz2NLfHHHv72xeRk9W/AokxZrW1dk6i11RyEZEBEwiGOoidgcQBGQhawn3I5rbOHt+rt9cHyuxBuDkZLT7MjaHfYd4bBbqIDJgsT6iEEg52iA33zoAlLzsUO02tPdek44NwsEwbldqwRjdQDV1Ejsg9z9ewblcz937sVLyeUFgHgpZHX6/jR/94m3cau2rIH7pvGVvrQyNIGg77uPWvb/H7FTsTvu9glkGijXLKPkNlbEneoL23Al1EjsidSzdHHocHhQSClp89VxMT5gDrdh2MPG5q9SUN876qHlXEln2Hux33GAhaKC3I5n0zx7GnuZ1dB9rYuKerHUW5yWNwdEku7x7s6Hb88lnjqCzKpbQwh+a2Tk6fUsaOhlb2HmynsiiX6tFFPLtxH1vrD7Nsa0PM9z503bwjuNKeKdBFZEBYa/E4JRd/0HKw3d/j+YmGAVYU5bD/cN+GB14xezzf/+BMqm99qttrWd7QDc/q0cV8619OBKDV52fGbUsj5+TneLt9H8D7Zo7lZ1efErnRG238yHy+umh6j+06+7hRrKptZNnW5ZFj08cUM7m8MOVr6yvV0EUEgIPtnUSPerPWEgxa/IFg5Li1FmttpEYeXStvbuvE6wxDPNjeGZmIk8ymvYe6HevvhJvo8eLRchIcz8/29vg8LDyk8kiUxg1PzPIe+Xv2RD10EWH97mYu+enLfOn8Y7nhvGoALv3Zy5ESyTnHVfKbT81l+tefpsOpbd/38VP5twdXR95j1u3PRB7f9+K2Xn/m42t2dzt20oQRCUsnPenppma2E6DRv6jig3pCaQGFOV5anMlE8aoS9Kgnlxek1LbwLyhjwNrkv3gGigJdRNhzIDSi5O8b9kYCPbre/fzmeoBImAP85pXt/f557zm2kpfero859skzJnPDedU8+vouAH7wgZnMm1rOpr0HqT/cwa1/XRdz/mfOmsLpU8s5d/qomOP3f/xUrnN+0RTmZtHU2hnTboCnblxAUW4WOxtbmTuljOf/42y+//Rm/vJ6XaTunusMLbzmzCqqRxcxobQAj4HahlbeU12R0nWWFebwyL+dwd6D7dzw0Bs91usHgkouIhJZs6SlI3EvNZEjmZN41WkTOWn8iJhjnzizivKirhEnHz5tIpPKC7jghDF89PTJeJ36/NSKUI95/jEVnD9jdOR4WHgxLYDivGwAWuN638ePLWFiWQHznXNHleRx0vgSIBTm0FWK8XgMC6ormVJRyOTyQt57bGWfyjFzp5RFHpc47RksCnSRNOfzB6nZ171e7Q8EWbZ1PzX7DrHmnQMAHGr3s3pHEw0J6t9Pr9sb83x3c1u3c1KVn+PtVl8u72U6fDhgw9Pm2zoT//KJrokX5YYetyUpp0TzB2N/QxUkuVnaH4faQ5OkivPUQxeRI/DdJRtZeNdL7IkL4Bc213P1L1aw8K6XuO+lUM17/+EOPnDvMj77u9Xd3if+WPyQxL6YVlnEhNL8mGPRvdepld3r1h+aMwGAy2aNA7rXthedMAYgpsf+vpmhcy86cUyvbQovQxA+d9608l6/J1XHji4G4OzjKgfsPRPRWi4iae7Su1/mrV3N/PVzZzJ7UteGEA8ur+Xrj63v13vmZHn4y2fP5NKfvZzS+V+58DjuXLqZy2eN47b3zaC8KJf2zgDb6lsYNzKPDn+Q0c6Em0PtnWR7PTGLe0FoRM3Btk5KC3PYf7iDiqLYCUGdgSCtHQFGFGTT0uGnqdXH+JH5HGjtpCQ/u1tpJp61lm37W5hSXkhjq6/b+x+pRG3uj57WctFNUZE0Fy5BxJcdGlv6v1bK6JJcTpowovcTHRXO6ofZXk+kTp6X7WXGuJJu5xYnqTN7PSZSpkkUjNleDyMKQkWHwtwsCp0bkPGlnWSMMZHdjQY6zAfrPeMp0EVcbEdDC89seJePnzGZ3Cwvbb4Av3t1B6dPLWNlbRNTKwsjE2ceXvkOa3c14w8EGTcynx/94+1+/1xD995uT0P/OgOhSsBgD9vLdAp0ERf75uL1PL+5nhPHj2De1HL+uaWe7yzZGHPOFaeMB2Dxmt0sTjD2uz8+Ni+0NO4N5x7DA8tqOdju59ZLZnD3c1u48IQxLF6zm4tOHMPrOw9QUZTDAmeY3wdPnTAgP18SU6CLuFids3lCeMRHQz931UlV/P6cX7rgOL50wXGR51efHgr6b152Qq/fKwNP//8RcbGAM6ih05k4k2h9lAOtQ7OuuAw/BbpkpEdWvcPzm/bxs+e2sGH3wd6/YQjc+8LWyHjwX7+8nde2N0Zeu+/FrbzpvAYQDFrueGoT2/d3bWbc3hmIWfkw7LlN+wa55XK0UMlFMtJX/7w28vinz9Xw9rcvGsbWhIbkff/pTUCoNHH7ExsijwG+99SmmOdv7zvE/764NfL9Pn+QR1a9k9LPWlBdQasvwMj8bGZPGslzm/bx+s4DMedMH1PcbfGsT82v6vuFyZBSoEvGG6qNFHpyoIfdexJt5xY/Rd/nD3Kol+VqAZ684SxOGBc73PD6c6u77en5q2tOY9yIPKbcsgRQ/dstVHKRjDcAq6QesfB2bIUJppu3J5jiHp5KHuYLBFOa3p7qbvPZXjMgy8fK0Eqph26MWQT8BPACv7TW3hH3+iTg/4CRzjk3W2uXDHBbRY7Y3c9u6VZK6Gts3fDQG6yqbSTL6+GJG86KmbJeu7+Fa37zGvOPqeCVmv3cfdUpkQk4OxpaeO+dLzBzwgg6OoN8aM4EPrNgKhDajg2gxReI6S0v+vFLMe2df8dz+INBRuTHTr65LcUZn6muN55onLkc/XoNdGOMF7gHOB+oA1YaYxZbazdEnfZfwCPW2nuNMTOAJUDVILRX5Ij88Jnuk2k8feyJRo/lXl3bxDlRy7eu291MbUMrtQ2hrdVW72iMBPrDK0M17rV1zQB8+8mNkUBPtmFy/C+fXQdCwxQTbYsW7T8XTeetXQdY8lZoQa0vn38sFcW53abTh/3s6tlMLivkybf2YEzXuia/uea0pDv6yNEnlR76XKDGWrsNwBjzMHA5EB3oFgjP4R0BDMzsBZEhcCSVhcMdsXXr+GGD0duwJdsZBwZ+/Pi/nz2NXQfaIoE+uaKQy04el/T88CJW8dP5z4lba1yObqkE+ngg+vZ5HXB63DnfBP5ujPkCUAgsTPRGxpjrgOsAJk2a1Ne2ivRZePG5nurB8eWFlg4/+dlePB5Dq89PjteTdGGncKCHf05D3H6YjS0+gkFLW2cgsmFCtEPtnXiMiUwQGkhl/dzOTdwrlUBP9C85fonGq4AHrLU/NMacATxojDnRWhtze95aez9wP4RWW+xPg0X6IjxKY+lN7+G4McUJz4nO+qYWH7O/FdpK7bzpo3i2lzHcLR1+nl63h8/+7vWErz+wrJYHltUm/f6Tvvn3Ht+/P8I3VqNLJZVDsDCUDL9UAr0OmBj1fALdSyrXAosArLXLjTF5QAWgGQ0ybIJRGxYs37o/pUAP16iBXsMcQqNL/rx6V/8b6bhq7iQeem1nyufftLCauVPK8PmD5GV7CVrL1voWRhXnMnviyMh5j37uTHY2tHLGAK7tLUevVAJ9JVBtjJkC7AKuBK6OO2cncB7wgDHmeCAPqEdkGDW3dQ3ti691R4suufS1lt3eGaSts/fx3725dOZYntmwl/2HE//88SPzY37ZfGr+lG4jXc6c1n2fy1MmlXJK1Brokt56DXRrrd8Ycz2wlNCQxF9ba9cbY24HVllrFwNfBn5hjPkioXLMNXa4ds6QtNLhD7D7QDtTKrrvYAOh2vWqHU1Mqyzi7XcPcdzoYuqa2mhs9cWM6X6ttol/bkncx2jrDPDqtgbGlORR19Tap/Yt37qflbVNffqeREoLc3qcGFRelBMT6D3dYJXMldI4dGdM+ZK4Y7dFPd4AzB/YponAf/55LX97czfr/vvChDumr61r5kP/uzzh9+ZE3YR86e36brvMR7vy/lf71b6+hnlFUS77E+zXOaYkj3OOG8XT6/cmXFf8/bPHR4Y7Quy1iYRp6r8c1V50QrjNF0gY6PH7ZEYbjin9j19/VsJt2V74j7M53OFndEkeHf4AgaClMxAkNyvU0y4tzOHHV87i3YPtjMjPpv5QB0V5WeQ4G0KUFeZwycyxtPuC5GYrzCUxBbq4QqLp73Bk26gNhmTbslUlKRlFy8v2MtnZ+HhkgiGHo4rzjqxxkvb0q16GxWNv7uJAq4+/rK5j/+EOlq7fG3nt9Z1NbN57iCfW7qbJWcv7dyt24HcWqdq+v4Vfv7ydh1/bybMb3x2W9oscjdRDlyG3blczNz78Zrfja75xASPys7ni58u6vXbfi9uoLMrlMwum8vW/rePlmv1D0VTKC3OYXF4Qs7ys12MIRA2JfP/s8by2vZFZk0LDBa+YPZ63djVz2cnj+OEzb/P5c6YNSVtFFOgy5JKN5jjQ6us2FC9a/aHQzcSdjX0bidJXXo+h5jsXYW3sGPXw8/jjxhiiB3Xd9ZFZkcdfOK96UNsqEk0lFxlyycaE9zYG3B8cmpGwRblZGGPweEJLyIb/hJ/HHwdiHosMF/XQBX8gyPee2sS/vXdqzI23+17cyvxjKjhx/AiWb23gpj++wf99ei7Tx5Rw1zNvU16Yg8fAo2/sYmpFEVefPolfvLSN82eM5od/38xXF02nqdXHjLElPL52N7lZXkaX5FLbkLiHfcNDb/DFhccmbeevXt7Onua2Qe+hi7iVGa75P3PmzLGrVq0alp8tsV6p2c9Hf7mC86aP4lfXnBY5Hl6Xu/aOSyKPK4tzWXnrwm473EBqa58MhamVhRTnZrGmrplsr+GaM6soK8ylwx9g/e6DPLMhdCP14/MmYwzUNbXF7Lv518+dyWzNrpSjlDFmtbV2TqLX1EOXyCqAjVFrcgeSlDeSHYeep9cPpT98Zh7ff3oTa+qa+cQZVdx6yYyY18O/jL71LycOR/NEBo1q6ILHWRr2cNTNymSTcjr9wZhFr6IdLYGen+2NrDSY6pZrIulAPfSj0NPr9nD3czU8fv1ZeDyGr/xpDeNL87mph/pyT+5+dgub3z1Ezb7DTCjN59qzpvKtJzbwsXmT+emzW7jopDEAHGzv5Iqfv0JVeSFvvNM1TO89P3g+8vhQh58FUc+jDUWgF+dmcaiXn5OX46HAWeukpIdRMyLpRoF+FLrx4Tfp8Adp6wxQmJvFn1bXAfQ70KO3Xdu09xDb9rewrb6FP67cyd6D7Szf2gCEtjV792BHzJhr6D5MMHqRqGgtPQTthSeMZlJZAb/453YgVL9+8NUdAHz09EmMLsnjsTd3MaG0AI+BWRNLqak/THFeFn9YEVpW9tHPncmeA+28tr2BM6aV89S6vTz2ZtdKzidPGMFFJ40lN8vLJ86oImAtF54wultbfnft6QS0dpykIQX6USi8O067E+gDzR8IhVl4qdaDbQMzfb6nHvr3PzCTkQU5kUD/97OnRQL9O+8/CYAbkozZDgf6zPEjOGVSKZfMHAvAohPHxgT6+2eP55r5UwCYVF7ANy49IeH7nVXdfZlZkXSgGvowstZG/kTzOuOZ2xKsX2Kt5XCHP/J9rT4/waCN9I7j3zPRKKbw++52FrY6MECB3t6ZfDGskrzY0sfokr6vS5Ll7fmfa2+vi6Q79dCHyWnf+QejinNZv/sgnzhjMl6P4Tev1FJ7xyV4vV099Gi3/vUtfr+ia1ebS04ay5Nv7Yk8/+dXz+Fnz9Xwx1VdW8CenGCxqPCMy3DWt/oSL3w1kDxxe3KG/xdSnDdw/wQ9mtgjGU6BPkzqD3VEgvW3y3dEjrf5ApEeenzQRoc5EBPmALUNLTFhDrAmag3tofLd95/E6VPLWPPOAWZPKo2prb9y87k0OwtuPX79WYwq6X2vy799fj6tvsTlnKdvWsC3ntjAKzUNqIMumU6BfpRpbPVFerNtfew5N/Zx+7TBcvXpkwCYVlnU7bXxI/MZPzIfSL7UbLxZUXtkxps+poQxJaH3Mwn3MxfJHAr0QdLY4iMQtOTneGlu6yQ3y4MBsjwetu4/nPT7onvuL7xdT1+WL9mw++ARttqdwvcJVHGRTKdAHySnfOsZAKpHFbFlX1eAXzBjNH/fkHwN7689+lbk8b0vbOXeF7am/DPve2lbP1o6sEYWDP2473nTynn0jV1MH1My5D9b5GiiQB9k0WEOsKbuQJIzQzbsGZpe9hfOPYa7n6uhOC+r23K2T3zhLKyF7yzZwKvbGpO+x80XTeeSk8aSm+Uhy+vBY4Znr8sPnTqBs4+tZFQ/Rs6IpBMF+hArys3iXbpvEjzUwsMGx4/MZ9PeQzGvnTg+VNueW1XWY6BXlRcysaxg8BqZImOMwlyEDAn0mn2HaW7zMXtiKX97cxeXnTyOdbsPkpvlYUJpPg+9tpNTJ5dx6uSuFfb8gSB/eG0nLR0B5k4pDc3c9AUoLczh5AkjeezNXVw+azxr6g5ENi8+1O6nzRfocYLN1vqWQb/evuhprZPe1kHJ8qhoLXI0yYhAX3jXiwD8+COz+NIja9jT3M6dSzcD8JMrZ/HdJZuYXF7Ai185J/I9v1+xk28sXg/A5PICdkSt4f3NS2fwzcc30N4Z5Gt/fQu3+NCpE1hb10x5UQ4LnNmS171nKsucqf/x4jcqzvYaOgNdd2nD4+VF5OiQEYEeFu451zW1dju2t7k95tx3D3Y9bzgcOxywrqnN+d7B2XF+xdfOY3RJHtZaptyypE/f+z8fOpkrZo/nO0s28quXt0eOr/6vhTE9bmMMtXdcknAmaVh4xUKAbd+9mPffu4w1UYt2qYcucnTJqEDPd1bgi56wEx7r3ZFkuVjovkZJqzODM/x+Ay0cvP3Z0iw/24vHY4jP2txsb8L36+lnRF+fx2O6L1GgQBc5qmRUoHucARjRCzpFDyH8wkNv8PKWeppae+55hxeL+vpj6we+kUD2EUx5zM9J/L05/XjP6B46dC0VEJbl0dRMkaNJRgV6S0f3mZevbe8axfH4mt3dXp87pSzmnKH2X5ccz/KtDVx68ji+/eRG9h/uPkJmakUh2/aHbrbmOb3q+J53dg/17q9dPJ1sr4cdDa2cdUzXSoTx/wP5/gdmctczm7l81ngeXL6DaZWF/b4uERl4GRXoTX2cGl97xyUACffP7I97rj6Fz//h9T59z2cWTOUzC6YCMHvSSN575wvdznnwM6cz/47nACjISfyR9lRaue490xIej++hzxhXwi8/Gdpz9NKTx/XadhEZWhn1f+aGuEAf6qniycohqYqvWYfbnx11fCDr+oN1j0BEBkfaB/ojK7tWH3xgWW3Ma+FFonpTMkBLvOZnH9n7BOPu2x43uhgAS9cytOEQ7k/NPF5BjgJdxE3SvuTy1b+sTfra6JI86praYmrQN55Xze9X7ODHH5kdOe/Rz82PjGUfPzKf48cWc+zoYn6/YidVFYVYa5kxtoQzppWzo6GVu5wt3x68di61Da10dAaoKMrl5Ikj+PT8Kfz6ldBwwitPm4gxhodeC91kvevDJ3PcmOKk7Z1Yls/XLp7OcWNK2HewnbOqK3hy7R5Gl+Tx84+ewrKtDUwoDf2S+shpEznc4WdBdUW3qf2pGpGfzU0LqzlhXGqrIorI8DI9jUMeTHPmzLGrVq0a9J8TX/9eUF3BP7fsB7pueIYnCkFX3TzZ+7z+9fN7nUEZPnfD7RcmrGnP+fY/2H+4g6duXEBetpdz/ucFsjyGmu9e3LeLE5GMY4xZba2dk+i1tC+5xKse1dUDDu8IVFmc+jogI/uwi3yyGnS4lp6T5SEv29PjuSIiqUrrQN+dYHf6aaNCQ+1yvJ5IDb2yuPddc8J19Pit1BIJn5JsZMmsiaWRNoSD/JSodWRERPojrWvotU5d/KITx/DUur0AjCnJ44FPnUZFUS4VRbmcP2M0p04u5akbF0QW2Urk7198L/sOtSd9PdrL/3luj7sH/eADM/nInImRlQof+td5Ke/eIyKSTFoHemNrKFRvWngsq3c0se9QB2WFOcye1NUbvuKUCQAcP7bnzRHGjMhjzIjUSjPjRuYzrocRNPk5Xs6q7prAc8a08pTeV0SkJ2ldcgn3kqNvYpYW9HxDU0TErdI60A84a7KMLMjmfTNDMxvLihToIpKe0rrk0uEP4PUYsr0evnbxdD579lRK8oZ+z0sRkaGQUg/dGLPIGLPZGFNjjLk5yTkfNsZsMMasN8b8YWCb2T8+fzAyYzLL62FUH4Ynioi4Ta89dGOMF7gHOB+oA1YaYxZbazdEnVMN3ALMt9Y2GWNGDVaD+8LnDw7LpsUiIsMhlbSbC9RYa7dZa33Aw8Dlcef8K3CPtbYJwFq7b2Cb2T++QPCI1hYXEXGTVNJuPPBO1PM651i0Y4FjjTGvGGNeNcYsSvRGxpjrjDGrjDGr6uvr+9fiPujwB8lVD11EMkQqaZdoumP8AjBZQDVwNnAV8EtjzMhu32Tt/dbaOdbaOZWVlX1ta591BqxKLiKSMVJJuzpgYtTzCUD81j51wGPW2k5r7XZgM6GAH1T3PF9Dzb5D3Y7/dnktb+xswucPDMgysiIibpBK2q0Eqo0xU4wxOcCVwOK4c/4GnANgjKkgVILZNpANjdfeGeDOpZv5wL3Lu71222Pref/Pl+mmqIhklF7TzlrrB64HlgIbgUesteuNMbcbYy5zTlsKNBhjNgDPA1+x1jYMVqOjHWpPvqGzL6BAF5HMkdLEImvtEmBJ3LHboh5b4EvOnyERXsY9aOOPdx2IHocuIpLuXJt2wSQbc/ijEn5lbRNZPex2LyKSTtIu0H3+2I03U1nrXEQkHbg40BMfjw/0M6dVJD5RRCTNuDbQo2vlbb5A5LEvEBvo2Sq5iEiGcHGgdz0+/raneWNnEwC3PbYu5jxN/ReRTOHatIuvodfsOwzA0vXvxhzPSmEPUBGRdODiQI993tSaeA9P9dBFJFO4Nu1sXA+9ocWXcBNnDVsUkUzh2kDv1kNv8fHZB1d3Oy/L49pLFBHpE9emXbiG/uE5E5hUVkBji4+djW2R10sLQlvNaZSLiGQK1+4pGg70OZPL2NPcTmOLD3+wa8hiZyD0epZq6CKSIVwb6OESujFQWpDDP7fsj3k9PMFIPXQRyRSu7b6GA91jDCOd8kq08AQjjXIRkUzh2rQLl1w8HrjytEmR4z+9ajbHji6KPNc4dBHJFO4PdGMoL8qJHC8vzMFjukJcPXQRyRSuTbtgpIYeW3IpLciJOU/j0EUkU7j4pmi4hw65WV4uPXkc+w62M6WiMKaH7lXJRUQyhGsDPRh1UxTg7qtmR16LnkvkNQp0EckMLi65hBI9UVybqKMeBbqIZAjXBrqNqqHHi66yeFRyEZEM4dpAD0bV0LtRDV1EMpBrA93G1dCjxfTQlecikiFcG+jRE4viRWe4augikilcH+iJa+i6KSoimcfFgR76mrjkohq6iGQe1wa67WHYIqqhi0gGcm+gO197uilqTOKSjIhIOnJtoAeDyYcthicWqX4uIpnEvYHe08Qi56o07V9EMolrA932MLEo0kN37dWJiPSdayMvMsolQaKHO+YquYhIJnFxoCfvoYeDXCUXEckkrg/0RDV0Y2K/iohkAtcGemS1xQSvRXroGoQuIhnEvYFO156i8cJHVEMXkUzi2kAPBkNfEwa6CY9yUaCLSOZwb6BHaujdXwvnuG6KikgmcXGgh74m7qGHXxvCBomIDDPXBrrtsYeukouIZJ6UAt0Ys8gYs9kYU2OMubmH8z5ojLHGmDkD18TEwj30RCNZNLFIRDJRr4FujPEC9wAXATOAq4wxMxKcVwzcAKwY6EYmEuhp6r+GLYpIBkqlhz4XqLHWbrPW+oCHgcsTnPct4AdA+/7GCZgAAAprSURBVAC2L6mu1RaTD1tUB11EMkkqgT4eeCfqeZ1zLMIYMxuYaK19oqc3MsZcZ4xZZYxZVV9f3+fGRuua+p98xyKNchGRTJJKoCdKRRt50RgP8CPgy729kbX2fmvtHGvtnMrKytRbmUDA6aEnKqtEhi2q5CIiGSSVQK8DJkY9nwDsjnpeDJwIvGCMqQXmAYsH+8ao7XG1RRPzVUQkE6QS6CuBamPMFGNMDnAlsDj8orW22VpbYa2tstZWAa8Cl1lrVw1Kix093xQNffW6dlCmiEjf9Rp51lo/cD2wFNgIPGKtXW+Mud0Yc9lgNzCZcA09UZ08Mg5dPXQRySBZqZxkrV0CLIk7dluSc88+8mb1LjzKJVFZJcvptueoiy4iGcS1idfTxKIsrxPoWa69PBGRPnNt4gWCyWvoWc5mogp0Eckkrk28yDj0BIkeDvJslVxEJIO4NvF6uikaqaGrhy4iGcS1iRfoYYOLLKdnnqseuohkENcmXlfJpftr2R4tnysimce9gd7D4lzhHrriXEQyiXsDPTxsMUGgZ3s1sUhEMo9rAz3Qw45FWZGSy1C2SERkeLk28oJBi8ckninqjdwMVQ9dRDKHewPd2qQllXZfAID8bO9QNklEZFi5NtAD1iYdxXKovROA4ryUlqoREUkLrg10a5PvSHSw3Q9ASX72UDZJRGRYuTbQA04NPZHywhwAJpUVDGGLRESGl2trEsEeSi6fPXsa1aOLWXj8qCFulYjI8HFvoAeT3xTN9npYdOKYIW6RiMjwcm/JxVptAi0iEsW1gR60iddCFxHJVO4N9B5KLiIimci9ga6Si4hIDNcGeiCoxbdERKK5NtB9gWBkVUUREXFxoDe1+Ch1JhCJiIiLA72hxReZESoiIi4O9KYWH6UFCnQRkTDXBvrB9k4tviUiEsWVgW6tpa0zQEGO1jsXEQlzZaB3+INYC/kKdBGRCFcGept2JBIR6cadgd6pQBcRiefuQFfJRUQkwp2BrpKLiEg3rgz0x97cBUBRrmv35xARGXCuDPTmtk4A5lSVDXNLRESOHq4M9MaWTo4fW0JOliubLyIyKFyZiI0tHZQVapaoiEg0Vwb6gbZORuZrHRcRkWiuDHSfP0iuyi0iIjFcmYr+gCVLm1uIiMRIKdCNMYuMMZuNMTXGmJsTvP4lY8wGY8xaY8yzxpjJA9/ULv5gkCyvK38XiYgMml5T0RjjBe4BLgJmAFcZY2bEnfYGMMdaOxP4M/CDgW5oNJ8/SLY2iBYRiZFKN3cuUGOt3Wat9QEPA5dHn2Ctfd5a2+o8fRWYMLDNjOUPWrLVQxcRiZFKKo4H3ol6XuccS+Za4KlELxhjrjPGrDLGrKqvr0+9lXFCNXQFuohItFRSMVFtwyY80ZiPAXOAOxO9bq2931o7x1o7p7KyMvVWxukMBsnWTVERkRipLIZSB0yMej4B2B1/kjFmIXAr8F5rbcfANK+7QNBiLWR51EMXEYmWSiquBKqNMVOMMTnAlcDi6BOMMbOB+4DLrLX7Br6ZXToDQQANWxQRidNroFtr/cD1wFJgI/CItXa9MeZ2Y8xlzml3AkXAn4wxbxpjFid5uyPmD4aqPSq5iIjESmn9WWvtEmBJ3LHboh4vHOB2JdXpd3roKrmIiMRwXSp2BkOBnq2p/yIiMVyXiv6AU3LRxCIRkRiuDXSNQxcRieW6VIyUXHRTVEQkhusCPdJD101REZEYrktFjUMXEUnMdYGucegiIom5LtAjPXSVXEREYrguFcOBruVzRURiuS4VI+PQVXIREYnhvkAPhm+Kuq7pIiKDynWp2BkZtqgeuohINNcFelfJxXVNFxEZVK5Lxa6Si3roIiLRXBfonZHFuVzXdBGRQeW6VIwMW8xSD11EJJrrAt2viUUiIgm5LhU7NQ5dRCQh1wW6xqGLiCTmulSsKi/k4pPGkKNAFxGJkdIm0UeTC04YwwUnjBnuZoiIHHXUzRURSRMKdBGRNKFAFxFJEwp0EZE0oUAXEUkTCnQRkTShQBcRSRMKdBGRNGGstcPzg42pB3b089srgP0D2Bw30DVnBl1zZjiSa55sra1M9MKwBfqRMMasstbOGe52DCVdc2bQNWeGwbpmlVxERNKEAl1EJE24NdDvH+4GDANdc2bQNWeGQblmV9bQRUSkO7f20EVEJI4CXUQkTbgu0I0xi4wxm40xNcaYm4e7PQPFGDPRGPO8MWajMWa9MeZG53iZMeYZY8wW52upc9wYY37q/D2sNcacMrxX0D/GGK8x5g1jzBPO8ynGmBXO9f7RGJPjHM91ntc4r1cNZ7v7yxgz0hjzZ2PMJuezPiMDPuMvOv+m1xljHjLG5KXj52yM+bUxZp8xZl3UsT5/tsaYTzrnbzHGfLIvbXBVoBtjvMA9wEXADOAqY8yM4W3VgPEDX7bWHg/MAz7vXNvNwLPW2mrgWec5hP4Oqp0/1wH3Dn2TB8SNwMao598HfuRcbxNwrXP8WqDJWnsM8CPnPDf6CfC0tXY6cDKha0/bz9gYMx64AZhjrT0R8AJXkp6f8wPAorhjffpsjTFlwDeA04G5wDfCvwRSYq11zR/gDGBp1PNbgFuGu12DdK2PAecDm4GxzrGxwGbn8X3AVVHnR85zyx9ggvOP/FzgCcAQmj2XFf95A0uBM5zHWc55ZrivoY/XWwJsj293mn/G44F3gDLnc3sCuDBdP2egCljX388WuAq4L+p4zHm9/XFVD52ufxxhdc6xtOL8N3M2sAIYba3dA+B8HeWclg5/Fz8GvgoEneflwAFrrd95Hn1Nket1Xm92zneTqUA98BunzPRLY0whafwZW2t3Af8D7AT2EPrcVpPen3O0vn62R/SZuy3QTYJjaTXu0hhTBPwFuMlae7CnUxMcc83fhTHmfcA+a+3q6MMJTrUpvOYWWcApwL3W2tlAC13/BU/E9dfslAsuB6YA44BCQuWGeOn0Oaci2XUe0fW7LdDrgIlRzycAu4epLQPOGJNNKMx/b6191Dn8rjFmrPP6WGCfc9ztfxfzgcuMMbXAw4TKLj8GRhpjspxzoq8pcr3O6yOAxqFs8ACoA+qstSuc538mFPDp+hkDLAS2W2vrrbWdwKPAmaT35xytr5/tEX3mbgv0lUC1c4c8h9DNlcXD3KYBYYwxwK+Ajdbau6JeWgyE73R/klBtPXz8E87d8nlAc/i/dm5grb3FWjvBWltF6HN8zlr7UeB54IPOafHXG/57+KBzvqt6btbavcA7xpjjnEPnARtI08/YsROYZ4wpcP6Nh685bT/nOH39bJcCFxhjSp3/3VzgHEvNcN9E6MdNh4uBt4GtwK3D3Z4BvK6zCP3Xai3wpvPnYkL1w2eBLc7XMud8Q2jEz1bgLUKjCIb9Ovp57WcDTziPpwKvATXAn4Bc53ie87zGeX3qcLe7n9c6C1jlfM5/A0rT/TMG/hvYBKwDHgRy0/FzBh4idJ+gk1BP+9r+fLbAp53rrwE+1Zc2aOq/iEiacFvJRUREklCgi4ikCQW6iEiaUKCLiKQJBbqISJpQoIuIpAkFuohImvh/lZ8UHszUnq4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'],'r')\n",
    "plt.plot(history.history['val_accuracy'],'g')\n",
    "plt.xlabel('# epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 111us/step\n",
      "[0.21891900897026062, 0.8888888955116272]\n"
     ]
    }
   ],
   "source": [
    "new_test_target = np_utils.to_categorical(test_target)\n",
    "\n",
    "print(model.evaluate(test_data , new_test_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 316\n",
      "Trainable params: 316\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('Mango_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.14372337e-01 2.84281194e-01 1.34640548e-03 4.67252903e-08]\n",
      " [4.84394642e-13 4.15835729e-07 4.16274846e-01 5.83724737e-01]\n",
      " [1.01257319e-04 3.19296829e-02 8.51098597e-01 1.16870485e-01]\n",
      " [8.43264925e-09 2.39282497e-04 8.63339961e-01 1.36420771e-01]\n",
      " [9.56374586e-01 4.36114855e-02 1.39207341e-05 3.01030229e-12]\n",
      " [8.55081081e-01 1.44763365e-01 1.55595568e-04 4.82962932e-08]\n",
      " [5.35278371e-14 1.72502962e-06 2.94551384e-02 9.70543146e-01]\n",
      " [8.57723236e-01 1.42229170e-01 4.75275228e-05 2.16152637e-10]\n",
      " [9.42836166e-04 9.37255979e-01 6.17986917e-02 2.42783381e-06]]\n",
      "[[4 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 2 1]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "predicted_target=model.predict(test_data)\n",
    "print(predicted_target)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781838555078/6/ch06lvl1sec34/confusion-matrix\n",
    "#cm=confusion_matrix(y_test,y_pred_class)\n",
    "cm=confusion_matrix(np.argmax(new_test_target,axis=1),np.argmax(predicted_target,axis=1))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
